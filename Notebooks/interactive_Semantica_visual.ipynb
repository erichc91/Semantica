{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79dbc480",
   "metadata": {},
   "source": [
    "# Interactive Semantica Visualization\n",
    "\n",
    "This notebook provides interactive visualizations for the Semantica project, demonstrating the behavior of experimental designs under Relational Semantic Convergence (RSC) theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d876cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting for Jupyter - set proper backend for interactive plots\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "# Set notebook backend for interactive plots\n",
    "mpl.use('notebook')\n",
    "\n",
    "# Increase default figure size for better visualization\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 100\n",
    "\n",
    "# For interactive plotly visualizations\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "pio.renderers.default = \"notebook\"\n",
    "\n",
    "# Add the Py Scripts folder to the path to import the ConceptNetProcessor\n",
    "# reload the module if it has been modified    \n",
    "\n",
    "sys.path.append('../Py Scripts')\n",
    "from conceptnet_processor import ConceptNetProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6c15a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload module if modified\n",
    "from importlib import reload\n",
    "sys.path.append('../Py Scripts')\n",
    "from conceptnet_processor import ConceptNetProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d9c540",
   "metadata": {},
   "source": [
    "## 1. Load ConceptNet Data\n",
    "\n",
    "We'll load the English and German ConceptNet data files that are already in your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b28abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "data_path = '../Data/Input'\n",
    "english_file = os.path.join(data_path, 'conceptnet-assertions-5.7.0.en.tsv')\n",
    "german_file = os.path.join(data_path, 'conceptnet-assertions-5.7.0.de.tsv')\n",
    "\n",
    "# Check if files exist\n",
    "english_exists = os.path.exists(english_file)\n",
    "german_exists = os.path.exists(german_file)\n",
    "\n",
    "print(f\"English ConceptNet data: {'Found' if english_exists else 'Not found'} at {english_file}\")\n",
    "print(f\"German ConceptNet data: {'Found' if german_exists else 'Not found'} at {german_file}\")\n",
    "\n",
    "# Load data if available\n",
    "english_data = None\n",
    "german_data = None\n",
    "\n",
    "if english_exists:\n",
    "    print(\"Loading English ConceptNet data...\")\n",
    "    english_data = pd.read_csv(\n",
    "        english_file, \n",
    "        sep='\\t', \n",
    "        names=['URI', 'rel', 'start', 'end', 'weight', 'source', 'id', 'dataset', 'surfaceText'],\n",
    "        header=None\n",
    "    )\n",
    "    print(f\"Loaded {len(english_data)} English assertions\")\n",
    "\n",
    "if german_exists:\n",
    "    print(\"Loading German ConceptNet data...\")\n",
    "    german_data = pd.read_csv(\n",
    "        german_file, \n",
    "        sep='\\t', \n",
    "        names=['URI', 'rel', 'start', 'end', 'weight', 'source', 'id', 'dataset', 'surfaceText'],\n",
    "        header=None\n",
    "    )\n",
    "    print(f\"Loaded {len(german_data)} German assertions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71532d",
   "metadata": {},
   "source": [
    "## 1.1 Process and Save Complete Dataset\n",
    "\n",
    "This cell processes the complete ConceptNet data and saves it to files for faster loading in future sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0175282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and save complete dataset for later use\n",
    "def process_and_save_complete_data(english_data=None, german_data=None):\n",
    "    \"\"\"Process the complete ConceptNet dataset and save it for faster loading in future sessions\"\"\"\n",
    "    print(\"Initializing ConceptNetProcessor for complete dataset...\")\n",
    "    full_processor = ConceptNetProcessor(english_data, german_data)\n",
    "    \n",
    "    print(\"Building semantic graph with complete dataset...\")\n",
    "    # Use much larger max_concepts and 100% of the data\n",
    "    full_processor.build_semantic_graph(\n",
    "        max_concepts=100_000,  # Use a large number to include most concepts\n",
    "        min_weight=1.0,        # Only include relationships with weight >= 1.0\n",
    "        sample_size=1.0        # Use the complete dataset\n",
    "    )\n",
    "    \n",
    "    print(\"Saving complete preprocessed data...\")\n",
    "    # Save the complete preprocessed data to files with a distinctive name\n",
    "    full_processor.save_preprocessed_data(\n",
    "        english_file='english_conceptnet_complete.csv',\n",
    "        german_file='german_conceptnet_complete.csv'\n",
    "    )\n",
    "    \n",
    "    print(\"\\nComplete dataset saved. You can now load this data directly in future sessions.\")\n",
    "    return full_processor\n",
    "\n",
    "# Uncomment and run the line below to process and save the complete dataset\n",
    "# Note: This may take a significant amount of time depending on the size of your data\n",
    "full_processor = process_and_save_complete_data(english_data, german_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1448c90",
   "metadata": {},
   "source": [
    "## 1.2 Load Preprocessed Data\n",
    "\n",
    "This cell lets you load previously saved preprocessed data to skip the time-consuming processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec08d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading complete preprocessed English data...\n",
      "Loaded 3423004 preprocessed English assertions\n",
      "Loading complete preprocessed German data...\n",
      "Loaded 3423004 preprocessed English assertions\n",
      "Loading complete preprocessed German data...\n",
      "Loaded 1078946 preprocessed German assertions\n",
      "Initializing ConceptNetProcessor with loaded data...\n",
      "ConceptNetProcessor initialized\n",
      "Building semantic graph with 10.0% of data...\n",
      "Building semantic graph from ConceptNet data...\n",
      "Processing 3423004 English ConceptNet assertions...\n",
      "Will sample 342300 English assertions\n",
      "Processing 1078946 German ConceptNet assertions...\n",
      "Will sample 107894 German assertions\n",
      "Sampling 342300 assertions from 3423004 en assertions\n",
      "Loaded 1078946 preprocessed German assertions\n",
      "Initializing ConceptNetProcessor with loaded data...\n",
      "ConceptNetProcessor initialized\n",
      "Building semantic graph with 10.0% of data...\n",
      "Building semantic graph from ConceptNet data...\n",
      "Processing 3423004 English ConceptNet assertions...\n",
      "Will sample 342300 English assertions\n",
      "Processing 1078946 German ConceptNet assertions...\n",
      "Will sample 107894 German assertions\n",
      "Sampling 342300 assertions from 3423004 en assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing en assertions: 100%|██████████| 342300/342300 [00:11<00:00, 30574.24it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 107894 assertions from 1078946 de assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing de assertions: 100%|██████████| 107894/107894 [00:03<00:00, 31475.09it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limiting graph to top 15000 concepts...\n",
      "Semantic graph built with 15000 nodes and 39885 edges\n",
      "Inferring semantic categories...\n",
      "Inferred categories: {'generic': 13874, 'place': 886, 'person': 240}\n",
      "Generating concept vectors...\n",
      "Generating 5-dimensional concept vectors...\n",
      "Semantic graph built with 15000 nodes and 39885 edges\n",
      "Inferring semantic categories...\n",
      "Inferred categories: {'generic': 13874, 'place': 886, 'person': 240}\n",
      "Generating concept vectors...\n",
      "Generating 5-dimensional concept vectors...\n"
     ]
    }
   ],
   "source": [
    "def load_preprocessed_data(sample_size=0.5, max_concepts=15_000):\n",
    "    \"\"\"Load preprocessed ConceptNet data from saved files and build a semantic graph\"\"\"\n",
    "    \n",
    "    # Check if complete preprocessed files exist\n",
    "    complete_english_file = 'english_conceptnet_complete.csv'\n",
    "    complete_german_file = 'german_conceptnet_complete.csv'\n",
    "    \n",
    "    english_data_loaded = None\n",
    "    german_data_loaded = None\n",
    "    \n",
    "    # Try to load complete preprocessed data first\n",
    "    if os.path.exists(complete_english_file):\n",
    "        print(\"Loading complete preprocessed English data...\")\n",
    "        english_data_loaded = pd.read_csv(complete_english_file)\n",
    "        print(f\"Loaded {len(english_data_loaded)} preprocessed English assertions\")\n",
    "    \n",
    "    if os.path.exists(complete_german_file):\n",
    "        print(\"Loading complete preprocessed German data...\")\n",
    "        german_data_loaded = pd.read_csv(complete_german_file)\n",
    "        print(f\"Loaded {len(german_data_loaded)} preprocessed German assertions\")\n",
    "    \n",
    "    # If we couldn't find complete files, try regular preprocessed files\n",
    "    if english_data_loaded is None:\n",
    "        regular_english_file = 'english_conceptnet_preprocessed.csv'\n",
    "        if os.path.exists(regular_english_file):\n",
    "            print(\"Loading regular preprocessed English data...\")\n",
    "            english_data_loaded = pd.read_csv(regular_english_file)\n",
    "            print(f\"Loaded {len(english_data_loaded)} preprocessed English assertions\")\n",
    "    \n",
    "    if german_data_loaded is None:\n",
    "        regular_german_file = 'german_conceptnet_preprocessed.csv'\n",
    "        if os.path.exists(regular_german_file):\n",
    "            print(\"Loading regular preprocessed German data...\")\n",
    "            german_data_loaded = pd.read_csv(regular_german_file)\n",
    "            print(f\"Loaded {len(german_data_loaded)} preprocessed German assertions\")\n",
    "    \n",
    "    if english_data_loaded is None and german_data_loaded is None:\n",
    "        print(\"No preprocessed data found. Please run the data processing cell first.\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize processor with loaded data\n",
    "    print(\"Initializing ConceptNetProcessor with loaded data...\")\n",
    "    processor = ConceptNetProcessor(english_data_loaded, german_data_loaded)\n",
    "    \n",
    "    # Build semantic graph with specified sample size\n",
    "    print(f\"Building semantic graph with {sample_size*100}% of data...\")\n",
    "    processor.build_semantic_graph(\n",
    "        max_concepts=max_concepts,  # Limit concepts as specified\n",
    "        min_weight=1.0,             # Only include relationships with weight >= 1.0\n",
    "        sample_size=sample_size     # Use specified sample size\n",
    "    )\n",
    "    \n",
    "    print(\"Generating concept vectors...\")\n",
    "    processor.generate_concept_vectors(dimensions=5)  # 5-dimensional vectors for visualization\n",
    "    \n",
    "    return processor\n",
    "\n",
    "# Uncomment and modify the parameters below to load preprocessed data with your desired sample size\n",
    "processor = load_preprocessed_data(sample_size=0.1, max_concepts=15_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617a9577",
   "metadata": {},
   "source": [
    "## 2. Process ConceptNet Data with ConceptNetProcessor\n",
    "\n",
    "We'll use the ConceptNetProcessor class from your codebase to process the data and build a semantic graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23e99f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_conceptnet_data(english_data=None, german_data=None, max_concepts=15_000, sample_size=0.5):\n",
    "#     \"\"\"Process ConceptNet data and return the processor object\"\"\"\n",
    "#     print(\"Initializing ConceptNetProcessor...\")\n",
    "#     processor = ConceptNetProcessor(english_data, german_data)\n",
    "    \n",
    "#     print(\"Building semantic graph...\")\n",
    "#     processor.build_semantic_graph(\n",
    "#         max_concepts=max_concepts,  # Limit to a manageable number of concepts\n",
    "#         min_weight=1.0,             # Only include relationships with weight >= 1.0\n",
    "#         sample_size=sample_size     # Use a subset of data for faster processing\n",
    "#     )\n",
    "    \n",
    "#     print(\"Generating concept vectors...\")\n",
    "#     processor.generate_concept_vectors(dimensions=5)  # 5-dimensional vectors for visualization\n",
    "    \n",
    "#     return processor\n",
    "\n",
    "# # Process the data with default parameters\n",
    "# processor = process_conceptnet_data(english_data, german_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e007dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save english and german preprocessed data\n",
    "# processor.save_preprocessed_data(\n",
    "#     english_file='english_conceptnet_preprocessed.csv',\n",
    "#     german_file='german_conceptnet_preprocessed.csv'\n",
    "# )\n",
    "# # Display the first few rows of the preprocessed data\n",
    "# if english_data is not None:\n",
    "#     print(\"\\nEnglish Preprocessed Data Sample:\")\n",
    "#     print(processor.english_data.head())\n",
    "# if german_data is not None:\n",
    "#     print(\"\\nGerman Preprocessed Data Sample:\")\n",
    "#     print(processor.german_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6308c9a5",
   "metadata": {},
   "source": [
    "## 3. Basic Network Information\n",
    "\n",
    "Let's show some basic information about the semantic network we've built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06976b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_network_info(processor):\n",
    "    \"\"\"Display basic information about the semantic network\"\"\"\n",
    "    # Get basic graph metrics\n",
    "    graph = processor.semantic_graph\n",
    "    num_nodes = graph.number_of_nodes()\n",
    "    num_edges = graph.number_of_edges()\n",
    "    \n",
    "    # Get node and edge attributes\n",
    "    categories = {}\n",
    "    languages = {}\n",
    "    relation_types = set()\n",
    "    \n",
    "    for node, data in graph.nodes(data=True):\n",
    "        cat = data.get('category', 'unknown')\n",
    "        lang = data.get('lang', 'unknown')\n",
    "        \n",
    "        categories[cat] = categories.get(cat, 0) + 1\n",
    "        languages[lang] = languages.get(lang, 0) + 1\n",
    "    \n",
    "    for _, _, data in graph.edges(data=True):\n",
    "        rel = data.get('relation', 'unknown')\n",
    "        relation_types.add(rel)\n",
    "    \n",
    "    # Display information\n",
    "    print(f\"Semantic Network Information:\")\n",
    "    print(f\"  - Nodes: {num_nodes}\")\n",
    "    print(f\"  - Edges: {num_edges}\")\n",
    "    print(f\"  - Node Category Distribution: {categories}\")\n",
    "    print(f\"  - Node Language Distribution: {languages}\")\n",
    "    print(f\"  - Relation Types: {len(relation_types)}\")\n",
    "    print(f\"  - Top 10 Relation Types: {list(relation_types)[:10]}\")\n",
    "\n",
    "display_network_info(processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ffba06",
   "metadata": {},
   "source": [
    "## 4. Interactive Concept Explorer\n",
    "\n",
    "This interactive widget allows you to explore concepts and their relationships in the semantic network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab7b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concept_explorer(processor):\n",
    "    \"\"\"Create an interactive widget to explore concepts and their relationships\"\"\"\n",
    "    # Get all concepts (nodes) from the graph\n",
    "    concepts = sorted(list(processor.semantic_graph.nodes()))\n",
    "    \n",
    "    if not concepts:\n",
    "        print(\"No concepts found in the graph. Please ensure data processing was successful.\")\n",
    "        return\n",
    "    \n",
    "    # Define the widget layout\n",
    "    concept_dropdown = widgets.Dropdown(\n",
    "        options=concepts,\n",
    "        description='Concept:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    relation_types = ['All'] + sorted(list(processor.relation_types))\n",
    "    relation_dropdown = widgets.Dropdown(\n",
    "        options=relation_types,\n",
    "        description='Relation Type:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    depth_slider = widgets.IntSlider(\n",
    "        min=1,\n",
    "        max=3,\n",
    "        step=1,\n",
    "        value=1,\n",
    "        description='Depth:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Define the output function\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def on_change(change):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            concept = concept_dropdown.value\n",
    "            relation = relation_dropdown.value\n",
    "            depth = depth_slider.value\n",
    "            \n",
    "            # Create a subgraph centered on the selected concept\n",
    "            nodes_to_include = {concept}\n",
    "            edges_to_include = []\n",
    "            \n",
    "            # BFS to get nodes up to specified depth\n",
    "            current_nodes = {concept}\n",
    "            for d in range(depth):\n",
    "                next_nodes = set()\n",
    "                for node in current_nodes:\n",
    "                    # Get outgoing edges\n",
    "                    for src, tgt, data in processor.semantic_graph.out_edges(node, data=True):\n",
    "                        rel_type = data.get('relation', 'unknown')\n",
    "                        if relation == 'All' or rel_type == relation:\n",
    "                            nodes_to_include.add(tgt)\n",
    "                            next_nodes.add(tgt)\n",
    "                            edges_to_include.append((src, tgt, data))\n",
    "                    \n",
    "                    # Get incoming edges\n",
    "                    for src, tgt, data in processor.semantic_graph.in_edges(node, data=True):\n",
    "                        rel_type = data.get('relation', 'unknown')\n",
    "                        if relation == 'All' or rel_type == relation:\n",
    "                            nodes_to_include.add(src)\n",
    "                            next_nodes.add(src)\n",
    "                            edges_to_include.append((src, tgt, data))\n",
    "                \n",
    "                current_nodes = next_nodes\n",
    "            \n",
    "            # Create subgraph\n",
    "            subgraph = nx.DiGraph()\n",
    "            for node in nodes_to_include:\n",
    "                if processor.semantic_graph.has_node(node):\n",
    "                    subgraph.add_node(node, **processor.semantic_graph.nodes[node])\n",
    "            \n",
    "            for src, tgt, data in edges_to_include:\n",
    "                subgraph.add_edge(src, tgt, **data)\n",
    "            \n",
    "            # Display concept information\n",
    "            if processor.semantic_graph.has_node(concept):\n",
    "                node_data = processor.semantic_graph.nodes[concept]\n",
    "                print(f\"Concept: {concept}\")\n",
    "                print(f\"Category: {node_data.get('category', 'unknown')}\")\n",
    "                print(f\"Language: {node_data.get('lang', 'unknown')}\")\n",
    "                print(f\"Occurrence count: {node_data.get('count', 0)}\")\n",
    "                print(f\"Connected concepts: {subgraph.number_of_nodes() - 1}\")\n",
    "                print(f\"Relationships: {subgraph.number_of_edges()}\")\n",
    "                print(\"\\n\")\n",
    "            \n",
    "            # Visualization settings\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            pos = nx.spring_layout(subgraph, seed=42)  # Consistent layout\n",
    "            \n",
    "            # Define node colors by category\n",
    "            category_colors = {\n",
    "                'person': 'skyblue',\n",
    "                'place': 'lightgreen',\n",
    "                'animal': 'salmon',\n",
    "                'generic': 'lightgray'\n",
    "            }\n",
    "            \n",
    "            # Create node color list\n",
    "            node_colors = [category_colors.get(subgraph.nodes[n].get('category', 'generic'), 'lightgray') for n in subgraph.nodes()]\n",
    "            \n",
    "            # Draw the graph\n",
    "            nx.draw_networkx_nodes(subgraph, pos, node_size=500, node_color=node_colors, alpha=0.8)\n",
    "            nx.draw_networkx_edges(subgraph, pos, width=1.5, alpha=0.6, edge_color='gray', arrows=True, arrowsize=15)\n",
    "            nx.draw_networkx_labels(subgraph, pos, font_size=10, font_weight='bold')\n",
    "            \n",
    "            # Add edge labels (relation types)\n",
    "            edge_labels = {(src, tgt): data.get('relation', '') for src, tgt, data in subgraph.edges(data=True)}\n",
    "            nx.draw_networkx_edge_labels(subgraph, pos, edge_labels=edge_labels, font_size=8)\n",
    "            \n",
    "            # Highlight selected concept\n",
    "            if concept in subgraph.nodes():\n",
    "                nx.draw_networkx_nodes(subgraph, pos, nodelist=[concept], node_size=700, node_color='gold', alpha=1.0)\n",
    "            \n",
    "            plt.title(f\"Semantic network centered on '{concept}'\")\n",
    "            plt.axis('off')  # Hide axes\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # List all relationships\n",
    "            print(\"Relationships:\")\n",
    "            for src, tgt, data in sorted(subgraph.edges(data=True), key=lambda x: x[2].get('relation', '')):\n",
    "                rel = data.get('relation', 'unknown')\n",
    "                weight = data.get('weight', 0.0)\n",
    "                print(f\"  - {src} -{rel}-> {tgt} (weight: {weight:.2f})\")\n",
    "    \n",
    "    # Connect widgets to the change function\n",
    "    concept_dropdown.observe(on_change, names='value')\n",
    "    relation_dropdown.observe(on_change, names='value')\n",
    "    depth_slider.observe(on_change, names='value')\n",
    "    \n",
    "    # Create the UI layout\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HBox([concept_dropdown, relation_dropdown, depth_slider]),\n",
    "        output\n",
    "    ])\n",
    "    \n",
    "    # Trigger initial display\n",
    "    on_change(None)\n",
    "    \n",
    "    return ui\n",
    "\n",
    "# Create and display the interactive widget\n",
    "explorer = concept_explorer(processor)\n",
    "display(explorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab4d6b1",
   "metadata": {},
   "source": [
    "## 5. Semantic Similarity Explorer\n",
    "\n",
    "This widget lets you explore semantic similarities between concepts based on vector representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e5c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_explorer(processor):\n",
    "    \"\"\"Create an interactive widget to explore semantic similarities between concepts\"\"\"\n",
    "    # Get concepts that have vector representations\n",
    "    concepts = sorted(list(processor.concept_vectors.keys()))\n",
    "    \n",
    "    if not concepts:\n",
    "        print(\"No concept vectors found. Please ensure vectors were generated successfully.\")\n",
    "        return\n",
    "    \n",
    "    # Define the widget layout\n",
    "    concept1_dropdown = widgets.Dropdown(\n",
    "        options=concepts,\n",
    "        description='Concept 1:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    concept2_dropdown = widgets.Dropdown(\n",
    "        options=concepts,\n",
    "        description='Concept 2:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    num_similar_slider = widgets.IntSlider(\n",
    "        min=5,\n",
    "        max=25,\n",
    "        step=5,\n",
    "        value=10,\n",
    "        description='# of similar concepts:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Define the output function\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    from scipy.spatial.distance import cosine\n",
    "    \n",
    "    def calculate_similarity(vec1, vec2):\n",
    "        \"\"\"Calculate cosine similarity between two vectors\"\"\"\n",
    "        return 1 - cosine(vec1, vec2)  # Convert distance to similarity\n",
    "    \n",
    "    def find_similar_concepts(concept, n=10):\n",
    "        \"\"\"Find the n most similar concepts to the given concept\"\"\"\n",
    "        if concept not in processor.concept_vectors:\n",
    "            return []\n",
    "        \n",
    "        concept_vec = processor.concept_vectors[concept]['vector']\n",
    "        similarities = []\n",
    "        \n",
    "        for c, data in processor.concept_vectors.items():\n",
    "            if c != concept:  # Skip self-comparison\n",
    "                sim = calculate_similarity(concept_vec, data['vector'])\n",
    "                similarities.append((c, sim))\n",
    "        \n",
    "        # Sort by similarity (descending)\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        return similarities[:n]\n",
    "    \n",
    "    def on_change(change):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            concept1 = concept1_dropdown.value\n",
    "            concept2 = concept2_dropdown.value\n",
    "            num_similar = num_similar_slider.value\n",
    "            \n",
    "            # Calculate similarity between selected concepts\n",
    "            if concept1 in processor.concept_vectors and concept2 in processor.concept_vectors:\n",
    "                vec1 = processor.concept_vectors[concept1]['vector']\n",
    "                vec2 = processor.concept_vectors[concept2]['vector']\n",
    "                similarity = calculate_similarity(vec1, vec2)\n",
    "                \n",
    "                print(f\"Semantic similarity between '{concept1}' and '{concept2}': {similarity:.4f}\")\n",
    "                print(\"\\n\")\n",
    "            \n",
    "            # Find similar concepts for concept1\n",
    "            similar_to_concept1 = find_similar_concepts(concept1, num_similar)\n",
    "            print(f\"Top {len(similar_to_concept1)} concepts similar to '{concept1}':\")\n",
    "            for c, sim in similar_to_concept1:\n",
    "                print(f\"  - {c}: {sim:.4f}\")\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            # Find similar concepts for concept2\n",
    "            similar_to_concept2 = find_similar_concepts(concept2, num_similar)\n",
    "            print(f\"Top {len(similar_to_concept2)} concepts similar to '{concept2}':\")\n",
    "            for c, sim in similar_to_concept2:\n",
    "                print(f\"  - {c}: {sim:.4f}\")\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            # Find common similar concepts\n",
    "            similar1_set = {c for c, _ in similar_to_concept1}\n",
    "            similar2_set = {c for c, _ in similar_to_concept2}\n",
    "            common_concepts = similar1_set.intersection(similar2_set)\n",
    "            \n",
    "            if common_concepts:\n",
    "                print(f\"Common similar concepts: {', '.join(sorted(common_concepts))}\")\n",
    "            else:\n",
    "                print(\"No common similar concepts found.\")\n",
    "    \n",
    "    # Connect widgets to the change function\n",
    "    concept1_dropdown.observe(on_change, names='value')\n",
    "    concept2_dropdown.observe(on_change, names='value')\n",
    "    num_similar_slider.observe(on_change, names='value')\n",
    "    \n",
    "    # Create the UI layout\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HBox([concept1_dropdown, concept2_dropdown, num_similar_slider]),\n",
    "        output\n",
    "    ])\n",
    "    \n",
    "    # Set different initial values for dropdowns\n",
    "    if len(concepts) > 1:\n",
    "        concept1_dropdown.value = concepts[0]\n",
    "        concept2_dropdown.value = concepts[1]\n",
    "    \n",
    "    # Trigger initial display\n",
    "    on_change(None)\n",
    "    \n",
    "    return ui\n",
    "\n",
    "# Create and display the interactive widget\n",
    "similarity_widget = similarity_explorer(processor)\n",
    "display(similarity_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0213b3",
   "metadata": {},
   "source": [
    "## 6. Relation Type Explorer\n",
    "\n",
    "This widget lets you explore different types of semantic relations in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relation_explorer(processor):\n",
    "    \"\"\"Create an interactive widget to explore relation types in the semantic network\"\"\"\n",
    "    # Get all relation types from the graph\n",
    "    relation_types = sorted(list(processor.relation_types))\n",
    "    \n",
    "    if not relation_types:\n",
    "        print(\"No relation types found in the graph. Please ensure data processing was successful.\")\n",
    "        return\n",
    "    \n",
    "    # Define the widget layout\n",
    "    relation_dropdown = widgets.Dropdown(\n",
    "        options=relation_types,\n",
    "        description='Relation Type:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    max_examples_slider = widgets.IntSlider(\n",
    "        min=5,\n",
    "        max=30,\n",
    "        step=5,\n",
    "        value=10,\n",
    "        description='Max Examples:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Define the output function\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def on_change(change):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            relation = relation_dropdown.value\n",
    "            max_examples = max_examples_slider.value\n",
    "            \n",
    "            # Find all edges with the selected relation type\n",
    "            examples = []\n",
    "            for src, tgt, data in processor.semantic_graph.edges(data=True):\n",
    "                if data.get('relation', '') == relation:\n",
    "                    examples.append((src, tgt, data.get('weight', 0.0)))\n",
    "            \n",
    "            # Sort by weight and take top examples\n",
    "            examples.sort(key=lambda x: x[2], reverse=True)\n",
    "            top_examples = examples[:max_examples]\n",
    "            \n",
    "            # Display information\n",
    "            print(f\"Relation Type: {relation}\")\n",
    "            print(f\"Total Occurrences: {len(examples)}\")\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            if top_examples:\n",
    "                print(f\"Top {len(top_examples)} Examples:\")\n",
    "                for src, tgt, weight in top_examples:\n",
    "                    print(f\"  - {src} -{relation}-> {tgt} (weight: {weight:.2f})\")\n",
    "            else:\n",
    "                print(\"No examples found.\")\n",
    "            \n",
    "            # Create a subgraph for visualization\n",
    "            subgraph = nx.DiGraph()\n",
    "            for src, tgt, weight in top_examples:\n",
    "                if processor.semantic_graph.has_node(src) and processor.semantic_graph.has_node(tgt):\n",
    "                    # Add nodes with their attributes\n",
    "                    subgraph.add_node(src, **processor.semantic_graph.nodes[src])\n",
    "                    subgraph.add_node(tgt, **processor.semantic_graph.nodes[tgt])\n",
    "                    # Add edge\n",
    "                    subgraph.add_edge(src, tgt, relation=relation, weight=weight)\n",
    "            \n",
    "            # Visualization\n",
    "            if subgraph.number_of_nodes() > 0:\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                pos = nx.spring_layout(subgraph, seed=42)  # Consistent layout\n",
    "                \n",
    "                # Define node colors by category\n",
    "                category_colors = {\n",
    "                    'person': 'skyblue',\n",
    "                    'place': 'lightgreen',\n",
    "                    'animal': 'salmon',\n",
    "                    'generic': 'lightgray'\n",
    "                }\n",
    "                \n",
    "                # Create node color list\n",
    "                node_colors = [category_colors.get(subgraph.nodes[n].get('category', 'generic'), 'lightgray') for n in subgraph.nodes()]\n",
    "                \n",
    "                # Draw the graph\n",
    "                nx.draw_networkx_nodes(subgraph, pos, node_size=500, node_color=node_colors, alpha=0.8)\n",
    "                nx.draw_networkx_edges(subgraph, pos, width=1.5, alpha=0.6, edge_color='gray', arrows=True, arrowsize=15)\n",
    "                nx.draw_networkx_labels(subgraph, pos, font_size=10, font_weight='bold')\n",
    "                \n",
    "                plt.title(f\"Examples of '{relation}' relationships\")\n",
    "                plt.axis('off')  # Hide axes\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "    \n",
    "    # Connect widgets to the change function\n",
    "    relation_dropdown.observe(on_change, names='value')\n",
    "    max_examples_slider.observe(on_change, names='value')\n",
    "    \n",
    "    # Create the UI layout\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HBox([relation_dropdown, max_examples_slider]),\n",
    "        output\n",
    "    ])\n",
    "    \n",
    "    # Trigger initial display\n",
    "    on_change(None)\n",
    "    \n",
    "    return ui\n",
    "\n",
    "# Create and display the interactive widget\n",
    "relation_widget = relation_explorer(processor)\n",
    "display(relation_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89bdb80",
   "metadata": {},
   "source": [
    "## 7. Cross-Lingual Concept Explorer\n",
    "\n",
    "This widget helps explore the cross-lingual relationships between English and German concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ba10b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_lingual_explorer(processor):\n",
    "    \"\"\"Create an interactive widget to explore cross-lingual relationships\"\"\"\n",
    "    # Get concepts by language\n",
    "    english_concepts = []\n",
    "    german_concepts = []\n",
    "    \n",
    "    for node, data in processor.semantic_graph.nodes(data=True):\n",
    "        lang = data.get('lang', 'unknown')\n",
    "        if lang == 'en':\n",
    "            english_concepts.append(node)\n",
    "        elif lang == 'de':\n",
    "            german_concepts.append(node)\n",
    "    \n",
    "    english_concepts.sort()\n",
    "    german_concepts.sort()\n",
    "    \n",
    "    if not english_concepts or not german_concepts:\n",
    "        print(\"Insufficient cross-lingual data. Please ensure both English and German data were processed successfully.\")\n",
    "        return\n",
    "    \n",
    "    # Define the widget layout\n",
    "    english_dropdown = widgets.Dropdown(\n",
    "        options=english_concepts,\n",
    "        description='English Concept:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    german_dropdown = widgets.Dropdown(\n",
    "        options=german_concepts,\n",
    "        description='German Concept:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Define the output function\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    from scipy.spatial.distance import cosine\n",
    "    \n",
    "    def find_translations(concept, from_lang, to_lang):\n",
    "        \"\"\"Find potential translations for a concept\"\"\"\n",
    "        if concept not in processor.concept_vectors:\n",
    "            return []\n",
    "        \n",
    "        concept_vec = processor.concept_vectors[concept]['vector']\n",
    "        translations = []\n",
    "        \n",
    "        for node, data in processor.semantic_graph.nodes(data=True):\n",
    "            if data.get('lang', '') == to_lang and node in processor.concept_vectors:\n",
    "                node_vec = processor.concept_vectors[node]['vector']\n",
    "                similarity = 1 - cosine(concept_vec, node_vec)\n",
    "                translations.append((node, similarity))\n",
    "        \n",
    "        # Sort by similarity (descending)\n",
    "        translations.sort(key=lambda x: x[1], reverse=True)\n",
    "        return translations[:10]  # Return top 10 potential translations\n",
    "    \n",
    "    def on_change(change):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            english_concept = english_dropdown.value\n",
    "            german_concept = german_dropdown.value\n",
    "            \n",
    "            # Get vectors for selected concepts\n",
    "            en_vector = None\n",
    "            de_vector = None\n",
    "            \n",
    "            if english_concept in processor.concept_vectors:\n",
    "                en_vector = processor.concept_vectors[english_concept]['vector']\n",
    "            \n",
    "            if german_concept in processor.concept_vectors:\n",
    "                de_vector = processor.concept_vectors[german_concept]['vector']\n",
    "            \n",
    "            # Calculate similarity between selected concepts\n",
    "            if en_vector is not None and de_vector is not None:\n",
    "                similarity = 1 - cosine(en_vector, de_vector)\n",
    "                print(f\"Semantic similarity between '{english_concept}' (EN) and '{german_concept}' (DE): {similarity:.4f}\")\n",
    "                print(\"\\n\")\n",
    "            \n",
    "            # Find potential translations for English concept\n",
    "            en_to_de = find_translations(english_concept, 'en', 'de')\n",
    "            print(f\"Potential German translations for '{english_concept}':\")\n",
    "            for concept, sim in en_to_de:\n",
    "                print(f\"  - {concept}: {sim:.4f}\")\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            # Find potential translations for German concept\n",
    "            de_to_en = find_translations(german_concept, 'de', 'en')\n",
    "            print(f\"Potential English translations for '{german_concept}':\")\n",
    "            for concept, sim in de_to_en:\n",
    "                print(f\"  - {concept}: {sim:.4f}\")\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            # Check for direct relationships in the graph\n",
    "            direct_relations = []\n",
    "            for src, tgt, data in processor.semantic_graph.edges(data=True):\n",
    "                if (src == english_concept and tgt == german_concept) or (src == german_concept and tgt == english_concept):\n",
    "                    relation = data.get('relation', 'unknown')\n",
    "                    weight = data.get('weight', 0.0)\n",
    "                    direct_relations.append((src, relation, tgt, weight))\n",
    "            \n",
    "            if direct_relations:\n",
    "                print(\"Direct relationships found:\")\n",
    "                for src, rel, tgt, weight in direct_relations:\n",
    "                    print(f\"  - {src} -{rel}-> {tgt} (weight: {weight:.2f})\")\n",
    "            else:\n",
    "                print(\"No direct relationships found between these concepts.\")\n",
    "    \n",
    "    # Connect widgets to the change function\n",
    "    english_dropdown.observe(on_change, names='value')\n",
    "    german_dropdown.observe(on_change, names='value')\n",
    "    \n",
    "    # Create the UI layout\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HBox([english_dropdown, german_dropdown]),\n",
    "        output\n",
    "    ])\n",
    "    \n",
    "    # Trigger initial display\n",
    "    on_change(None)\n",
    "    \n",
    "    return ui\n",
    "\n",
    "# Create and display the interactive widget\n",
    "cross_lingual_widget = cross_lingual_explorer(processor)\n",
    "display(cross_lingual_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2ae60b",
   "metadata": {},
   "source": [
    "## 8. Important Relationships Visualization\n",
    "\n",
    "This section uses the concept vectors to identify and visualize the most important relationships in the semantic network based on vector similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff84dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_relationships_viz(processor):\n",
    "    \"\"\"Create an interactive visualization for the most important semantic relationships\"\"\"\n",
    "    # Get concepts that have vector representations\n",
    "    concepts = list(processor.concept_vectors.keys())\n",
    "    \n",
    "    if not concepts:\n",
    "        print(\"No concept vectors found. Please ensure vectors were generated successfully.\")\n",
    "        return\n",
    "    \n",
    "    # Define the widget layout\n",
    "    num_relationships_slider = widgets.IntSlider(\n",
    "        min=10,\n",
    "        max=100,\n",
    "        step=10,\n",
    "        value=30,\n",
    "        description='# of relationships:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    threshold_slider = widgets.FloatSlider(\n",
    "        min=0.5,\n",
    "        max=0.95,\n",
    "        step=0.05,\n",
    "        value=0.7,\n",
    "        description='Similarity threshold:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    layout_dropdown = widgets.Dropdown(\n",
    "        options=['spring', 'circular', 'kamada_kawai', 'planar', 'random', 'spectral'],\n",
    "        value='spring',\n",
    "        description='Layout:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    color_by_dropdown = widgets.Dropdown(\n",
    "        options=['category', 'language', 'connectivity'],\n",
    "        value='category',\n",
    "        description='Color by:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Define the output function\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    from scipy.spatial.distance import cosine\n",
    "    import matplotlib.cm as cm\n",
    "    \n",
    "    def on_change(change):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            num_relationships = num_relationships_slider.value\n",
    "            threshold = threshold_slider.value\n",
    "            layout_type = layout_dropdown.value\n",
    "            color_by = color_by_dropdown.value\n",
    "            \n",
    "            # Find the most important relationships based on vector similarity\n",
    "            print(f\"Finding the {num_relationships} most important semantic relationships...\")\n",
    "            \n",
    "            # Calculate similarity between all concept pairs\n",
    "            similarities = []\n",
    "            concept_list = list(processor.concept_vectors.keys())\n",
    "            \n",
    "            # Use a subset if there are too many concepts\n",
    "            if len(concept_list) > 200:\n",
    "                import random\n",
    "                random.seed(42)  # For reproducibility\n",
    "                concept_list = random.sample(concept_list, 200)\n",
    "            \n",
    "            for i, concept1 in enumerate(tqdm(concept_list)):\n",
    "                for concept2 in concept_list[i+1:]:  # Avoid duplicate pairs\n",
    "                    if concept1 == concept2:\n",
    "                        continue\n",
    "                        \n",
    "                    vec1 = processor.concept_vectors[concept1]['vector']\n",
    "                    vec2 = processor.concept_vectors[concept2]['vector']\n",
    "                    similarity = 1 - cosine(vec1, vec2)\n",
    "                    \n",
    "                    if similarity >= threshold:\n",
    "                        similarities.append((concept1, concept2, similarity))\n",
    "            \n",
    "            # Sort by similarity and take top relationships\n",
    "            similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "            top_relationships = similarities[:num_relationships]\n",
    "            \n",
    "            if not top_relationships:\n",
    "                print(f\"No relationships found with similarity >= {threshold}. Try lowering the threshold.\")\n",
    "                return\n",
    "                \n",
    "            print(f\"Found {len(top_relationships)} relationships with similarity >= {threshold}\")\n",
    "            \n",
    "            # Create a subgraph for visualization\n",
    "            subgraph = nx.Graph()  # Undirected graph for similarity relationships\n",
    "            \n",
    "            # Add nodes and edges\n",
    "            nodes_added = set()\n",
    "            for concept1, concept2, sim in top_relationships:\n",
    "                # Add nodes with attributes from the original graph\n",
    "                for concept in [concept1, concept2]:\n",
    "                    if concept not in nodes_added:\n",
    "                        attrs = {}\n",
    "                        if processor.semantic_graph.has_node(concept):\n",
    "                            attrs = processor.semantic_graph.nodes[concept]\n",
    "                        subgraph.add_node(concept, **attrs)\n",
    "                        nodes_added.add(concept)\n",
    "                \n",
    "                # Add edge with similarity as weight\n",
    "                subgraph.add_edge(concept1, concept2, weight=sim, similarity=sim)\n",
    "            \n",
    "            # Calculate node size based on degree centrality\n",
    "            centrality = nx.degree_centrality(subgraph)\n",
    "            node_sizes = [300 + 700 * centrality[n] for n in subgraph.nodes()]\n",
    "            \n",
    "            # Calculate node colors based on selected attribute\n",
    "            if color_by == 'category':\n",
    "                categories = {n: subgraph.nodes[n].get('category', 'generic') for n in subgraph.nodes()}\n",
    "                unique_categories = sorted(set(categories.values()))\n",
    "                color_map = {cat: i for i, cat in enumerate(unique_categories)}\n",
    "                node_colors = [color_map[categories[n]] for n in subgraph.nodes()]\n",
    "                color_legend = {cat: plt.cm.tab10(i % 10) for i, cat in enumerate(unique_categories)}\n",
    "            elif color_by == 'language':\n",
    "                languages = {n: subgraph.nodes[n].get('lang', 'unknown') for n in subgraph.nodes()}\n",
    "                unique_languages = sorted(set(languages.values()))\n",
    "                color_map = {lang: i for i, lang in enumerate(unique_languages)}\n",
    "                node_colors = [color_map[languages[n]] for n in subgraph.nodes()]\n",
    "                color_legend = {lang: plt.cm.tab10(i % 10) for i, lang in enumerate(unique_languages)}\n",
    "            else:  # connectivity\n",
    "                node_colors = [centrality[n] for n in subgraph.nodes()]\n",
    "                color_legend = None\n",
    "            \n",
    "            # Calculate edge colors and widths based on similarity\n",
    "            edge_colors = [subgraph[u][v]['similarity'] for u, v in subgraph.edges()]\n",
    "            edge_widths = [1 + 3 * subgraph[u][v]['similarity'] for u, v in subgraph.edges()]\n",
    "            \n",
    "            # Select the layout function\n",
    "            if layout_type == 'spring':\n",
    "                pos = nx.spring_layout(subgraph, seed=42)\n",
    "            elif layout_type == 'circular':\n",
    "                pos = nx.circular_layout(subgraph)\n",
    "            elif layout_type == 'kamada_kawai':\n",
    "                pos = nx.kamada_kawai_layout(subgraph)\n",
    "            elif layout_type == 'planar':\n",
    "                try:\n",
    "                    pos = nx.planar_layout(subgraph)\n",
    "                except:\n",
    "                    pos = nx.spring_layout(subgraph, seed=42)\n",
    "                    print(\"Planar layout failed, falling back to spring layout.\")\n",
    "            elif layout_type == 'random':\n",
    "                pos = nx.random_layout(subgraph, seed=42)\n",
    "            else:  # spectral\n",
    "                pos = nx.spectral_layout(subgraph)\n",
    "            \n",
    "            # Create the visualization\n",
    "            plt.figure(figsize=(16, 12))\n",
    "            \n",
    "            # Draw nodes\n",
    "            if color_by == 'connectivity':\n",
    "                nodes = nx.draw_networkx_nodes(\n",
    "                    subgraph,\n",
    "                    pos,\n",
    "                    node_size=node_sizes,\n",
    "                    node_color=node_colors,\n",
    "                    alpha=0.8,\n",
    "                    cmap=plt.cm.viridis\n",
    "                )\n",
    "                plt.colorbar(nodes, label='Connectivity Centrality')\n",
    "            else:\n",
    "                nx.draw_networkx_nodes(\n",
    "                    subgraph,\n",
    "                    pos,\n",
    "                    node_size=node_sizes,\n",
    "                    node_color=node_colors,\n",
    "                    alpha=0.8,\n",
    "                    cmap=plt.cm.tab10\n",
    "                )\n",
    "                \n",
    "                # Add a legend for categories or languages\n",
    "                if color_legend:\n",
    "                    legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                                               markerfacecolor=plt.cm.tab10(color_map[k] % 10), \n",
    "                                               markersize=10, label=k)\n",
    "                                    for k in color_legend.keys()]\n",
    "                    plt.legend(handles=legend_elements, title=color_by.capitalize())\n",
    "            \n",
    "            # Draw edges with color gradient based on similarity\n",
    "            edges = nx.draw_networkx_edges(\n",
    "                subgraph,\n",
    "                pos,\n",
    "                width=edge_widths,\n",
    "                alpha=0.6,\n",
    "                edge_color=edge_colors,\n",
    "                edge_cmap=plt.cm.Blues\n",
    "            )\n",
    "            \n",
    "            # Draw labels for the most central nodes only\n",
    "            top_central_nodes = sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:15]\n",
    "            top_central_nodes = [n[0] for n in top_central_nodes]\n",
    "            nx.draw_networkx_labels(\n",
    "                subgraph,\n",
    "                pos,\n",
    "                labels={n: n for n in top_central_nodes},\n",
    "                font_size=10,\n",
    "                font_weight='bold'\n",
    "            )\n",
    "            \n",
    "            plt.title(f\"Most Important Semantic Relationships (similarity ≥ {threshold})\")\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Print some statistics\n",
    "            print(f\"Network Statistics:\")\n",
    "            print(f\"  - Nodes: {subgraph.number_of_nodes()}\")\n",
    "            print(f\"  - Edges: {subgraph.number_of_edges()}\")\n",
    "            print(f\"  - Density: {nx.density(subgraph):.4f}\")\n",
    "            print(f\"  - Average clustering coefficient: {nx.average_clustering(subgraph):.4f}\")\n",
    "            \n",
    "            # Print top 10 most similar concept pairs\n",
    "            print(\"\\nTop 10 Most Similar Concept Pairs:\")\n",
    "            for i, (c1, c2, sim) in enumerate(top_relationships[:10]):\n",
    "                print(f\"  {i+1}. {c1} — {c2}: {sim:.4f}\")\n",
    "    \n",
    "    # Connect widgets to the change function\n",
    "    num_relationships_slider.observe(on_change, names='value')\n",
    "    threshold_slider.observe(on_change, names='value')\n",
    "    layout_dropdown.observe(on_change, names='value')\n",
    "    color_by_dropdown.observe(on_change, names='value')\n",
    "    \n",
    "    # Create the UI layout\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HBox([\n",
    "            num_relationships_slider,\n",
    "            threshold_slider,\n",
    "            layout_dropdown,\n",
    "            color_by_dropdown\n",
    "        ]),\n",
    "        output\n",
    "    ])\n",
    "    \n",
    "    # Trigger initial display\n",
    "    on_change(None)\n",
    "    \n",
    "    return ui\n",
    "\n",
    "# Create and display the interactive widget\n",
    "important_relationships_widget = important_relationships_viz(processor)\n",
    "display(important_relationships_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387d4967",
   "metadata": {},
   "source": [
    "## 9. Animated Semantic Diffusion\n",
    "\n",
    "This visualization demonstrates how semantic information spreads through the network, simulating diffusion of meaning across concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d583e72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_diffusion_animation(processor):\n",
    "    \"\"\"Create an animated visualization of semantic diffusion in the network\"\"\"\n",
    "    # Get all concepts from the graph\n",
    "    concepts = sorted(list(processor.semantic_graph.nodes()))\n",
    "    \n",
    "    if not concepts:\n",
    "        print(\"No concepts found in the graph. Please ensure data processing was successful.\")\n",
    "        return\n",
    "    \n",
    "    # Define the widget layout\n",
    "    concept_dropdown = widgets.Dropdown(\n",
    "        options=concepts,\n",
    "        description='Start concept:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    num_steps_slider = widgets.IntSlider(\n",
    "        min=3,\n",
    "        max=10,\n",
    "        step=1,\n",
    "        value=5,\n",
    "        description='Diffusion steps:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    max_nodes_slider = widgets.IntSlider(\n",
    "        min=20,\n",
    "        max=100,\n",
    "        step=10,\n",
    "        value=50,\n",
    "        description='Max nodes:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    layout_dropdown = widgets.Dropdown(\n",
    "        options=['spring', 'circular', 'kamada_kawai', 'spectral'],\n",
    "        value='spring',\n",
    "        description='Layout:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Define the output function\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    from matplotlib.animation import FuncAnimation\n",
    "    import matplotlib as mpl\n",
    "    from IPython.display import HTML\n",
    "    \n",
    "    def on_change(change):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            start_concept = concept_dropdown.value\n",
    "            num_steps = num_steps_slider.value\n",
    "            max_nodes = max_nodes_slider.value\n",
    "            layout_type = layout_dropdown.value\n",
    "            \n",
    "            print(f\"Creating semantic diffusion animation starting from '{start_concept}'...\")\n",
    "            \n",
    "            # Simulate semantic diffusion\n",
    "            # We'll start with the selected concept and spread to neighbors in steps\n",
    "            current_nodes = {start_concept}\n",
    "            all_nodes = {start_concept}\n",
    "            step_nodes = [{start_concept}]  # Nodes added at each step\n",
    "            \n",
    "            for step in range(num_steps):\n",
    "                next_nodes = set()\n",
    "                for node in current_nodes:\n",
    "                    # Get neighbors in either direction\n",
    "                    neighbors = set(processor.semantic_graph.successors(node)).union(\n",
    "                        set(processor.semantic_graph.predecessors(node)))\n",
    "                    \n",
    "                    # Filter out nodes we've already seen\n",
    "                    new_neighbors = neighbors - all_nodes\n",
    "                    \n",
    "                    # Add to next wave, up to max_nodes\n",
    "                    remaining = max_nodes - len(all_nodes)\n",
    "                    if remaining <= 0:\n",
    "                        break\n",
    "                        \n",
    "                    # Add nodes up to the limit\n",
    "                    to_add = list(new_neighbors)[:remaining]\n",
    "                    next_nodes.update(to_add)\n",
    "                    all_nodes.update(to_add)\n",
    "                \n",
    "                step_nodes.append(next_nodes)\n",
    "                current_nodes = next_nodes\n",
    "                \n",
    "                if len(all_nodes) >= max_nodes:\n",
    "                    break\n",
    "            \n",
    "            # Create subgraph with the selected nodes\n",
    "            subgraph = nx.DiGraph()\n",
    "            for node in all_nodes:\n",
    "                if processor.semantic_graph.has_node(node):\n",
    "                    subgraph.add_node(node, **processor.semantic_graph.nodes[node])\n",
    "            \n",
    "            # Add edges between nodes in the subgraph\n",
    "            for node in all_nodes:\n",
    "                for nbr in processor.semantic_graph.successors(node):\n",
    "                    if nbr in all_nodes:\n",
    "                        edge_data = processor.semantic_graph.get_edge_data(node, nbr)\n",
    "                        subgraph.add_edge(node, nbr, **edge_data)\n",
    "            \n",
    "            # Calculate layout\n",
    "            if layout_type == 'spring':\n",
    "                pos = nx.spring_layout(subgraph, seed=42)\n",
    "            elif layout_type == 'circular':\n",
    "                pos = nx.circular_layout(subgraph)\n",
    "            elif layout_type == 'kamada_kawai':\n",
    "                pos = nx.kamada_kawai_layout(subgraph)\n",
    "            else:  # spectral\n",
    "                pos = nx.spectral_layout(subgraph)\n",
    "            \n",
    "            # Create the animation\n",
    "            fig, ax = plt.subplots(figsize=(12, 10), facecolor='#f0f0f0')\n",
    "            \n",
    "            # Define node colors by language\n",
    "            languages = {n: subgraph.nodes[n].get('lang', 'unknown') for n in subgraph.nodes()}\n",
    "            unique_languages = sorted(set(languages.values()))\n",
    "            language_colors = {lang: plt.cm.tab10(i % 10) for i, lang in enumerate(unique_languages)}\n",
    "            \n",
    "            def init():\n",
    "                ax.clear()\n",
    "                return []\n",
    "            \n",
    "            def animate(i):\n",
    "                ax.clear()\n",
    "                \n",
    "                # Calculate the active nodes at this step\n",
    "                active_nodes = set()\n",
    "                for step in range(min(i+1, len(step_nodes))):\n",
    "                    active_nodes.update(step_nodes[step])\n",
    "                \n",
    "                # Calculate node colors and sizes\n",
    "                node_colors = []\n",
    "                node_sizes = []\n",
    "                node_alphas = []\n",
    "                edge_colors = []\n",
    "                edge_widths = []\n",
    "                edge_alphas = []\n",
    "                \n",
    "                for node in subgraph.nodes():\n",
    "                    lang = languages[node]\n",
    "                    base_color = language_colors[lang]\n",
    "                    \n",
    "                    if node in active_nodes:\n",
    "                        # Active nodes are fully colored\n",
    "                        node_colors.append(base_color)\n",
    "                        node_sizes.append(300)\n",
    "                        node_alphas.append(1.0)\n",
    "                    else:\n",
    "                        # Inactive nodes are gray and smaller\n",
    "                        node_colors.append('gray')\n",
    "                        node_sizes.append(100)\n",
    "                        node_alphas.append(0.3)\n",
    "                        \n",
    "                # Handle edges\n",
    "                for u, v in subgraph.edges():\n",
    "                    if u in active_nodes and v in active_nodes:\n",
    "                        # Both nodes active - full color\n",
    "                        edge_colors.append('blue')\n",
    "                        edge_widths.append(2.0)\n",
    "                        edge_alphas.append(0.8)\n",
    "                    elif u in active_nodes or v in active_nodes:\n",
    "                        # One node active - medium color\n",
    "                        edge_colors.append('blue')\n",
    "                        edge_widths.append(1.5)\n",
    "                        edge_alphas.append(0.4)\n",
    "                    else:\n",
    "                        # No nodes active - light gray\n",
    "                        edge_colors.append('gray')\n",
    "                        edge_widths.append(0.5)\n",
    "                        edge_alphas.append(0.2)\n",
    "                \n",
    "                # Draw nodes with custom colors and sizes\n",
    "                for idx, node in enumerate(subgraph.nodes()):\n",
    "                    nx.draw_networkx_nodes(\n",
    "                        subgraph,\n",
    "                        pos,\n",
    "                        nodelist=[node],\n",
    "                        node_color=[node_colors[idx]],\n",
    "                        node_size=node_sizes[idx],\n",
    "                        alpha=node_alphas[idx],\n",
    "                        ax=ax\n",
    "                    )\n",
    "                \n",
    "                # Draw edges with varying colors and widths\n",
    "                for idx, (u, v) in enumerate(subgraph.edges()):\n",
    "                    nx.draw_networkx_edges(\n",
    "                        subgraph,\n",
    "                        pos,\n",
    "                        edgelist=[(u, v)],\n",
    "                        width=edge_widths[idx],\n",
    "                        edge_color=[edge_colors[idx]],\n",
    "                        alpha=edge_alphas[idx],\n",
    "                        ax=ax\n",
    "                    )\n",
    "                \n",
    "                # Draw labels for active nodes only\n",
    "                label_dict = {n: n for n in active_nodes}\n",
    "                nx.draw_networkx_labels(\n",
    "                    subgraph,\n",
    "                    pos,\n",
    "                    labels=label_dict,\n",
    "                    font_size=10,\n",
    "                    font_weight='bold',\n",
    "                    ax=ax\n",
    "                )\n",
    "                \n",
    "                # Add step counter and legend\n",
    "                diffusion_step = min(i, len(step_nodes)-1)\n",
    "                ax.set_title(f\"Semantic Diffusion - Step {diffusion_step} of {len(step_nodes)-1}\")\n",
    "                ax.set_axis_off()\n",
    "                \n",
    "                # Add language legend\n",
    "                legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                                          markerfacecolor=language_colors[lang], \n",
    "                                          markersize=10, label=lang)\n",
    "                               for lang in unique_languages]\n",
    "                ax.legend(handles=legend_elements, title='Language', loc='upper right')\n",
    "                \n",
    "                return []\n",
    "            \n",
    "            # Create the animation\n",
    "            num_frames = len(step_nodes) + 3  # Add a few extra frames at the end\n",
    "            anim = FuncAnimation(\n",
    "                fig,\n",
    "                animate,\n",
    "                init_func=init,\n",
    "                frames=num_frames,\n",
    "                interval=800,  # milliseconds per frame\n",
    "                blit=True\n",
    "            )\n",
    "            \n",
    "            # Display the animation\n",
    "            plt.close(fig)  # prevent display of static figure\n",
    "            display(HTML(anim.to_jshtml()))\n",
    "            \n",
    "            # Print diffusion statistics\n",
    "            print(\"\\nDiffusion Statistics:\")\n",
    "            print(f\"  - Starting concept: {start_concept}\")\n",
    "            print(f\"  - Total steps: {len(step_nodes)-1}\")\n",
    "            print(f\"  - Total nodes reached: {len(all_nodes)}\")\n",
    "            \n",
    "            # Print nodes reached at each step\n",
    "            for i, nodes in enumerate(step_nodes):\n",
    "                if i == 0:\n",
    "                    print(f\"  - Step 0: Starting with '{start_concept}'\")\n",
    "                else:\n",
    "                    node_list = sorted(list(nodes))\n",
    "                    node_str = \", \".join(node_list[:5])\n",
    "                    if len(node_list) > 5:\n",
    "                        node_str += f\" and {len(node_list)-5} more\"\n",
    "                    print(f\"  - Step {i}: Added {len(nodes)} nodes ({node_str})\")\n",
    "    \n",
    "    # Connect widgets to the change function\n",
    "    concept_dropdown.observe(on_change, names='value')\n",
    "    num_steps_slider.observe(on_change, names='value')\n",
    "    max_nodes_slider.observe(on_change, names='value')\n",
    "    layout_dropdown.observe(on_change, names='value')\n",
    "    \n",
    "    # Create the UI layout\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HBox([concept_dropdown, num_steps_slider, max_nodes_slider, layout_dropdown]),\n",
    "        output\n",
    "    ])\n",
    "    \n",
    "    # Trigger initial display\n",
    "    on_change(None)\n",
    "    \n",
    "    return ui\n",
    "\n",
    "# Create and display the interactive widget\n",
    "diffusion_animation = semantic_diffusion_animation(processor)\n",
    "display(diffusion_animation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbe4c65",
   "metadata": {},
   "source": [
    "## 10. Enhanced Concept Explorer (Upgraded Version)\n",
    "\n",
    "This is an upgraded version of the Concept Explorer with improved visual design and richer semantic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "061c7cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded additional English ConceptNet data for enhanced visualization\n",
      "Loaded additional German ConceptNet data for enhanced visualization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce51c4c74d4f4fafa22179a8a45640e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Concept:', options=('a', 'ability', 'abwertend', 'accounti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def enhanced_concept_explorer(processor):\n",
    "    \"\"\"Create an enhanced interactive widget to explore concepts with better visuals and richer data\"\"\"\n",
    "    # Get all concepts (nodes) from the graph\n",
    "    concepts = sorted(list(processor.semantic_graph.nodes()))\n",
    "    \n",
    "    if not concepts:\n",
    "        print(\"No concepts found in the graph. Please ensure data processing was successful.\")\n",
    "        return\n",
    "    \n",
    "    # Try to load additional ConceptNet data if available\n",
    "    try:\n",
    "        # If preprocessed data is available, use it\n",
    "        english_data = pd.read_csv('english_conceptnet_preprocessed.csv')\n",
    "        print(\"Loaded additional English ConceptNet data for enhanced visualization\")\n",
    "    except:\n",
    "        english_data = None\n",
    "        \n",
    "    try:\n",
    "        german_data = pd.read_csv('german_conceptnet_preprocessed.csv')\n",
    "        print(\"Loaded additional German ConceptNet data for enhanced visualization\")\n",
    "    except:\n",
    "        german_data = None\n",
    "    \n",
    "    # Define the widget layout\n",
    "    concept_dropdown = widgets.Dropdown(\n",
    "        options=concepts,\n",
    "        description='Concept:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    relation_types = ['All'] + sorted(list(processor.relation_types))\n",
    "    relation_dropdown = widgets.Dropdown(\n",
    "        options=relation_types,\n",
    "        description='Relation Type:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    depth_slider = widgets.IntSlider(\n",
    "        min=1,\n",
    "        max=3,\n",
    "        step=1,\n",
    "        value=1,\n",
    "        description='Depth:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    layout_dropdown = widgets.Dropdown(\n",
    "        options=['spring', 'circular', 'kamada_kawai', 'spectral'],\n",
    "        value='spring',\n",
    "        description='Layout:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Define the output function\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def get_conceptnet_examples(concept, max_examples=5):\n",
    "        \"\"\"Get example sentences from ConceptNet data for a concept\"\"\"\n",
    "        examples = []\n",
    "        \n",
    "        # Check English data\n",
    "        if english_data is not None:\n",
    "            concept_prefix = f\"/c/en/{concept}\"\n",
    "            matches = english_data[english_data['start'].str.startswith(concept_prefix, na=False) | \n",
    "                                  english_data['end'].str.startswith(concept_prefix, na=False)]\n",
    "            \n",
    "            # Extract surface text examples\n",
    "            if 'surfaceText' in matches.columns:\n",
    "                examples.extend(matches['surfaceText'].dropna().tolist()[:max_examples])\n",
    "        \n",
    "        # Check German data\n",
    "        if german_data is not None and len(examples) < max_examples:\n",
    "            concept_prefix = f\"/c/de/{concept}\"\n",
    "            matches = german_data[german_data['start'].str.startswith(concept_prefix, na=False) | \n",
    "                                 german_data['end'].str.startswith(concept_prefix, na=False)]\n",
    "            \n",
    "            # Extract surface text examples\n",
    "            if 'surfaceText' in matches.columns:\n",
    "                examples.extend(matches['surfaceText'].dropna().tolist()[:max_examples-len(examples)])\n",
    "        \n",
    "        return examples\n",
    "    \n",
    "    def on_change(change):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            concept = concept_dropdown.value\n",
    "            relation = relation_dropdown.value\n",
    "            depth = depth_slider.value\n",
    "            layout_type = layout_dropdown.value\n",
    "            \n",
    "            # Create a subgraph centered on the selected concept\n",
    "            nodes_to_include = {concept}\n",
    "            edges_to_include = []\n",
    "            \n",
    "            # BFS to get nodes up to specified depth\n",
    "            current_nodes = {concept}\n",
    "            for d in range(depth):\n",
    "                next_nodes = set()\n",
    "                for node in current_nodes:\n",
    "                    # Get outgoing edges\n",
    "                    for src, tgt, data in processor.semantic_graph.out_edges(node, data=True):\n",
    "                        rel_type = data.get('relation', 'unknown')\n",
    "                        if relation == 'All' or rel_type == relation:\n",
    "                            nodes_to_include.add(tgt)\n",
    "                            next_nodes.add(tgt)\n",
    "                            edges_to_include.append((src, tgt, data))\n",
    "                    \n",
    "                    # Get incoming edges\n",
    "                    for src, tgt, data in processor.semantic_graph.in_edges(node, data=True):\n",
    "                        rel_type = data.get('relation', 'unknown')\n",
    "                        if relation == 'All' or rel_type == relation:\n",
    "                            nodes_to_include.add(src)\n",
    "                            next_nodes.add(src)\n",
    "                            edges_to_include.append((src, tgt, data))\n",
    "                \n",
    "                current_nodes = next_nodes\n",
    "            \n",
    "            # Create subgraph\n",
    "            subgraph = nx.DiGraph()\n",
    "            for node in nodes_to_include:\n",
    "                if processor.semantic_graph.has_node(node):\n",
    "                    subgraph.add_node(node, **processor.semantic_graph.nodes[node])\n",
    "            \n",
    "            for src, tgt, data in edges_to_include:\n",
    "                subgraph.add_edge(src, tgt, **data)\n",
    "            \n",
    "            # Get concept information\n",
    "            concept_examples = get_conceptnet_examples(concept)\n",
    "            \n",
    "            # Create a figure with two subplots - one for the graph, one for the info panel\n",
    "            fig = plt.figure(figsize=(16, 10), facecolor='#f8f9fa')\n",
    "            gs = fig.add_gridspec(1, 5)  # 1 row, 5 columns (graph takes 3, info panel takes 2)\n",
    "            \n",
    "            # Graph area\n",
    "            ax1 = fig.add_subplot(gs[0, :3])\n",
    "            \n",
    "            # Info panel area\n",
    "            ax2 = fig.add_subplot(gs[0, 3:])\n",
    "            \n",
    "            # Calculate the layout\n",
    "            if layout_type == 'spring':\n",
    "                pos = nx.spring_layout(subgraph, seed=42)\n",
    "            elif layout_type == 'circular':\n",
    "                pos = nx.circular_layout(subgraph)\n",
    "            elif layout_type == 'kamada_kawai':\n",
    "                pos = nx.kamada_kawai_layout(subgraph)\n",
    "            else:  # spectral\n",
    "                pos = nx.spectral_layout(subgraph)\n",
    "            \n",
    "            # Define node colors by language\n",
    "            languages = {n: subgraph.nodes[n].get('lang', 'unknown') for n in subgraph.nodes()}\n",
    "            unique_languages = sorted(set(languages.values()))\n",
    "            language_colors = {}\n",
    "            \n",
    "            # Use distinct colors for languages\n",
    "            if 'en' in unique_languages:\n",
    "                language_colors['en'] = '#3498db'  # Blue for English\n",
    "            if 'de' in unique_languages:\n",
    "                language_colors['de'] = '#e74c3c'  # Red for German\n",
    "                \n",
    "            # Fill in others with tab10 colors\n",
    "            other_langs = [l for l in unique_languages if l not in language_colors]\n",
    "            for i, lang in enumerate(other_langs):\n",
    "                language_colors[lang] = plt.cm.tab10(i % 10)\n",
    "            \n",
    "            # Create node color list\n",
    "            node_colors = [language_colors.get(languages[n], 'gray') for n in subgraph.nodes()]\n",
    "            \n",
    "            # Group edges by relation type for better visualization\n",
    "            relation_groups = {}\n",
    "            for src, tgt, data in subgraph.edges(data=True):\n",
    "                rel = data.get('relation', 'unknown')\n",
    "                if rel not in relation_groups:\n",
    "                    relation_groups[rel] = []\n",
    "                relation_groups[rel].append((src, tgt))\n",
    "            \n",
    "            # Calculate node sizes based on connectivity\n",
    "            node_sizes = {}\n",
    "            for node in subgraph.nodes():\n",
    "                # Use degree as a measure of importance\n",
    "                degree = subgraph.degree(node)\n",
    "                if node == concept:\n",
    "                    # Make the central concept larger\n",
    "                    node_sizes[node] = 800\n",
    "                else:\n",
    "                    # Scale other nodes by degree\n",
    "                    node_sizes[node] = 300 + (100 * degree)\n",
    "            \n",
    "            # Draw the graph in the left subplot\n",
    "            ax1.set_facecolor('#f8f9fa')\n",
    "            \n",
    "            # Draw nodes\n",
    "            nx.draw_networkx_nodes(\n",
    "                subgraph,\n",
    "                pos,\n",
    "                nodelist=list(subgraph.nodes()),\n",
    "                node_size=[node_sizes[n] for n in subgraph.nodes()],\n",
    "                node_color=node_colors,\n",
    "                alpha=0.8,\n",
    "                ax=ax1\n",
    "            )\n",
    "            \n",
    "            # Draw edges with different colors by relation type\n",
    "            edge_styles = {\n",
    "                'IsA': 'solid',\n",
    "                'PartOf': 'dashed',\n",
    "                'HasA': 'dashdot',\n",
    "                'UsedFor': 'dotted',\n",
    "                'CapableOf': 'solid',\n",
    "                'AtLocation': 'dashed',\n",
    "                'RelatedTo': 'dotted'\n",
    "            }\n",
    "            \n",
    "            edge_colors = {\n",
    "                'IsA': '#2ecc71',        # Green\n",
    "                'PartOf': '#9b59b6',     # Purple\n",
    "                'HasA': '#e67e22',       # Orange\n",
    "                'UsedFor': '#3498db',    # Blue\n",
    "                'CapableOf': '#f1c40f',  # Yellow\n",
    "                'AtLocation': '#1abc9c', # Turquoise\n",
    "                'RelatedTo': '#95a5a6'   # Gray\n",
    "            }\n",
    "            \n",
    "            # Draw edges by relation type\n",
    "            for rel, edges in relation_groups.items():\n",
    "                edge_style = edge_styles.get(rel, 'solid')\n",
    "                edge_color = edge_colors.get(rel, '#95a5a6')  # Default to gray\n",
    "                \n",
    "                nx.draw_networkx_edges(\n",
    "                    subgraph,\n",
    "                    pos,\n",
    "                    edgelist=edges,\n",
    "                    width=1.5,\n",
    "                    alpha=0.6,\n",
    "                    edge_color=edge_color,\n",
    "                    style=edge_style,\n",
    "                    arrows=True,\n",
    "                    arrowsize=15,\n",
    "                    ax=ax1\n",
    "                )\n",
    "            \n",
    "            # Draw node labels\n",
    "            nx.draw_networkx_labels(\n",
    "                subgraph,\n",
    "                pos,\n",
    "                font_size=10,\n",
    "                font_weight='bold',\n",
    "                ax=ax1\n",
    "            )\n",
    "            \n",
    "            # Highlight the selected concept\n",
    "            if concept in subgraph.nodes():\n",
    "                nx.draw_networkx_nodes(\n",
    "                    subgraph,\n",
    "                    pos,\n",
    "                    nodelist=[concept],\n",
    "                    node_size=node_sizes[concept],\n",
    "                    node_color='gold',\n",
    "                    edgecolors='black',\n",
    "                    linewidths=2,\n",
    "                    alpha=1.0,\n",
    "                    ax=ax1\n",
    "                )\n",
    "            \n",
    "            ax1.set_title(f\"Semantic Network for '{concept}'\")\n",
    "            ax1.axis('off')\n",
    "            \n",
    "            # Create the info panel in the right subplot\n",
    "            ax2.set_facecolor('#f8f9fa')\n",
    "            ax2.axis('off')\n",
    "            \n",
    "            # Format concept information as text\n",
    "            if processor.semantic_graph.has_node(concept):\n",
    "                node_data = processor.semantic_graph.nodes[concept]\n",
    "                \n",
    "                # Concept information\n",
    "                concept_info = [\n",
    "                    f\"Concept: {concept}\",\n",
    "                    f\"Category: {node_data.get('category', 'unknown')}\",\n",
    "                    f\"Language: {node_data.get('lang', 'unknown')}\",\n",
    "                    f\"Connected concepts: {subgraph.number_of_nodes() - 1}\",\n",
    "                    f\"Relationships: {subgraph.number_of_edges()}\",\n",
    "                ]\n",
    "                \n",
    "                # Display concept information\n",
    "                for i, line in enumerate(concept_info):\n",
    "                    ax2.text(0.05, 0.95 - (i * 0.05), line, fontsize=12, fontweight='bold' if i == 0 else 'normal')\n",
    "                \n",
    "                # Display example sentences if available\n",
    "                if concept_examples:\n",
    "                    ax2.text(0.05, 0.75, \"Example Usage:\", fontsize=12, fontweight='bold')\n",
    "                    for i, example in enumerate(concept_examples):\n",
    "                        wrapped_text = '\\n'.join(textwrap.wrap(example, width=40))\n",
    "                        ax2.text(0.05, 0.7 - (i * 0.1), wrapped_text, fontsize=10, fontstyle='italic')\n",
    "                \n",
    "                # Create a legend for relation types\n",
    "                legend_elements = []\n",
    "                for rel, color in edge_colors.items():\n",
    "                    if rel in relation_groups:\n",
    "                        style = edge_styles.get(rel, 'solid')\n",
    "                        legend_elements.append(\n",
    "                            plt.Line2D([0], [0], color=color, lw=2, linestyle=style, label=rel)\n",
    "                        )\n",
    "                \n",
    "                if legend_elements:\n",
    "                    ax2.legend(handles=legend_elements, title=\"Relation Types\", loc='lower left', \n",
    "                              bbox_to_anchor=(0, 0.3), fontsize=10)\n",
    "                \n",
    "                # Create a legend for languages\n",
    "                language_legend = []\n",
    "                for lang, color in language_colors.items():\n",
    "                    language_legend.append(\n",
    "                        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, \n",
    "                                 markersize=10, label=lang)\n",
    "                    )\n",
    "                \n",
    "                if language_legend:\n",
    "                    ax2.legend(handles=language_legend, title=\"Languages\", loc='lower right', \n",
    "                              bbox_to_anchor=(1, 0.3), fontsize=10)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Display additional relationship information\n",
    "            if len(edges_to_include) > 0:\n",
    "                print(\"Key Relationships:\")\n",
    "                for src, tgt, data in sorted(edges_to_include, key=lambda x: x[2].get('weight', 0.0), reverse=True)[:10]:\n",
    "                    rel = data.get('relation', 'unknown')\n",
    "                    weight = data.get('weight', 0.0)\n",
    "                    print(f\"  - {src} -{rel}-> {tgt} (weight: {weight:.2f})\")\n",
    "    \n",
    "    # Connect widgets to the change function\n",
    "    concept_dropdown.observe(on_change, names='value')\n",
    "    relation_dropdown.observe(on_change, names='value')\n",
    "    depth_slider.observe(on_change, names='value')\n",
    "    layout_dropdown.observe(on_change, names='value')\n",
    "    \n",
    "    # Create the UI layout\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HBox([concept_dropdown, relation_dropdown, depth_slider, layout_dropdown]),\n",
    "        output\n",
    "    ])\n",
    "    \n",
    "    # Trigger initial display\n",
    "    on_change(None)\n",
    "    \n",
    "    return ui\n",
    "\n",
    "# Create and display the enhanced interactive widget\n",
    "try:\n",
    "    import textwrap  # For wrapping long text in the info panel\n",
    "    enhanced_explorer = enhanced_concept_explorer(processor)\n",
    "    display(enhanced_explorer)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading enhanced concept explorer: {e}\")\n",
    "    print(\"Using standard concept explorer instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bc5c67",
   "metadata": {},
   "source": [
    "## 11. Enhanced Semantic Similarity Explorer (Upgraded Version)\n",
    "\n",
    "This is an upgraded version of the Semantic Similarity Explorer with improved visualizations and interactive features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48268fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164da26a4b10445a92723b5d1289cdfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Concept 1:', options=('a', 'ability', 'abwertend', 'accoun…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def enhanced_similarity_explorer(processor):\n",
    "    \"\"\"Create an enhanced interactive widget to explore semantic similarities with better visuals\"\"\"\n",
    "    # Get concepts that have vector representations\n",
    "    concepts = sorted(list(processor.concept_vectors.keys()))\n",
    "    \n",
    "    if not concepts:\n",
    "        print(\"No concept vectors found. Please ensure vectors were generated successfully.\")\n",
    "        return\n",
    "    \n",
    "    # Define the widget layout\n",
    "    concept1_dropdown = widgets.Dropdown(\n",
    "        options=concepts,\n",
    "        description='Concept 1:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    concept2_dropdown = widgets.Dropdown(\n",
    "        options=concepts,\n",
    "        description='Concept 2:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    num_similar_slider = widgets.IntSlider(\n",
    "        min=5,\n",
    "        max=30,\n",
    "        step=5,\n",
    "        value=15,\n",
    "        description='# of similar:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    viz_type_dropdown = widgets.Dropdown(\n",
    "        options=['Network', 'Heatmap', 'Radar', 'Venn'],\n",
    "        value='Network',\n",
    "        description='Visualization:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Define the output function\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    from scipy.spatial.distance import cosine\n",
    "    import matplotlib.patches as mpatches\n",
    "    from matplotlib_venn import venn2\n",
    "    import matplotlib.colors as mcolors\n",
    "    \n",
    "    def calculate_similarity(vec1, vec2):\n",
    "        \"\"\"Calculate cosine similarity between two vectors\"\"\"\n",
    "        return 1 - cosine(vec1, vec2)  # Convert distance to similarity\n",
    "    \n",
    "    def find_similar_concepts(concept, n=15):\n",
    "        \"\"\"Find the n most similar concepts to the given concept\"\"\"\n",
    "        if concept not in processor.concept_vectors:\n",
    "            return []\n",
    "        \n",
    "        concept_vec = processor.concept_vectors[concept]['vector']\n",
    "        similarities = []\n",
    "        \n",
    "        for c, data in processor.concept_vectors.items():\n",
    "            if c != concept:  # Skip self-comparison\n",
    "                sim = calculate_similarity(concept_vec, data['vector'])\n",
    "                similarities.append((c, sim))\n",
    "        \n",
    "        # Sort by similarity (descending)\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        return similarities[:n]\n",
    "    \n",
    "    def create_network_viz(concept1, concept2, similar1, similar2):\n",
    "        \"\"\"Create network visualization of semantic similarities\"\"\"\n",
    "        # Create graph\n",
    "        G = nx.Graph()\n",
    "        \n",
    "        # Add center nodes (main concepts)\n",
    "        G.add_node(concept1, type='main')\n",
    "        G.add_node(concept2, type='main')\n",
    "        \n",
    "        # Add edge between main concepts with their similarity\n",
    "        if concept1 in processor.concept_vectors and concept2 in processor.concept_vectors:\n",
    "            vec1 = processor.concept_vectors[concept1]['vector']\n",
    "            vec2 = processor.concept_vectors[concept2]['vector']\n",
    "            similarity = calculate_similarity(vec1, vec2)\n",
    "            G.add_edge(concept1, concept2, weight=similarity)\n",
    "        \n",
    "        # Add similar concepts as nodes and connect to their respective main concept\n",
    "        for c, sim in similar1:\n",
    "            G.add_node(c, type='similar1')\n",
    "            G.add_edge(concept1, c, weight=sim)\n",
    "        \n",
    "        for c, sim in similar2:\n",
    "            if c not in G:  # Not already added\n",
    "                G.add_node(c, type='similar2')\n",
    "                G.add_edge(concept2, c, weight=sim)\n",
    "            else:  # Node already exists, must be common to both\n",
    "                G.nodes[c]['type'] = 'common'\n",
    "                G.add_edge(concept2, c, weight=sim)\n",
    "        \n",
    "        # Prepare visualization\n",
    "        plt.figure(figsize=(14, 10), facecolor='#f0f0f0')\n",
    "        pos = nx.spring_layout(G, seed=42, k=0.3)  # k controls spacing\n",
    "        \n",
    "        # Define node colors by type\n",
    "        color_map = {\n",
    "            'main': '#3498db',     # Blue for main concepts\n",
    "            'similar1': '#e74c3c', # Red for similar to concept1\n",
    "            'similar2': '#2ecc71', # Green for similar to concept2\n",
    "            'common': '#f39c12'    # Orange for common concepts\n",
    "        }\n",
    "        \n",
    "        # Create node color list\n",
    "        node_colors = [color_map[G.nodes[n]['type']] for n in G.nodes()]\n",
    "        \n",
    "        # Calculate node sizes based on centrality or type\n",
    "        node_sizes = []\n",
    "        for n in G.nodes():\n",
    "            if G.nodes[n]['type'] == 'main':\n",
    "                node_sizes.append(800)  # Large for main concepts\n",
    "            elif G.nodes[n]['type'] == 'common':\n",
    "                node_sizes.append(500)  # Medium-large for common concepts\n",
    "            else:\n",
    "                node_sizes.append(300)  # Regular for other concepts\n",
    "        \n",
    "        # Calculate edge widths based on similarity\n",
    "        edge_widths = [2 * G[u][v]['weight'] for u, v in G.edges()]\n",
    "        \n",
    "        # Create curved edges for better visualization\n",
    "        curved_edges = [edge for edge in G.edges() if G.nodes[edge[0]]['type'] == 'main' and G.nodes[edge[1]]['type'] == 'main']\n",
    "        straight_edges = [edge for edge in G.edges() if edge not in curved_edges]\n",
    "        \n",
    "        # Draw curved edge between main concepts if it exists\n",
    "        if curved_edges:\n",
    "            nx.draw_networkx_edges(\n",
    "                G,\n",
    "                pos,\n",
    "                edgelist=curved_edges,\n",
    "                width=[4 * G[u][v]['weight'] for u, v in curved_edges],\n",
    "                alpha=0.7,\n",
    "                edge_color='#34495e',\n",
    "                connectionstyle='arc3,rad=0.3'\n",
    "            )\n",
    "        \n",
    "        # Draw straight edges\n",
    "        nx.draw_networkx_edges(\n",
    "            G,\n",
    "            pos,\n",
    "            edgelist=straight_edges,\n",
    "            width=[2 * G[u][v]['weight'] for u, v in straight_edges],\n",
    "            alpha=0.6,\n",
    "            edge_color='gray'\n",
    "        )\n",
    "        \n",
    "        # Draw nodes\n",
    "        nx.draw_networkx_nodes(\n",
    "            G,\n",
    "            pos,\n",
    "            node_size=node_sizes,\n",
    "            node_color=node_colors,\n",
    "            alpha=0.8,\n",
    "            edgecolors='#2c3e50',\n",
    "            linewidths=1\n",
    "        )\n",
    "        \n",
    "        # Draw node labels\n",
    "        nx.draw_networkx_labels(\n",
    "            G,\n",
    "            pos,\n",
    "            font_size=10,\n",
    "            font_weight='bold',\n",
    "            font_color='black'\n",
    "        )\n",
    "        \n",
    "        # Create legend\n",
    "        legend_elements = [\n",
    "            mpatches.Patch(color='#3498db', label=f'Main Concept'),\n",
    "            mpatches.Patch(color='#e74c3c', label=f'Similar to {concept1}'),\n",
    "            mpatches.Patch(color='#2ecc71', label=f'Similar to {concept2}'),\n",
    "            mpatches.Patch(color='#f39c12', label='Common to Both')\n",
    "        ]\n",
    "        plt.legend(handles=legend_elements, loc='upper right')\n",
    "        \n",
    "        plt.title(f\"Semantic Similarity Network: '{concept1}' and '{concept2}'\")\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def create_heatmap_viz(concept1, concept2, similar1, similar2):\n",
    "        \"\"\"Create heatmap visualization of semantic similarities\"\"\"\n",
    "        # Get all concepts to include in the heatmap\n",
    "        concepts_set = set([concept1, concept2])\n",
    "        for c, _ in similar1[:8]:  # Limit to top 8 for readability\n",
    "            concepts_set.add(c)\n",
    "        for c, _ in similar2[:8]:  # Limit to top 8 for readability\n",
    "            concepts_set.add(c)\n",
    "        \n",
    "        concepts_list = sorted(list(concepts_set))\n",
    "        n = len(concepts_list)\n",
    "        \n",
    "        # Create similarity matrix\n",
    "        sim_matrix = np.zeros((n, n))\n",
    "        for i, c1 in enumerate(concepts_list):\n",
    "            for j, c2 in enumerate(concepts_list):\n",
    "                if i == j:  # Self similarity is 1\n",
    "                    sim_matrix[i, j] = 1.0\n",
    "                elif c1 in processor.concept_vectors and c2 in processor.concept_vectors:\n",
    "                    vec1 = processor.concept_vectors[c1]['vector']\n",
    "                    vec2 = processor.concept_vectors[c2]['vector']\n",
    "                    sim_matrix[i, j] = calculate_similarity(vec1, vec2)\n",
    "        \n",
    "        # Create the heatmap\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        im = ax.imshow(sim_matrix, cmap='viridis')\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = ax.figure.colorbar(im, ax=ax)\n",
    "        cbar.ax.set_ylabel('Semantic Similarity', rotation=-90, va='bottom')\n",
    "        \n",
    "        # Show all ticks and label them with the respective list entries\n",
    "        ax.set_xticks(np.arange(n))\n",
    "        ax.set_yticks(np.arange(n))\n",
    "        ax.set_xticklabels(concepts_list)\n",
    "        ax.set_yticklabels(concepts_list)\n",
    "        \n",
    "        # Rotate the tick labels and set their alignment\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')\n",
    "        \n",
    "        # Highlight the main concepts with boxes\n",
    "        for i, concept in enumerate(concepts_list):\n",
    "            if concept == concept1 or concept == concept2:\n",
    "                ax.add_patch(plt.Rectangle((i-0.5, -0.5), 1, len(concepts_list), \n",
    "                                          fill=False, edgecolor='red', lw=2))\n",
    "                ax.add_patch(plt.Rectangle((-0.5, i-0.5), len(concepts_list), 1, \n",
    "                                          fill=False, edgecolor='red', lw=2))\n",
    "        \n",
    "        # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "        ax.set_title(f\"Semantic Similarity Heatmap: '{concept1}' and '{concept2}'\")\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def create_radar_viz(concept1, concept2, similar1, similar2):\n",
    "        \"\"\"Create radar chart visualization of semantic similarities\"\"\"\n",
    "        # Find common similar concepts\n",
    "        similar1_dict = dict(similar1)\n",
    "        similar2_dict = dict(similar2)\n",
    "        common_concepts = set(similar1_dict.keys()).intersection(set(similar2_dict.keys()))\n",
    "        \n",
    "        # If we have at least 3 common concepts, use them for the radar\n",
    "        # Otherwise, use top concepts from each\n",
    "        if len(common_concepts) >= 3:\n",
    "            radar_concepts = list(common_concepts)[:8]  # Limit to 8 for readability\n",
    "        else:\n",
    "            radar_concepts = []\n",
    "            # Alternately add concepts from each list\n",
    "            for i in range(min(8, max(len(similar1), len(similar2)))):\n",
    "                if i < len(similar1):\n",
    "                    radar_concepts.append(similar1[i][0])\n",
    "                if i < len(similar2) and similar2[i][0] not in radar_concepts:\n",
    "                    radar_concepts.append(similar2[i][0])\n",
    "                if len(radar_concepts) >= 8:\n",
    "                    break\n",
    "        \n",
    "        # Get similarities for both main concepts to each radar concept\n",
    "        sim_values1 = []\n",
    "        sim_values2 = []\n",
    "        concept1_vec = processor.concept_vectors[concept1]['vector']\n",
    "        concept2_vec = processor.concept_vectors[concept2]['vector']\n",
    "        \n",
    "        for c in radar_concepts:\n",
    "            if c in processor.concept_vectors:\n",
    "                c_vec = processor.concept_vectors[c]['vector']\n",
    "                sim1 = calculate_similarity(concept1_vec, c_vec)\n",
    "                sim2 = calculate_similarity(concept2_vec, c_vec)\n",
    "                sim_values1.append(sim1)\n",
    "                sim_values2.append(sim2)\n",
    "            else:\n",
    "                sim_values1.append(0)\n",
    "                sim_values2.append(0)\n",
    "        \n",
    "        # Set up the radar chart\n",
    "        angles = np.linspace(0, 2*np.pi, len(radar_concepts), endpoint=False)\n",
    "        # Close the polygon by appending the first angle again\n",
    "        angles = np.concatenate((angles, [angles[0]]))\n",
    "        sim_values1 = np.concatenate((sim_values1, [sim_values1[0]]))\n",
    "        sim_values2 = np.concatenate((sim_values2, [sim_values2[0]]))\n",
    "        radar_concepts = np.concatenate((radar_concepts, [radar_concepts[0]]))\n",
    "        \n",
    "        # Create the plot\n",
    "        fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(polar=True))\n",
    "        \n",
    "        # Plot the similarity values\n",
    "        ax.plot(angles, sim_values1, 'o-', linewidth=2, label=concept1, color='#e74c3c')\n",
    "        ax.fill(angles, sim_values1, alpha=0.25, color='#e74c3c')\n",
    "        ax.plot(angles, sim_values2, 'o-', linewidth=2, label=concept2, color='#3498db')\n",
    "        ax.fill(angles, sim_values2, alpha=0.25, color='#3498db')\n",
    "        \n",
    "        # Set the labels\n",
    "        ax.set_xticks(angles[:-1])\n",
    "        ax.set_xticklabels(radar_concepts[:-1], size=10)\n",
    "        \n",
    "        # Add gridlines and set their properties\n",
    "        ax.set_rgrids([0.2, 0.4, 0.6, 0.8, 1.0], angle=0, weight='black')\n",
    "        ax.set_ylim(0, 1)\n",
    "        \n",
    "        # Add a title and legend\n",
    "        ax.set_title(f\"Semantic Similarity Comparison: '{concept1}' vs '{concept2}'\")\n",
    "        ax.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def create_venn_viz(concept1, concept2, similar1, similar2):\n",
    "        \"\"\"Create a Venn diagram of similar concepts\"\"\"\n",
    "        # Get sets of similar concepts\n",
    "        similar1_set = set(c for c, _ in similar1)\n",
    "        similar2_set = set(c for c, _ in similar2)\n",
    "        \n",
    "        # Find the intersection\n",
    "        common_set = similar1_set.intersection(similar2_set)\n",
    "        \n",
    "        # Create Venn diagram\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        v = venn2([similar1_set, similar2_set], \n",
    "                 set_labels=[f\"{concept1} similar\", f\"{concept2} similar\"])\n",
    "        \n",
    "        # Customize colors\n",
    "        v.get_patch_by_id('10').set_color('#e74c3c')  # Red for concept1 only\n",
    "        v.get_patch_by_id('01').set_color('#3498db')  # Blue for concept2 only\n",
    "        v.get_patch_by_id('11').set_color('#f39c12')  # Orange for intersection\n",
    "        \n",
    "        # Customize labels\n",
    "        v.get_label_by_id('10').set_text(f\"{len(similar1_set - common_set)} concepts\")\n",
    "        v.get_label_by_id('01').set_text(f\"{len(similar2_set - common_set)} concepts\")\n",
    "        v.get_label_by_id('11').set_text(f\"{len(common_set)} concepts\")\n",
    "        \n",
    "        # Add title\n",
    "        plt.title(f\"Similar Concepts: '{concept1}' vs '{concept2}'\")\n",
    "        \n",
    "        # Add some common concepts as text\n",
    "        if common_set:\n",
    "            common_list = list(common_set)\n",
    "            common_str = \"Common concepts: \" + \", \".join(common_list[:5])\n",
    "            if len(common_list) > 5:\n",
    "                common_str += f\" and {len(common_list) - 5} more\"\n",
    "            plt.figtext(0.5, 0.01, common_str, ha='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def on_change(change):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            concept1 = concept1_dropdown.value\n",
    "            concept2 = concept2_dropdown.value\n",
    "            num_similar = num_similar_slider.value\n",
    "            viz_type = viz_type_dropdown.value\n",
    "            \n",
    "            # Calculate similarity between selected concepts\n",
    "            if concept1 in processor.concept_vectors and concept2 in processor.concept_vectors:\n",
    "                vec1 = processor.concept_vectors[concept1]['vector']\n",
    "                vec2 = processor.concept_vectors[concept2]['vector']\n",
    "                similarity = calculate_similarity(vec1, vec2)\n",
    "                \n",
    "                print(f\"Semantic similarity between '{concept1}' and '{concept2}': {similarity:.4f}\")\n",
    "                print(\"\\n\")\n",
    "            \n",
    "            # Find similar concepts for concept1\n",
    "            similar_to_concept1 = find_similar_concepts(concept1, num_similar)\n",
    "            \n",
    "            # Find similar concepts for concept2\n",
    "            similar_to_concept2 = find_similar_concepts(concept2, num_similar)\n",
    "            \n",
    "            # Find common similar concepts\n",
    "            similar1_set = {c for c, _ in similar_to_concept1}\n",
    "            similar2_set = {c for c, _ in similar_to_concept2}\n",
    "            common_concepts = similar1_set.intersection(similar2_set)\n",
    "            \n",
    "            # Create the requested visualization\n",
    "            if viz_type == 'Network':\n",
    "                create_network_viz(concept1, concept2, similar_to_concept1, similar_to_concept2)\n",
    "            elif viz_type == 'Heatmap':\n",
    "                create_heatmap_viz(concept1, concept2, similar_to_concept1, similar_to_concept2)\n",
    "            elif viz_type == 'Radar':\n",
    "                create_radar_viz(concept1, concept2, similar_to_concept1, similar_to_concept2)\n",
    "            else:  # Venn\n",
    "                create_venn_viz(concept1, concept2, similar_to_concept1, similar_to_concept2)\n",
    "                \n",
    "            # Print similar concepts for each main concept\n",
    "            print(f\"Top concepts similar to '{concept1}':\")\n",
    "            for c, sim in similar_to_concept1[:10]:  # Show top 10\n",
    "                status = \" (also similar to {concept2})\" if c in common_concepts else \"\"\n",
    "                print(f\"  - {c}: {sim:.4f}{status}\")\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            print(f\"Top concepts similar to '{concept2}':\")\n",
    "            for c, sim in similar_to_concept2[:10]:  # Show top 10\n",
    "                status = \" (also similar to {concept1})\" if c in common_concepts else \"\"\n",
    "                print(f\"  - {c}: {sim:.4f}{status}\")\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            # List common similar concepts\n",
    "            if common_concepts:\n",
    "                print(f\"Common similar concepts: {', '.join(sorted(common_concepts))}\")\n",
    "                print(f\"Total: {len(common_concepts)} common concepts\")\n",
    "            else:\n",
    "                print(\"No common similar concepts found.\")\n",
    "    \n",
    "    # Connect widgets to the change function\n",
    "    concept1_dropdown.observe(on_change, names='value')\n",
    "    concept2_dropdown.observe(on_change, names='value')\n",
    "    num_similar_slider.observe(on_change, names='value')\n",
    "    viz_type_dropdown.observe(on_change, names='value')\n",
    "    \n",
    "    # Create the UI layout\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HBox([concept1_dropdown, concept2_dropdown, num_similar_slider, viz_type_dropdown]),\n",
    "        output\n",
    "    ])\n",
    "    \n",
    "    # Set different initial values for dropdowns\n",
    "    if len(concepts) > 1:\n",
    "        concept1_dropdown.value = concepts[0]\n",
    "        concept2_dropdown.value = concepts[1]\n",
    "    \n",
    "    # Trigger initial display\n",
    "    on_change(None)\n",
    "    \n",
    "    return ui\n",
    "\n",
    "# Create and display the enhanced interactive widget\n",
    "try:\n",
    "    # Try to import necessary packages for enhanced visualization\n",
    "    import matplotlib.patches as mpatches\n",
    "    from matplotlib_venn import venn2\n",
    "    enhanced_similarity_widget = enhanced_similarity_explorer(processor)\n",
    "    display(enhanced_similarity_widget)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading enhanced similarity explorer: {e}\")\n",
    "    print(\"Using standard similarity explorer instead.\")\n",
    "    # Fall back to standard similarity explorer\n",
    "    similarity_widget = similarity_explorer(processor)\n",
    "    display(similarity_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d4137",
   "metadata": {},
   "source": [
    "## 12. Enhanced Relation Type Explorer (Upgraded Version)\n",
    "\n",
    "This is an upgraded version of the Relation Type Explorer with improved visual design and interactive features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8853cbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379225e1b8914a26ac47c9f810b9203d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Relation Type:', options=('Antonym', 'AtLocation', 'Capabl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def enhanced_relation_explorer(processor):\n",
    "    \"\"\"Create an enhanced interactive widget to explore relation types with better visuals\"\"\"\n",
    "    # Get all relation types from the graph\n",
    "    relation_types = sorted(list(processor.relation_types))\n",
    "    \n",
    "    if not relation_types:\n",
    "        print(\"No relation types found in the graph. Please ensure data processing was successful.\")\n",
    "        return\n",
    "    \n",
    "    # Define the widget layout\n",
    "    relation_dropdown = widgets.Dropdown(\n",
    "        options=relation_types,\n",
    "        description='Relation Type:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    max_examples_slider = widgets.IntSlider(\n",
    "        min=5,\n",
    "        max=30,\n",
    "        step=5,\n",
    "        value=15,\n",
    "        description='Max Examples:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    language_dropdown = widgets.Dropdown(\n",
    "        options=['All', 'en', 'de'],\n",
    "        value='All',\n",
    "        description='Language:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    layout_dropdown = widgets.Dropdown(\n",
    "        options=['force', 'circular', 'hierarchical'],\n",
    "        value='force',\n",
    "        description='Layout:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Define the output function\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def on_change(change):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            relation = relation_dropdown.value\n",
    "            max_examples = max_examples_slider.value\n",
    "            language = language_dropdown.value\n",
    "            layout_style = layout_dropdown.value\n",
    "            \n",
    "            # Find all edges with the selected relation type\n",
    "            examples = []\n",
    "            for src, tgt, data in processor.semantic_graph.edges(data=True):\n",
    "                if data.get('relation', '') == relation:\n",
    "                    # Filter by language if specified\n",
    "                    if language != 'All':\n",
    "                        src_lang = processor.semantic_graph.nodes[src].get('lang', 'unknown')\n",
    "                        tgt_lang = processor.semantic_graph.nodes[tgt].get('lang', 'unknown')\n",
    "                        if src_lang != language and tgt_lang != language:\n",
    "                            continue\n",
    "                            \n",
    "                    examples.append((src, tgt, data.get('weight', 0.0)))\n",
    "            \n",
    "            # Sort by weight and take top examples\n",
    "            examples.sort(key=lambda x: x[2], reverse=True)\n",
    "            top_examples = examples[:max_examples]\n",
    "            \n",
    "            # Display information\n",
    "            print(f\"Relation Type: {relation}\")\n",
    "            print(f\"Total Occurrences: {len(examples)}\")\n",
    "            print(f\"Language Filter: {language}\")\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            if top_examples:\n",
    "                # Create a subgraph for visualization\n",
    "                subgraph = nx.DiGraph()\n",
    "                \n",
    "                # Add nodes and edges\n",
    "                for src, tgt, weight in top_examples:\n",
    "                    if processor.semantic_graph.has_node(src) and processor.semantic_graph.has_node(tgt):\n",
    "                        # Add nodes with their attributes\n",
    "                        src_attrs = processor.semantic_graph.nodes[src]\n",
    "                        tgt_attrs = processor.semantic_graph.nodes[tgt]\n",
    "                        \n",
    "                        subgraph.add_node(src, **src_attrs)\n",
    "                        subgraph.add_node(tgt, **tgt_attrs)\n",
    "                        \n",
    "                        # Add edge with weight and relation type\n",
    "                        subgraph.add_edge(src, tgt, relation=relation, weight=weight)\n",
    "                \n",
    "                if subgraph.number_of_nodes() > 0:\n",
    "                    # Create figure for visualization\n",
    "                    fig = plt.figure(figsize=(14, 10), facecolor='#f8f9fa')\n",
    "                    \n",
    "                    # Create visualization based on layout style\n",
    "                    if layout_style == 'force':\n",
    "                        pos = nx.spring_layout(subgraph, k=0.3, seed=42)\n",
    "                    elif layout_style == 'circular':\n",
    "                        pos = nx.circular_layout(subgraph)\n",
    "                    else:  # hierarchical\n",
    "                        try:\n",
    "                            # Try to create a hierarchical layout\n",
    "                            pos = nx.multipartite_layout(subgraph, subset_key='lang')\n",
    "                        except:\n",
    "                            # Fall back to spring layout if hierarchical fails\n",
    "                            pos = nx.spring_layout(subgraph, k=0.3, seed=42)\n",
    "                            print(\"Hierarchical layout failed, falling back to force layout.\")\n",
    "                    \n",
    "                    # Define node colors by language\n",
    "                    language_colors = {\n",
    "                        'en': '#3498db',  # Blue for English\n",
    "                        'de': '#e74c3c',  # Red for German\n",
    "                        'unknown': '#95a5a6'  # Gray for unknown\n",
    "                    }\n",
    "                    \n",
    "                    # Create node color list\n",
    "                    node_colors = [language_colors.get(subgraph.nodes[n].get('lang', 'unknown'), '#95a5a6') \n",
    "                                   for n in subgraph.nodes()]\n",
    "                    \n",
    "                    # Calculate node sizes based on degree centrality\n",
    "                    centrality = nx.degree_centrality(subgraph)\n",
    "                    node_sizes = [300 + 1000 * centrality[n] for n in subgraph.nodes()]\n",
    "                    \n",
    "                    # Calculate edge widths based on weight\n",
    "                    edge_widths = [0.5 + 3 * subgraph.edges[u, v]['weight'] for u, v in subgraph.edges()]\n",
    "                    \n",
    "                    # Draw the nodes\n",
    "                    nx.draw_networkx_nodes(\n",
    "                        subgraph,\n",
    "                        pos,\n",
    "                        node_size=node_sizes,\n",
    "                        node_color=node_colors,\n",
    "                        alpha=0.8,\n",
    "                        edgecolors='#2c3e50',\n",
    "                        linewidths=1\n",
    "                    )\n",
    "                    \n",
    "                    # Draw the edges with arrows\n",
    "                    nx.draw_networkx_edges(\n",
    "                        subgraph,\n",
    "                        pos,\n",
    "                        width=edge_widths,\n",
    "                        alpha=0.7,\n",
    "                        edge_color='#34495e',\n",
    "                        arrows=True,\n",
    "                        arrowsize=20,\n",
    "                        arrowstyle='-|>',\n",
    "                        connectionstyle='arc3,rad=0.1'\n",
    "                    )\n",
    "                    \n",
    "                    # Draw node labels\n",
    "                    nx.draw_networkx_labels(\n",
    "                        subgraph,\n",
    "                        pos,\n",
    "                        font_size=10,\n",
    "                        font_weight='bold',\n",
    "                        font_color='black'\n",
    "                    )\n",
    "                    \n",
    "                    # Add title\n",
    "                    plt.title(f\"Examples of '{relation}' Relationships\", size=16)\n",
    "                    \n",
    "                    # Add language legend\n",
    "                    legend_elements = []\n",
    "                    for lang, color in language_colors.items():\n",
    "                        if any(subgraph.nodes[n].get('lang', 'unknown') == lang for n in subgraph.nodes()):\n",
    "                            legend_elements.append(\n",
    "                                plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color,\n",
    "                                         markersize=10, label=lang)\n",
    "                            )\n",
    "                    plt.legend(handles=legend_elements, title=\"Languages\", loc='upper right')\n",
    "                    \n",
    "                    plt.axis('off')\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                    \n",
    "                # Display example relations in a visually appealing format\n",
    "                print(f\"Top {len(top_examples)} Examples:\")\n",
    "                for i, (src, tgt, weight) in enumerate(top_examples):\n",
    "                    src_lang = processor.semantic_graph.nodes[src].get('lang', 'unknown')\n",
    "                    tgt_lang = processor.semantic_graph.nodes[tgt].get('lang', 'unknown')\n",
    "                    print(f\"  {i+1}. {src} ({src_lang}) —[{relation}]→ {tgt} ({tgt_lang}) [weight: {weight:.2f}]\")\n",
    "                \n",
    "                # Display relation statistics\n",
    "                print(\"\\nRelation Statistics:\")\n",
    "                print(f\"  - Average weight: {sum(w for _, _, w in top_examples)/len(top_examples):.2f}\")\n",
    "                \n",
    "                # Count language combinations\n",
    "                lang_combos = {}\n",
    "                for src, tgt, _ in top_examples:\n",
    "                    src_lang = processor.semantic_graph.nodes[src].get('lang', 'unknown')\n",
    "                    tgt_lang = processor.semantic_graph.nodes[tgt].get('lang', 'unknown')\n",
    "                    combo = f\"{src_lang}-{tgt_lang}\"\n",
    "                    lang_combos[combo] = lang_combos.get(combo, 0) + 1\n",
    "                \n",
    "                print(\"  - Language combinations:\")\n",
    "                for combo, count in lang_combos.items():\n",
    "                    print(f\"    * {combo}: {count} instances\")\n",
    "            else:\n",
    "                print(\"No examples found. Try changing the language filter or relation type.\")\n",
    "    \n",
    "    # Connect widgets to the change function\n",
    "    relation_dropdown.observe(on_change, names='value')\n",
    "    max_examples_slider.observe(on_change, names='value')\n",
    "    language_dropdown.observe(on_change, names='value')\n",
    "    layout_dropdown.observe(on_change, names='value')\n",
    "    \n",
    "    # Create the UI layout\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HBox([relation_dropdown, max_examples_slider, language_dropdown, layout_dropdown]),\n",
    "        output\n",
    "    ])\n",
    "    \n",
    "    # Trigger initial display\n",
    "    on_change(None)\n",
    "    \n",
    "    return ui\n",
    "\n",
    "# Create and display the enhanced interactive widget\n",
    "enhanced_relation_widget = enhanced_relation_explorer(processor)\n",
    "display(enhanced_relation_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2718ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
