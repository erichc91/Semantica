{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd83624a",
   "metadata": {},
   "source": [
    "# Optimized Interactive ConceptNet Visualization\n",
    "\n",
    "This notebook demonstrates a high-performance visualization of ConceptNet semantic relationships. We'll use our optimized preprocessing pipeline to load data efficiently and render interactive visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c443972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU libraries not available. Using CPU processing instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        </script>\n",
       "        <script type=\"module\">import \"https://cdn.plot.ly/plotly-3.0.1.min\"</script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project modules\n",
    "sys.path.append('../Py Scripts')\n",
    "from conceptnet_processor_v3 import ConceptNetStreamProcessor\n",
    "\n",
    "# Try to import GPU libraries, but continue if not available\n",
    "GPU_AVAILABLE = False\n",
    "try:\n",
    "    import cudf\n",
    "    import cugraph\n",
    "    import cupy as cp\n",
    "    from pycuda import driver\n",
    "    import pycuda.autoinit\n",
    "    print(f\"GPU: {driver.Device(0).name()}\")\n",
    "    print(f\"CUDA Version: {driver.get_version()}\")\n",
    "    GPU_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"GPU libraries not available. Using CPU processing instead.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing GPU: {e}. Using CPU processing instead.\")\n",
    "\n",
    "# Interactive visualization\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fbf34f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GPU Diagnostics ===\n",
      "\n",
      "-- CUDA Status --\n",
      "PyTorch not available\n",
      "PyCUDA error: No module named 'pycuda'\n",
      "RAPIDS error: No module named 'cudf'\n"
     ]
    }
   ],
   "source": [
    "def check_gpu_status():\n",
    "    \"\"\"Comprehensive GPU diagnostic function\"\"\"\n",
    "    print(\"=== GPU Diagnostics ===\")\n",
    "    \n",
    "    # Check CUDA availability via different libraries\n",
    "    print(\"\\n-- CUDA Status --\")\n",
    "    try:\n",
    "        import torch\n",
    "        print(f\"PyTorch CUDA available: {torch.cuda.is_available()}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"PyTorch: {torch.cuda.get_device_name(0)}\")\n",
    "            print(f\"Memory allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "            print(f\"Memory reserved: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "    except ImportError:\n",
    "        print(\"PyTorch not available\")\n",
    "    \n",
    "    try:\n",
    "        import pycuda.driver as cuda\n",
    "        cuda.init()\n",
    "        print(f\"PyCUDA device count: {cuda.Device.count()}\")\n",
    "        for i in range(cuda.Device.count()):\n",
    "            device = cuda.Device(i)\n",
    "            props = device.get_attributes()\n",
    "            print(f\"  Device {i}: {device.name()}\")\n",
    "            print(f\"    Memory: {device.total_memory() / 1e9:.2f} GB\")\n",
    "            print(f\"    Compute Capability: {props[cuda.device_attribute.COMPUTE_CAPABILITY_MAJOR]}.{props[cuda.device_attribute.COMPUTE_CAPABILITY_MINOR]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"PyCUDA error: {e}\")\n",
    "    \n",
    "    try:\n",
    "        import cudf\n",
    "        print(\"\\n-- RAPIDS Status --\")\n",
    "        print(f\"cuDF version: {cudf.__version__}\")\n",
    "        # Test with simple dataframe operation\n",
    "        test_df = cudf.DataFrame({'a': [1, 2, 3]})\n",
    "        print(f\"cuDF test: {test_df.a.sum()} (should be 6)\")\n",
    "    except Exception as e:\n",
    "        print(f\"RAPIDS error: {e}\")\n",
    "\n",
    "# Call this at the beginning of your notebook\n",
    "check_gpu_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf1e1fc",
   "metadata": {},
   "source": [
    "## 1. Optimized Data Loading\n",
    "We'll use our efficient data processor to load a manageable sample of ConceptNet data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce780b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask loading failed with error: 'DataFrame' object has no attribute 'compute'\n",
      "Falling back to pandas for data loading\n",
      "Dask loading failed with error: 'DataFrame' object has no attribute 'compute'\n",
      "Falling back to pandas for data loading\n",
      "Loaded 200000 English assertions with 32548 source concepts\n",
      "Loaded 200000 German assertions with 79021 source concepts\n",
      "After filtering: 17468 English and 3085 German assertions\n"
     ]
    }
   ],
   "source": [
    "# Initialize our optimized processor\n",
    "processor = ConceptNetStreamProcessor(\n",
    "    input_dir='../Data/Input',\n",
    "    output_dir='../Data/Processed'\n",
    ")\n",
    "\n",
    "# Load a small sample for testing visualization\n",
    "# For initial testing, we'll use a very small fraction\n",
    "sample_size = 1  # Start with 1% for speed\n",
    "max_concepts = 500  # Limit number of unique concepts\n",
    "min_weight = 1.5     # Higher threshold for stronger relationships\n",
    "\n",
    "# Load English data\n",
    "english_df = processor.load_processed_data(\n",
    "    lang='en', \n",
    "    sample_size=sample_size, \n",
    "    max_rows=200_000\n",
    ")\n",
    "\n",
    "# Load German data\n",
    "german_df = processor.load_processed_data(\n",
    "    lang='de', \n",
    "    sample_size=sample_size,\n",
    "    max_rows=200_000\n",
    ")\n",
    "\n",
    "# Display statistics\n",
    "print(f\"Loaded {len(english_df)} English assertions with {english_df['clean_start'].nunique()} source concepts\")\n",
    "print(f\"Loaded {len(german_df)} German assertions with {german_df['clean_start'].nunique()} source concepts\")\n",
    "\n",
    "# Filter by weight for better visualization\n",
    "english_df = english_df[english_df['weight'] >= min_weight]\n",
    "german_df = german_df[german_df['weight'] >= min_weight]\n",
    "\n",
    "print(f\"After filtering: {len(english_df)} English and {len(german_df)} German assertions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a362e049",
   "metadata": {},
   "source": [
    "## 2. Graph Construction\n",
    "Now we'll construct semantic graphs from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba8c301b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building English semantic graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17468/17468 [00:00<00:00, 69878.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building German semantic graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3085/3085 [00:00<00:00, 63922.40it/s]\n"
     ]
    }
   ],
   "source": [
    "def build_graph(df, weight_col='weight'):\n",
    "    \"\"\"Build a graph from ConceptNet dataframe\"\"\"\n",
    "    # Create NetworkX graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add edges with attributes\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        G.add_edge(\n",
    "            row['clean_start'], \n",
    "            row['clean_end'], \n",
    "            weight=row[weight_col],\n",
    "            relation=row['relation']\n",
    "        )\n",
    "    return G\n",
    "\n",
    "# Build graphs for both languages\n",
    "print(\"Building English semantic graph...\")\n",
    "english_graph = build_graph(english_df)\n",
    "\n",
    "print(\"Building German semantic graph...\")\n",
    "german_graph = build_graph(german_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8cd2d4",
   "metadata": {},
   "source": [
    "## 3. Graph Layout Computation\n",
    "Calculate optimal positions for nodes using force-directed layout algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edceb155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing English semantic layout...\n",
      "Computing layout for graph with 4809 nodes and 4467 edges...\n",
      "Computing German semantic layout...\n",
      "Computing layout for graph with 3044 nodes and 2997 edges...\n"
     ]
    }
   ],
   "source": [
    "def compute_layout(graph, iterations=500):\n",
    "    \"\"\"Compute force-directed layout for the graph\"\"\"\n",
    "    # Compute layout using NetworkX\n",
    "    print(f\"Computing layout for graph with {len(graph.nodes())} nodes and {len(graph.edges())} edges...\")\n",
    "    pos = nx.spring_layout(graph, k=0.15, iterations=iterations, seed=42)\n",
    "    \n",
    "    # Convert to DataFrame for easier processing later\n",
    "    layout_df = pd.DataFrame({\n",
    "        'node': list(pos.keys()),\n",
    "        'x': [pos[node][0] for node in pos],\n",
    "        'y': [pos[node][1] for node in pos]\n",
    "    })\n",
    "    \n",
    "    return layout_df\n",
    "\n",
    "# Compute layouts\n",
    "print(\"Computing English semantic layout...\")\n",
    "english_layout = compute_layout(english_graph)\n",
    "\n",
    "print(\"Computing German semantic layout...\")\n",
    "german_layout = compute_layout(german_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeab1635",
   "metadata": {},
   "source": [
    "## 4. Interactive Visualization\n",
    "Create an interactive visualization for exploring the semantic networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86bdf505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing approximate betweenness centrality...\n",
      "Computing approximate betweenness centrality...\n"
     ]
    }
   ],
   "source": [
    "class SemanticVisualizer:\n",
    "    \"\"\"Interactive semantic network visualizer\"\"\"\n",
    "    \n",
    "    def __init__(self, graph, layout, title=\"Semantic Network\", height=800, width=1200):\n",
    "        self.graph = graph\n",
    "        self.layout = layout\n",
    "        self.title = title\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.node_size_scale = 10\n",
    "        self.edge_width_scale = 0.5\n",
    "        self.selected_nodes = set()\n",
    "        \n",
    "        # Precompute node metrics for sizing\n",
    "        self._compute_node_metrics()\n",
    "        \n",
    "    def _compute_node_metrics(self):\n",
    "        \"\"\"Compute node metrics for sizing and coloring\"\"\"\n",
    "        # Calculate node degrees\n",
    "        self.node_degrees = dict(self.graph.degree())\n",
    "        \n",
    "        # Calculate centrality (use approximate betweenness for large graphs)\n",
    "        if len(self.graph) > 1000:\n",
    "            print(\"Computing approximate betweenness centrality...\")\n",
    "            self.node_betweenness = nx.betweenness_centrality(self.graph, k=min(100, len(self.graph)))\n",
    "        else:\n",
    "            print(\"Computing exact betweenness centrality...\")\n",
    "            self.node_betweenness = nx.betweenness_centrality(self.graph)\n",
    "        \n",
    "        # Create node dataframe\n",
    "        nodes = list(self.graph.nodes())\n",
    "        self.node_df = pd.DataFrame({\n",
    "            'node': nodes,\n",
    "            'degree': [self.node_degrees.get(n, 0) for n in nodes],\n",
    "            'betweenness': [self.node_betweenness.get(n, 0) for n in nodes]\n",
    "        })\n",
    "        \n",
    "        # Merge with layout\n",
    "        self.node_layout_df = pd.merge(self.layout, self.node_df, on='node', how='inner')\n",
    "        \n",
    "        # Create edges dataframe\n",
    "        edges = list(self.graph.edges(data=True))\n",
    "        self.edge_df = pd.DataFrame({\n",
    "            'source': [e[0] for e in edges],\n",
    "            'target': [e[1] for e in edges],\n",
    "            'weight': [e[2].get('weight', 1.0) for e in edges],\n",
    "            'relation': [e[2].get('relation', 'related') for e in edges]\n",
    "        })\n",
    "    \n",
    "    def render(self, show_labels=True, max_edges=5000, full_screen=False):\n",
    "        \"\"\"Render the interactive semantic graph visualization\n",
    "        \n",
    "        Args:\n",
    "            show_labels (bool): Whether to show node labels\n",
    "            max_edges (int): Maximum number of edges to display\n",
    "            full_screen (bool): Whether to render in full screen mode\n",
    "        \"\"\"\n",
    "        # Set dimensions based on display mode\n",
    "        if full_screen:\n",
    "            height = \"100vh\"  # 100% of viewport height\n",
    "            width = \"100%\"    # 100% of viewport width\n",
    "        else:\n",
    "            height = self.height\n",
    "            width = self.width\n",
    "            \n",
    "        # Limit number of edges for performance\n",
    "        if len(self.edge_df) > max_edges:\n",
    "            # Select edges with highest weights\n",
    "            edge_sample = self.edge_df.sort_values('weight', ascending=False).head(max_edges)\n",
    "        else:\n",
    "            edge_sample = self.edge_df\n",
    "            \n",
    "        # Create edge traces\n",
    "        edge_trace = []\n",
    "        \n",
    "        # Get coordinates for each edge\n",
    "        for _, edge in tqdm(edge_sample.iterrows(), total=len(edge_sample), desc=\"Creating edge traces\"):\n",
    "            source = edge['source']\n",
    "            target = edge['target']\n",
    "            relation = edge['relation']\n",
    "            weight = edge['weight']\n",
    "            \n",
    "            # Get node positions\n",
    "            source_pos = self.node_layout_df[self.node_layout_df['node'] == source]\n",
    "            target_pos = self.node_layout_df[self.node_layout_df['node'] == target]\n",
    "            \n",
    "            if len(source_pos) == 0 or len(target_pos) == 0:\n",
    "                continue\n",
    "                \n",
    "            x0, y0 = source_pos['x'].values[0], source_pos['y'].values[0]\n",
    "            x1, y1 = target_pos['x'].values[0], target_pos['y'].values[0]\n",
    "            \n",
    "            trace = go.Scatter(\n",
    "                x=[x0, x1, None],\n",
    "                y=[y0, y1, None],\n",
    "                mode='lines',\n",
    "                line=dict(\n",
    "                    width=weight * self.edge_width_scale,\n",
    "                    color='rgba(150,150,150,0.3)'\n",
    "                ),\n",
    "                hoverinfo='none',\n",
    "                showlegend=False\n",
    "            )\n",
    "            edge_trace.append(trace)\n",
    "        \n",
    "        # Create node trace\n",
    "        node_trace = go.Scatter(\n",
    "            x=self.node_layout_df['x'],\n",
    "            y=self.node_layout_df['y'],\n",
    "            mode='markers+text' if show_labels else 'markers',\n",
    "            text=self.node_layout_df['node'] if show_labels else None,\n",
    "            textposition='top center',\n",
    "            textfont=dict(size=10, color='black'),\n",
    "            marker=dict(\n",
    "                size=self.node_layout_df['degree'] * self.node_size_scale,\n",
    "                color=self.node_layout_df['betweenness'],\n",
    "                colorscale='Viridis',\n",
    "                line=dict(width=1, color='black'),\n",
    "                opacity=0.8,\n",
    "                showscale=True,\n",
    "                colorbar=dict(title='Centrality')\n",
    "            ),\n",
    "            hovertemplate=(\n",
    "                '<b>%{text}</b><br>'\n",
    "                'Degree: %{marker.size:.1f}<br>'\n",
    "                'Centrality: %{marker.color:.4f}'\n",
    "                '<extra></extra>'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Combine all traces\n",
    "        all_traces = edge_trace + [node_trace]\n",
    "        \n",
    "        # Create layout\n",
    "        layout = go.Layout(\n",
    "            title=dict(\n",
    "                text=self.title,\n",
    "                font=dict(size=24)\n",
    "            ),\n",
    "            showlegend=False,\n",
    "            hovermode='closest',\n",
    "            margin=dict(b=20, l=5, r=5, t=40),\n",
    "            height=height,\n",
    "            width=width,\n",
    "            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "            plot_bgcolor='rgba(240,240,240,1)',\n",
    "            dragmode='pan',\n",
    "            updatemenus=[\n",
    "                dict(\n",
    "                    type='buttons',\n",
    "                    showactive=False,\n",
    "                    buttons=[\n",
    "                        dict(\n",
    "                            label='Reset View',\n",
    "                            method='relayout',\n",
    "                            args=['xaxis.range', [None, None]]\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Create figure\n",
    "        fig = go.Figure(data=all_traces, layout=layout)\n",
    "        \n",
    "        # Add zoom capability\n",
    "        fig.update_layout(\n",
    "            newshape=dict(line_color='#ff0000'),\n",
    "            modebar=dict(\n",
    "                add=['drawrect', 'eraseshape', 'zoomIn', 'zoomOut', 'autoScale', 'resetScale']\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # For full screen, open in new browser tab\n",
    "        if full_screen:\n",
    "            import tempfile\n",
    "            import webbrowser\n",
    "            import os\n",
    "            \n",
    "            # Create a temporary HTML file\n",
    "            temp_dir = tempfile.gettempdir()\n",
    "            temp_path = os.path.join(temp_dir, f\"semantic_viz_{hash(self.title)}.html\")\n",
    "            \n",
    "            # Write the figure to the temporary file with full screen settings\n",
    "            fig.write_html(\n",
    "                temp_path,\n",
    "                full_html=True,\n",
    "                include_plotlyjs='cdn',\n",
    "                config={\n",
    "                    'displayModeBar': True,\n",
    "                    'scrollZoom': True,\n",
    "                    'responsive': True\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Open the file in the default browser\n",
    "            webbrowser.open('file://' + temp_path, new=2)\n",
    "            \n",
    "            # Return a message\n",
    "            return HTML(f\"<p>Visualization opened in a new browser tab. If it didn't open automatically, <a href='file://{temp_path}' target='_blank'>click here</a>.</p>\")\n",
    "        \n",
    "        return fig\n",
    "\n",
    "# Create the visualizers\n",
    "english_vis = SemanticVisualizer(\n",
    "    english_graph, \n",
    "    english_layout, \n",
    "    title=\"English Semantic Network\",\n",
    "    height=900,\n",
    "    width=1200\n",
    ")\n",
    "\n",
    "german_vis = SemanticVisualizer(\n",
    "    german_graph, \n",
    "    german_layout, \n",
    "    title=\"German Semantic Network\",\n",
    "    height=900,\n",
    "    width=1200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bb68b8",
   "metadata": {},
   "source": [
    "## 5. Display the Interactive Visualizations\n",
    "Let's render our visualizations and explore the semantic networks interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c666d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render English visualization\n",
    "english_fig = english_vis.render(show_labels=True, max_edges=3000)\n",
    "english_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0071844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render German visualization\n",
    "german_fig = german_vis.render(show_labels=True, max_edges=3000)\n",
    "german_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d771bf2d",
   "metadata": {},
   "source": [
    "## 6. Interactive Multi-Language Semantic Explorer\n",
    "Let's create an interactive tool that allows for exploring cross-language semantic relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f7d33ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing approximate betweenness centrality...\n",
      "Computing approximate betweenness centrality...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec9b0a9f30549639b7eabed96d4e5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='', description='Search:', placeholder='Search for a concept'), Radio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class SemanticExplorer:\n",
    "    \"\"\"Interactive multi-language semantic explorer\"\"\"\n",
    "    \n",
    "    def __init__(self, en_graph, en_layout, de_graph, de_layout):\n",
    "        self.en_graph = en_graph\n",
    "        self.en_layout = en_layout\n",
    "        self.de_graph = de_graph\n",
    "        self.de_layout = de_layout\n",
    "        \n",
    "        # Create visualizers\n",
    "        self.en_vis = SemanticVisualizer(en_graph, en_layout, title=\"English Semantic Network\")\n",
    "        self.de_vis = SemanticVisualizer(de_graph, de_layout, title=\"German Semantic Network\")\n",
    "        \n",
    "        # Create UI elements\n",
    "        self._setup_ui()\n",
    "        \n",
    "    def _setup_ui(self):\n",
    "        \"\"\"Set up interactive UI elements\"\"\"\n",
    "        self.search_input = widgets.Text(\n",
    "            value='',\n",
    "            placeholder='Search for a concept',\n",
    "            description='Search:',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        self.language_selector = widgets.RadioButtons(\n",
    "            options=['English', 'German', 'Both'],\n",
    "            value='Both',\n",
    "            description='Language:',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        self.depth_slider = widgets.IntSlider(\n",
    "            value=1,\n",
    "            min=1,\n",
    "            max=3,\n",
    "            step=1,\n",
    "            description='Network Depth:',\n",
    "            disabled=False,\n",
    "            continuous_update=False,\n",
    "            orientation='horizontal',\n",
    "            readout=True\n",
    "        )\n",
    "        \n",
    "        self.min_weight_slider = widgets.FloatSlider(\n",
    "            value=1.5,\n",
    "            min=1.0,\n",
    "            max=5.0,\n",
    "            step=0.1,\n",
    "            description='Min Weight:',\n",
    "            disabled=False,\n",
    "            continuous_update=False,\n",
    "            orientation='horizontal',\n",
    "            readout=True\n",
    "        )\n",
    "        \n",
    "        self.show_labels_checkbox = widgets.Checkbox(\n",
    "            value=True,\n",
    "            description='Show Labels',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        self.fullscreen_checkbox = widgets.Checkbox(\n",
    "            value=False,\n",
    "            description='Open in Full Screen',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        self.search_button = widgets.Button(\n",
    "            description='Explore',\n",
    "            disabled=False,\n",
    "            button_style='primary',\n",
    "            tooltip='Click to explore the semantic network'\n",
    "        )\n",
    "        \n",
    "        self.output = widgets.Output()\n",
    "        \n",
    "        # Wire up events\n",
    "        self.search_button.on_click(self._on_search_clicked)\n",
    "        \n",
    "    def show(self):\n",
    "        \"\"\"Display the interactive explorer\"\"\"\n",
    "        # Create layout\n",
    "        top_controls = widgets.HBox([self.search_input, self.language_selector])\n",
    "        bottom_controls = widgets.HBox([\n",
    "            self.depth_slider, \n",
    "            self.min_weight_slider, \n",
    "            self.show_labels_checkbox, \n",
    "            self.fullscreen_checkbox,\n",
    "            self.search_button\n",
    "        ])\n",
    "        \n",
    "        # Display the UI\n",
    "        display(widgets.VBox([top_controls, bottom_controls, self.output]))\n",
    "        \n",
    "    def _on_search_clicked(self, b):\n",
    "        \"\"\"Handle search button click\"\"\"\n",
    "        with self.output:\n",
    "            clear_output()\n",
    "            concept = self.search_input.value.lower().strip()\n",
    "            \n",
    "            if not concept:\n",
    "                print(\"Please enter a concept to search for.\")\n",
    "                return\n",
    "                \n",
    "            print(f\"Exploring concept: {concept}\")\n",
    "            \n",
    "            # Get parameters\n",
    "            language = self.language_selector.value\n",
    "            depth = self.depth_slider.value\n",
    "            min_weight = self.min_weight_slider.value\n",
    "            show_labels = self.show_labels_checkbox.value\n",
    "            full_screen = self.fullscreen_checkbox.value\n",
    "            \n",
    "            # Generate visualizations based on selection\n",
    "            if language in ['English', 'Both']:\n",
    "                print(\"Generating English visualization...\")\n",
    "                en_fig = self._generate_subgraph_viz(\n",
    "                    concept, \n",
    "                    self.en_vis, \n",
    "                    depth, \n",
    "                    min_weight, \n",
    "                    show_labels,\n",
    "                    full_screen,\n",
    "                    title=f\"English Semantic Network for '{concept}'\"\n",
    "                )\n",
    "                if en_fig:\n",
    "                    display(en_fig)\n",
    "                else:\n",
    "                    print(f\"Concept '{concept}' not found in English network.\")\n",
    "            \n",
    "            if language in ['German', 'Both'] and not (full_screen and language == 'Both'):\n",
    "                print(\"Generating German visualization...\")\n",
    "                de_fig = self._generate_subgraph_viz(\n",
    "                    concept, \n",
    "                    self.de_vis, \n",
    "                    depth, \n",
    "                    min_weight, \n",
    "                    show_labels,\n",
    "                    full_screen,\n",
    "                    title=f\"German Semantic Network for '{concept}'\"\n",
    "                )\n",
    "                if de_fig:\n",
    "                    display(de_fig)\n",
    "                else:\n",
    "                    print(f\"Concept '{concept}' not found in German network.\")\n",
    "    \n",
    "    def _generate_subgraph_viz(self, concept, visualizer, depth, min_weight, show_labels, full_screen=False, title=\"\"):\n",
    "        \"\"\"Generate a subgraph visualization for a concept\"\"\"\n",
    "        # Check if concept exists in the graph nodes\n",
    "        if concept not in visualizer.graph.nodes():\n",
    "            return None\n",
    "            \n",
    "        # Extract subgraph using BFS\n",
    "        nodes_to_include = {concept}\n",
    "        frontier = {concept}\n",
    "        \n",
    "        # BFS to depth\n",
    "        for _ in range(depth):\n",
    "            new_frontier = set()\n",
    "            for node in frontier:\n",
    "                neighbors = set(n for n in visualizer.graph.neighbors(node))\n",
    "                new_frontier.update(neighbors)\n",
    "            frontier = new_frontier - nodes_to_include\n",
    "            nodes_to_include.update(frontier)\n",
    "        \n",
    "        # Create subgraph\n",
    "        subgraph = visualizer.graph.subgraph(nodes_to_include)\n",
    "        \n",
    "        # Filter edges by weight\n",
    "        edges_to_remove = []\n",
    "        for u, v, data in subgraph.edges(data=True):\n",
    "            if data.get('weight', 0) < min_weight:\n",
    "                edges_to_remove.append((u, v))\n",
    "        \n",
    "        # Remove edges below weight threshold\n",
    "        for edge in edges_to_remove:\n",
    "            subgraph.remove_edge(*edge)\n",
    "        \n",
    "        # Extract layout for subgraph\n",
    "        nodes_in_subgraph = set(subgraph.nodes())\n",
    "        sub_layout = visualizer.layout[visualizer.layout['node'].isin(nodes_in_subgraph)].copy()\n",
    "        \n",
    "        # Create visualization\n",
    "        sub_vis = SemanticVisualizer(subgraph, sub_layout, title=title)\n",
    "        \n",
    "        # Ensure node metrics are computed\n",
    "        sub_vis._compute_node_metrics()\n",
    "        \n",
    "        # Render with full screen option if requested\n",
    "        return sub_vis.render(show_labels=show_labels, full_screen=full_screen)\n",
    "\n",
    "# Create the explorer\n",
    "explorer = SemanticExplorer(english_graph, english_layout, german_graph, german_layout)\n",
    "explorer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97681d49",
   "metadata": {},
   "source": [
    "## 7. Semantic Path Finder\n",
    "\n",
    "Let's implement a simple semantic path finder that can discover relationships between concepts. This is useful for understanding how different concepts relate to each other through intermediate relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc87a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Semantic Path Finder:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ab34eb4ba74ed1953fbd7595fd2b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Label(value='Source Concept:'), Text(value='', description='Sourc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "German Semantic Path Finder:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ddd485760c41698a7120293e01f8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Label(value='Source Concept:'), Text(value='', description='Sourc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class SemanticPathFinder:\n",
    "    \"\"\"Find and visualize semantic paths between concepts\"\"\"\n",
    "    \n",
    "    def __init__(self, graph, max_suggestions=100):\n",
    "        self.graph = graph\n",
    "        self.max_suggestions = max_suggestions\n",
    "        self._setup_ui()\n",
    "    \n",
    "    def _setup_ui(self):\n",
    "        \"\"\"Set up the path finder UI with better concept selection\"\"\"\n",
    "        # Create a sorted list of all concepts (nodes) in the graph\n",
    "        all_concepts = sorted(list(self.graph.nodes()))\n",
    "        self.top_concepts = self._get_top_concepts(20)  # Get 20 most connected concepts\n",
    "        \n",
    "        # Source concept search box with auto-complete\n",
    "        self.source_search = widgets.Text(\n",
    "            value='',\n",
    "            placeholder='Search for source concept',\n",
    "            description='Source:',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        # Target concept search box with auto-complete\n",
    "        self.target_search = widgets.Text(\n",
    "            value='',\n",
    "            placeholder='Search for target concept',\n",
    "            description='Target:',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        # Dropdown for source selection (will be populated based on search)\n",
    "        self.source_dropdown = widgets.Dropdown(\n",
    "            options=self.top_concepts,\n",
    "            description='Select:',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        # Dropdown for target selection (will be populated based on search)\n",
    "        self.target_dropdown = widgets.Dropdown(\n",
    "            options=self.top_concepts,\n",
    "            description='Select:',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        # Max path length slider\n",
    "        self.max_path_length = widgets.IntSlider(\n",
    "            value=3,\n",
    "            min=1,\n",
    "            max=5,\n",
    "            step=1,\n",
    "            description='Max Path Length:',\n",
    "            disabled=False,\n",
    "            continuous_update=False\n",
    "        )\n",
    "        \n",
    "        # Find paths button\n",
    "        self.find_button = widgets.Button(\n",
    "            description='Find Paths',\n",
    "            disabled=False,\n",
    "            button_style='primary'\n",
    "        )\n",
    "        \n",
    "        # Output area\n",
    "        self.output = widgets.Output()\n",
    "        \n",
    "        # Connect events\n",
    "        self.find_button.on_click(self._on_find_clicked)\n",
    "        self.source_search.observe(self._on_source_search_change, names='value')\n",
    "        self.target_search.observe(self._on_target_search_change, names='value')\n",
    "    \n",
    "    def _get_top_concepts(self, n):\n",
    "        \"\"\"Get the top n most connected concepts in the graph\"\"\"\n",
    "        # Get concepts with most connections\n",
    "        degree_dict = dict(self.graph.degree())\n",
    "        sorted_concepts = sorted(degree_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        return [concept for concept, _ in sorted_concepts[:n]]\n",
    "    \n",
    "    def _on_source_search_change(self, change):\n",
    "        \"\"\"Filter source concept options based on search term\"\"\"\n",
    "        search_term = change['new'].lower().strip()\n",
    "        if not search_term:\n",
    "            # If search is empty, show top concepts\n",
    "            self.source_dropdown.options = self.top_concepts\n",
    "        else:\n",
    "            # Find matching concepts\n",
    "            matches = [n for n in self.graph.nodes() if search_term in n.lower()]\n",
    "            # Limit matches to avoid overloading the dropdown\n",
    "            matches = sorted(matches)[:self.max_suggestions]\n",
    "            if matches:\n",
    "                self.source_dropdown.options = matches\n",
    "            else:\n",
    "                self.source_dropdown.options = ['No matches found']\n",
    "    \n",
    "    def _on_target_search_change(self, change):\n",
    "        \"\"\"Filter target concept options based on search term\"\"\"\n",
    "        search_term = change['new'].lower().strip()\n",
    "        if not search_term:\n",
    "            # If search is empty, show top concepts\n",
    "            self.target_dropdown.options = self.top_concepts\n",
    "        else:\n",
    "            # Find matching concepts\n",
    "            matches = [n for n in self.graph.nodes() if search_term in n.lower()]\n",
    "            # Limit matches to avoid overloading the dropdown\n",
    "            matches = sorted(matches)[:self.max_suggestions]\n",
    "            if matches:\n",
    "                self.target_dropdown.options = matches\n",
    "            else:\n",
    "                self.target_dropdown.options = ['No matches found']\n",
    "    \n",
    "    def show(self):\n",
    "        \"\"\"Display the path finder interface\"\"\"\n",
    "        source_box = widgets.VBox([\n",
    "            widgets.Label('Source Concept:'),\n",
    "            self.source_search,\n",
    "            self.source_dropdown\n",
    "        ])\n",
    "        \n",
    "        target_box = widgets.VBox([\n",
    "            widgets.Label('Target Concept:'),\n",
    "            self.target_search,\n",
    "            self.target_dropdown\n",
    "        ])\n",
    "        \n",
    "        display(widgets.VBox([\n",
    "            widgets.HBox([source_box, target_box, self.max_path_length]),\n",
    "            self.find_button,\n",
    "            self.output\n",
    "        ]))\n",
    "    \n",
    "    def _on_find_clicked(self, b):\n",
    "        \"\"\"Handle button click event\"\"\"\n",
    "        with self.output:\n",
    "            clear_output()\n",
    "            \n",
    "            source = self.source_dropdown.value\n",
    "            target = self.target_dropdown.value\n",
    "            max_length = self.max_path_length.value\n",
    "            \n",
    "            if source == 'No matches found' or target == 'No matches found':\n",
    "                print(\"Please select valid source and target concepts.\")\n",
    "                return\n",
    "            \n",
    "            if not source or not target:\n",
    "                print(\"Please select both source and target concepts.\")\n",
    "                return\n",
    "            \n",
    "            # Check if both concepts exist in the graph\n",
    "            if source not in self.graph:\n",
    "                print(f\"Source concept '{source}' not found in the graph.\")\n",
    "                return\n",
    "                \n",
    "            if target not in self.graph:\n",
    "                print(f\"Target concept '{target}' not found in the graph.\")\n",
    "                return\n",
    "            \n",
    "            print(f\"Finding paths from '{source}' to '{target}' (max length: {max_length})...\")\n",
    "            paths = self._find_all_paths(source, target, max_length)\n",
    "            \n",
    "            if not paths:\n",
    "                print(f\"No paths found between '{source}' and '{target}' within {max_length} steps.\")\n",
    "            else:\n",
    "                print(f\"Found {len(paths)} path(s):\")\n",
    "                self._display_paths(paths)\n",
    "    \n",
    "    def _find_all_paths(self, source, target, max_length):\n",
    "        \"\"\"Find all paths between source and target up to max_length\"\"\"\n",
    "        # Use limited depth-first search to find paths\n",
    "        paths = []\n",
    "        self._dfs(source, target, max_length, [source], paths, set([source]))\n",
    "        return paths\n",
    "    \n",
    "    def _dfs(self, current, target, depth_left, current_path, result_paths, visited):\n",
    "        # Base case: reached target\n",
    "        if current == target:\n",
    "            result_paths.append(current_path.copy())\n",
    "            return\n",
    "            \n",
    "        # Base case: max depth reached\n",
    "        if depth_left <= 0:\n",
    "            return\n",
    "            \n",
    "        # Explore neighbors\n",
    "        for neighbor in self.graph.neighbors(current):\n",
    "            if neighbor not in visited:\n",
    "                # Add to current path and visited set\n",
    "                current_path.append(neighbor)\n",
    "                visited.add(neighbor)\n",
    "                \n",
    "                # Recursively search from this neighbor\n",
    "                self._dfs(neighbor, target, depth_left - 1, current_path, result_paths, visited)\n",
    "                \n",
    "                # Backtrack\n",
    "                current_path.pop()\n",
    "                visited.remove(neighbor)\n",
    "    \n",
    "    def _display_paths(self, paths):\n",
    "        \"\"\"Display found paths with relationship information\"\"\"\n",
    "        for i, path in enumerate(paths):\n",
    "            print(f\"\\nPath {i+1}: {' → '.join(path)}\")\n",
    "            print(\"Relationships:\")\n",
    "            \n",
    "            # Show the relationships between each pair of concepts in the path\n",
    "            for j in range(len(path) - 1):\n",
    "                source, target = path[j], path[j+1]\n",
    "                if self.graph.has_edge(source, target):\n",
    "                    edge_data = self.graph.get_edge_data(source, target)\n",
    "                    relation = edge_data.get('relation', 'related')\n",
    "                    weight = edge_data.get('weight', 1.0)\n",
    "                    print(f\"  {source} --[{relation} ({weight:.2f})]-> {target}\")\n",
    "                else:\n",
    "                    print(f\"  {source} --[?]-> {target} (relationship data missing)\")\n",
    "            \n",
    "            # Add a visual separator between paths\n",
    "            if i < len(paths) - 1:\n",
    "                print(\"---\")\n",
    "        \n",
    "        # Visualize the first path if available\n",
    "        if paths:\n",
    "            self._visualize_path(paths[0])\n",
    "    \n",
    "    def _visualize_path(self, path):\n",
    "        \"\"\"Create a simple visualization of the path\"\"\"\n",
    "        # Create a subgraph containing just the path\n",
    "        path_graph = nx.DiGraph()\n",
    "        \n",
    "        # Add nodes and edges from the path\n",
    "        for i in range(len(path) - 1):\n",
    "            source, target = path[i], path[i+1]\n",
    "            \n",
    "            # Get edge data if available\n",
    "            if self.graph.has_edge(source, target):\n",
    "                edge_data = self.graph.get_edge_data(source, target)\n",
    "                path_graph.add_edge(source, target, **edge_data)\n",
    "            else:\n",
    "                path_graph.add_edge(source, target)\n",
    "        \n",
    "        # Create a simple visualization\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        pos = nx.spring_layout(path_graph)\n",
    "        \n",
    "        # Draw the path\n",
    "        nx.draw(path_graph, pos, with_labels=True, node_color='skyblue', \n",
    "                node_size=2000, edge_color='gray', width=2, font_weight='bold')\n",
    "        \n",
    "        # Add edge labels\n",
    "        edge_labels = {}\n",
    "        for source, target, data in path_graph.edges(data=True):\n",
    "            relation = data.get('relation', '?')\n",
    "            edge_labels[(source, target)] = relation\n",
    "        \n",
    "        nx.draw_networkx_edge_labels(path_graph, pos, edge_labels=edge_labels)\n",
    "        \n",
    "        plt.title(f\"Semantic Path: {' → '.join(path)}\")\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Create path finders for both languages with improved UI\n",
    "print(\"English Semantic Path Finder:\")\n",
    "english_path_finder = SemanticPathFinder(english_graph)\n",
    "english_path_finder.show()\n",
    "\n",
    "print(\"\\nGerman Semantic Path Finder:\")\n",
    "german_path_finder = SemanticPathFinder(german_graph)\n",
    "german_path_finder.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0eeb9a",
   "metadata": {},
   "source": [
    "## 8. Cross-Language Semantic Mapper\n",
    "\n",
    "Let's build a tool that can map concepts across languages (English to German) and visualize the semantic bridges between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5300dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Language Semantic Mapper:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be8b454e3db47de86195c7fc86e7a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Label(value='English Concept:'), Text(value='', description='Engl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CrossLanguageMapper:\n",
    "    \"\"\"Maps semantic concepts across languages and visualizes the connections\"\"\"\n",
    "    \n",
    "    def __init__(self, en_graph, de_graph, max_suggestions=100):\n",
    "        self.en_graph = en_graph\n",
    "        self.de_graph = de_graph\n",
    "        self.max_suggestions = max_suggestions\n",
    "        self._setup_ui()\n",
    "    \n",
    "    def _setup_ui(self):\n",
    "        \"\"\"Set up interactive UI for cross-language mapping\"\"\"\n",
    "        # Get top concepts from both languages\n",
    "        self.top_en_concepts = self._get_top_concepts(self.en_graph, 20)\n",
    "        self.top_de_concepts = self._get_top_concepts(self.de_graph, 20)\n",
    "        \n",
    "        # Source concept (English) selection\n",
    "        self.en_search = widgets.Text(\n",
    "            value='',\n",
    "            placeholder='Search for English concept',\n",
    "            description='English:',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.en_dropdown = widgets.Dropdown(\n",
    "            options=self.top_en_concepts,\n",
    "            description='Select:',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        # Target concept (German) for comparison\n",
    "        self.de_search = widgets.Text(\n",
    "            value='',\n",
    "            placeholder='Search for German concept',\n",
    "            description='German:',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.de_dropdown = widgets.Dropdown(\n",
    "            options=self.top_de_concepts,\n",
    "            description='Select:',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        # Mapping parameters\n",
    "        self.semantic_depth = widgets.IntSlider(\n",
    "            value=2,\n",
    "            min=1,\n",
    "            max=4,\n",
    "            step=1,\n",
    "            description='Semantic Depth:',\n",
    "            disabled=False,\n",
    "            continuous_update=False\n",
    "        )\n",
    "        \n",
    "        self.similarity_threshold = widgets.FloatSlider(\n",
    "            value=0.4,\n",
    "            min=0.1,\n",
    "            max=0.9,\n",
    "            step=0.1,\n",
    "            description='Similarity Threshold:',\n",
    "            disabled=False,\n",
    "            continuous_update=False\n",
    "        )\n",
    "        \n",
    "        # Action button\n",
    "        self.map_button = widgets.Button(\n",
    "            description='Map Concepts',\n",
    "            disabled=False,\n",
    "            button_style='primary'\n",
    "        )\n",
    "        \n",
    "        # Output area\n",
    "        self.output = widgets.Output()\n",
    "        \n",
    "        # Connect events\n",
    "        self.map_button.on_click(self._on_map_clicked)\n",
    "        self.en_search.observe(self._on_en_search_change, names='value')\n",
    "        self.de_search.observe(self._on_de_search_change, names='value')\n",
    "    \n",
    "    def _get_top_concepts(self, graph, n):\n",
    "        \"\"\"Get top n concepts with highest degree from the graph\"\"\"\n",
    "        degree_dict = dict(graph.degree())\n",
    "        sorted_concepts = sorted(degree_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        return [concept for concept, _ in sorted_concepts[:n]]\n",
    "    \n",
    "    def _on_en_search_change(self, change):\n",
    "        \"\"\"Update English concept dropdown based on search\"\"\"\n",
    "        search_term = change['new'].lower().strip()\n",
    "        if not search_term:\n",
    "            self.en_dropdown.options = self.top_en_concepts\n",
    "        else:\n",
    "            matches = [n for n in self.en_graph.nodes() if search_term in n.lower()]\n",
    "            matches = sorted(matches)[:self.max_suggestions]\n",
    "            if matches:\n",
    "                self.en_dropdown.options = matches\n",
    "            else:\n",
    "                self.en_dropdown.options = ['No matches found']\n",
    "    \n",
    "    def _on_de_search_change(self, change):\n",
    "        \"\"\"Update German concept dropdown based on search\"\"\"\n",
    "        search_term = change['new'].lower().strip()\n",
    "        if not search_term:\n",
    "            self.de_dropdown.options = self.top_de_concepts\n",
    "        else:\n",
    "            matches = [n for n in self.de_graph.nodes() if search_term in n.lower()]\n",
    "            matches = sorted(matches)[:self.max_suggestions]\n",
    "            if matches:\n",
    "                self.de_dropdown.options = matches\n",
    "            else:\n",
    "                self.de_dropdown.options = ['No matches found']\n",
    "    \n",
    "    def show(self):\n",
    "        \"\"\"Display the cross-language mapper interface\"\"\"\n",
    "        en_box = widgets.VBox([\n",
    "            widgets.Label('English Concept:'),\n",
    "            self.en_search,\n",
    "            self.en_dropdown\n",
    "        ])\n",
    "        \n",
    "        de_box = widgets.VBox([\n",
    "            widgets.Label('German Concept:'),\n",
    "            self.de_search,\n",
    "            self.de_dropdown\n",
    "        ])\n",
    "        \n",
    "        controls = widgets.HBox([\n",
    "            en_box,\n",
    "            de_box,\n",
    "            widgets.VBox([\n",
    "                self.semantic_depth,\n",
    "                self.similarity_threshold\n",
    "            ])\n",
    "        ])\n",
    "        \n",
    "        display(widgets.VBox([\n",
    "            controls,\n",
    "            self.map_button,\n",
    "            self.output\n",
    "        ]))\n",
    "    \n",
    "    def _on_map_clicked(self, b):\n",
    "        \"\"\"Handle mapping button click\"\"\"\n",
    "        with self.output:\n",
    "            clear_output()\n",
    "            \n",
    "            en_concept = self.en_dropdown.value\n",
    "            de_concept = self.de_dropdown.value\n",
    "            \n",
    "            # Validate inputs\n",
    "            if en_concept in ['No matches found'] or de_concept in ['No matches found']:\n",
    "                print(\"Please select valid concepts in both languages.\")\n",
    "                return\n",
    "                \n",
    "            if not en_concept or not en_concept in self.en_graph:\n",
    "                print(f\"English concept '{en_concept}' not found in the graph.\")\n",
    "                return\n",
    "                \n",
    "            if not de_concept or not de_concept in self.de_graph:\n",
    "                print(f\"German concept '{de_concept}' not found in the graph.\")\n",
    "                return\n",
    "            \n",
    "            depth = self.semantic_depth.value\n",
    "            threshold = self.similarity_threshold.value\n",
    "            \n",
    "            print(f\"Mapping {en_concept} (EN) to {de_concept} (DE) with depth {depth}...\")\n",
    "            self._create_cross_language_mapping(en_concept, de_concept, depth, threshold)\n",
    "    \n",
    "    def _find_neighborhood(self, graph, concept, depth):\n",
    "        \"\"\"Extract neighborhood of concepts up to specified depth\"\"\"\n",
    "        neighborhood = {concept}\n",
    "        frontier = {concept}\n",
    "        \n",
    "        # BFS to collect neighbors\n",
    "        for _ in range(depth):\n",
    "            new_frontier = set()\n",
    "            for node in frontier:\n",
    "                # Add both outgoing and incoming neighbors\n",
    "                out_neighbors = set(graph.neighbors(node))\n",
    "                in_neighbors = set(graph.predecessors(node))\n",
    "                new_frontier.update(out_neighbors | in_neighbors)\n",
    "            \n",
    "            # Remove already processed nodes\n",
    "            frontier = new_frontier - neighborhood\n",
    "            neighborhood.update(frontier)\n",
    "        \n",
    "        return neighborhood\n",
    "    \n",
    "    def _compute_similarity(self, concept1, concept2):\n",
    "        \"\"\"Compute simple string similarity between concepts\"\"\"\n",
    "        # Convert to lowercase for comparison\n",
    "        c1 = concept1.lower()\n",
    "        c2 = concept2.lower()\n",
    "        \n",
    "        # Use Jaccard similarity on character trigrams\n",
    "        def get_trigrams(s):\n",
    "            return {s[i:i+3] for i in range(len(s)-2)} if len(s) > 2 else {s}\n",
    "        \n",
    "        trigrams1 = get_trigrams(c1)\n",
    "        trigrams2 = get_trigrams(c2)\n",
    "        \n",
    "        # Calculate Jaccard similarity\n",
    "        intersection = len(trigrams1.intersection(trigrams2))\n",
    "        union = len(trigrams1.union(trigrams2))\n",
    "        \n",
    "        if union == 0:\n",
    "            return 0\n",
    "        return intersection / union\n",
    "    \n",
    "    def _create_semantic_connections(self, en_neighborhood, de_neighborhood, threshold):\n",
    "        \"\"\"Create connections between semantically similar concepts across languages\"\"\"\n",
    "        connections = []\n",
    "        \n",
    "        # Find concept pairs that exceed similarity threshold\n",
    "        for en_concept in en_neighborhood:\n",
    "            for de_concept in de_neighborhood:\n",
    "                similarity = self._compute_similarity(en_concept, de_concept)\n",
    "                if similarity >= threshold:\n",
    "                    connections.append((en_concept, de_concept, similarity))\n",
    "        \n",
    "        # Sort by similarity score\n",
    "        return sorted(connections, key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    def _create_cross_language_mapping(self, en_concept, de_concept, depth, threshold):\n",
    "        \"\"\"Create and visualize cross-language semantic mapping\"\"\"\n",
    "        # Extract neighborhoods in both languages\n",
    "        print(\"Extracting semantic neighborhoods...\")\n",
    "        en_neighborhood = self._find_neighborhood(self.en_graph, en_concept, depth)\n",
    "        de_neighborhood = self._find_neighborhood(self.de_graph, de_concept, depth)\n",
    "        \n",
    "        print(f\"Found {len(en_neighborhood)} English concepts and {len(de_neighborhood)} German concepts\")\n",
    "        \n",
    "        # Compute cross-language semantic connections\n",
    "        print(\"Computing cross-language connections...\")\n",
    "        connections = self._create_semantic_connections(en_neighborhood, de_neighborhood, threshold)\n",
    "        \n",
    "        print(f\"Found {len(connections)} cross-language connections above threshold {threshold}\")\n",
    "        \n",
    "        # Display top connections\n",
    "        self._display_connections(connections[:20])  # Show top 20 connections\n",
    "        \n",
    "        # Visualize the cross-language mapping\n",
    "        self._visualize_mapping(en_concept, de_concept, en_neighborhood, de_neighborhood, connections)\n",
    "    \n",
    "    def _display_connections(self, connections):\n",
    "        \"\"\"Display top cross-language connections\"\"\"\n",
    "        if not connections:\n",
    "            print(\"No semantic connections found above threshold.\")\n",
    "            return\n",
    "            \n",
    "        print(\"\\nTop Cross-Language Connections:\")\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"{'English Concept':<25} | {'German Concept':<25} | {'Similarity':<10}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for en_concept, de_concept, similarity in connections:\n",
    "            print(f\"{en_concept:<25} | {de_concept:<25} | {similarity:.2f}\")\n",
    "    \n",
    "    def _visualize_mapping(self, en_root, de_root, en_neighborhood, de_neighborhood, connections):\n",
    "        \"\"\"Create an interactive visualization of cross-language mapping\"\"\"\n",
    "        # Create a combined graph for visualization\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        # Add English nodes (blue)\n",
    "        for node in en_neighborhood:\n",
    "            G.add_node(node, language='en', color='blue')\n",
    "            \n",
    "        # Add German nodes (red)\n",
    "        for node in de_neighborhood:\n",
    "            # Add 'DE:' prefix to avoid node name collisions\n",
    "            node_id = f\"DE:{node}\"\n",
    "            G.add_node(node_id, language='de', name=node, color='red')\n",
    "        \n",
    "        # Add English graph connections\n",
    "        for source in en_neighborhood:\n",
    "            for target in self.en_graph.neighbors(source):\n",
    "                if target in en_neighborhood:\n",
    "                    if self.en_graph.has_edge(source, target):\n",
    "                        data = self.en_graph.get_edge_data(source, target)\n",
    "                        weight = data.get('weight', 1.0)\n",
    "                        relation = data.get('relation', 'related')\n",
    "                        G.add_edge(source, target, weight=weight, relation=relation, type='en-en')\n",
    "        \n",
    "        # Add German graph connections\n",
    "        for source in de_neighborhood:\n",
    "            source_id = f\"DE:{source}\"\n",
    "            for target in self.de_graph.neighbors(source):\n",
    "                if target in de_neighborhood:\n",
    "                    target_id = f\"DE:{target}\"\n",
    "                    if self.de_graph.has_edge(source, target):\n",
    "                        data = self.de_graph.get_edge_data(source, target)\n",
    "                        weight = data.get('weight', 1.0)\n",
    "                        relation = data.get('relation', 'related')\n",
    "                        G.add_edge(source_id, target_id, weight=weight, relation=relation, type='de-de')\n",
    "        \n",
    "        # Add cross-language connections\n",
    "        for en_concept, de_concept, similarity in connections:\n",
    "            de_id = f\"DE:{de_concept}\"\n",
    "            G.add_edge(en_concept, de_id, weight=similarity, relation='similar', type='cross-lang')\n",
    "        \n",
    "        # Create positions using a spring layout, with English and German separated\n",
    "        pos = nx.spring_layout(G, k=0.5, iterations=100, seed=42)\n",
    "        \n",
    "        # Adjust positions to separate languages visually\n",
    "        for node, position in pos.items():\n",
    "            if isinstance(node, str) and node.startswith('DE:'):\n",
    "                pos[node] = (position[0] + 3, position[1]) # Shift German nodes to the right\n",
    "        \n",
    "        # Create the figure\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        # Draw English nodes (blue)\n",
    "        en_nodes = [n for n, attr in G.nodes(data=True) if attr.get('language') == 'en']\n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=en_nodes, node_color='skyblue', \n",
    "                           node_size=500, alpha=0.8)\n",
    "        \n",
    "        # Draw German nodes (red)\n",
    "        de_nodes = [n for n, attr in G.nodes(data=True) if attr.get('language') == 'de']\n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=de_nodes, node_color='lightcoral', \n",
    "                           node_size=500, alpha=0.8)\n",
    "        \n",
    "        # Highlight root nodes (green)\n",
    "        root_nodes = [en_root, f\"DE:{de_root}\"]\n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=root_nodes, node_color='lightgreen',\n",
    "                           node_size=700, alpha=1.0)\n",
    "        \n",
    "        # Draw intra-language edges\n",
    "        en_en_edges = [(u, v) for u, v, attr in G.edges(data=True) if attr.get('type') == 'en-en']\n",
    "        de_de_edges = [(u, v) for u, v, attr in G.edges(data=True) if attr.get('type') == 'de-de']\n",
    "        \n",
    "        nx.draw_networkx_edges(G, pos, edgelist=en_en_edges, edge_color='blue', alpha=0.3, width=1)\n",
    "        nx.draw_networkx_edges(G, pos, edgelist=de_de_edges, edge_color='red', alpha=0.3, width=1)\n",
    "        \n",
    "        # Draw cross-language edges\n",
    "        cross_lang_edges = [(u, v) for u, v, attr in G.edges(data=True) if attr.get('type') == 'cross-lang']\n",
    "        nx.draw_networkx_edges(G, pos, edgelist=cross_lang_edges, edge_color='purple', \n",
    "                           style='dashed', alpha=0.7, width=1.5)\n",
    "        \n",
    "        # Add labels for both languages\n",
    "        en_labels = {n: n for n in en_nodes}\n",
    "        de_labels = {n: G.nodes[n]['name'] for n in de_nodes}  # Use the original name without DE: prefix\n",
    "        \n",
    "        nx.draw_networkx_labels(G, pos, labels=en_labels, font_size=9, font_color='black')\n",
    "        nx.draw_networkx_labels(G, pos, labels=de_labels, font_size=9, font_color='black')\n",
    "        \n",
    "        # Add title and legend\n",
    "        plt.title(f\"Cross-Language Semantic Mapping: '{en_root}' (EN) ↔ '{de_root}' (DE)\", fontsize=16)\n",
    "        \n",
    "        # Legend elements\n",
    "        from matplotlib.lines import Line2D\n",
    "        from matplotlib.patches import Patch\n",
    "        \n",
    "        legend_elements = [\n",
    "            Patch(facecolor='skyblue', edgecolor='black', alpha=0.8, label='English Concepts'),\n",
    "            Patch(facecolor='lightcoral', edgecolor='black', alpha=0.8, label='German Concepts'),\n",
    "            Patch(facecolor='lightgreen', edgecolor='black', alpha=1.0, label='Root Concepts'),\n",
    "            Line2D([0], [0], color='blue', alpha=0.3, label='English Connections'),\n",
    "            Line2D([0], [0], color='red', alpha=0.3, label='German Connections'),\n",
    "            Line2D([0], [0], color='purple', linestyle='dashed', alpha=0.7, label='Cross-Language Similarities')\n",
    "        ]\n",
    "        \n",
    "        plt.legend(handles=legend_elements, loc='upper right')\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Also create an interactive Plotly visualization\n",
    "        self._create_interactive_visualization(G, pos, en_root, de_root)\n",
    "    \n",
    "    def _create_interactive_visualization(self, G, pos, en_root, de_root):\n",
    "        \"\"\"Create an interactive visualization using Plotly\"\"\"\n",
    "        # Prepare node traces\n",
    "        en_nodes = [n for n, attr in G.nodes(data=True) if attr.get('language') == 'en']\n",
    "        de_nodes = [n for n, attr in G.nodes(data=True) if attr.get('language') == 'de']\n",
    "        root_nodes = [en_root, f\"DE:{de_root}\"]\n",
    "        \n",
    "        # Create node positions and labels\n",
    "        en_x = [pos[node][0] for node in en_nodes if node not in root_nodes]\n",
    "        en_y = [pos[node][1] for node in en_nodes if node not in root_nodes]\n",
    "        en_text = [node for node in en_nodes if node not in root_nodes]\n",
    "        \n",
    "        de_x = [pos[node][0] for node in de_nodes if node not in root_nodes]\n",
    "        de_y = [pos[node][1] for node in de_nodes if node not in root_nodes]\n",
    "        de_text = [G.nodes[node]['name'] for node in de_nodes if node not in root_nodes]  # Original name, not node ID\n",
    "        \n",
    "        root_x = [pos[node][0] for node in root_nodes]\n",
    "        root_y = [pos[node][1] for node in root_nodes]\n",
    "        root_text = [en_root, de_root]  # Use original German name for display\n",
    "        \n",
    "        # Create node traces\n",
    "        node_trace_en = go.Scatter(\n",
    "            x=en_x, y=en_y,\n",
    "            mode='markers+text',\n",
    "            text=en_text,\n",
    "            textposition='top center',\n",
    "            hoverinfo='text',\n",
    "            marker=dict(color='skyblue', size=15, line=dict(width=1, color='black')),\n",
    "            name='English Concepts'\n",
    "        )\n",
    "        \n",
    "        node_trace_de = go.Scatter(\n",
    "            x=de_x, y=de_y,\n",
    "            mode='markers+text',\n",
    "            text=de_text,\n",
    "            textposition='top center',\n",
    "            hoverinfo='text',\n",
    "            marker=dict(color='lightcoral', size=15, line=dict(width=1, color='black')),\n",
    "            name='German Concepts'\n",
    "        )\n",
    "        \n",
    "        node_trace_root = go.Scatter(\n",
    "            x=root_x, y=root_y,\n",
    "            mode='markers+text',\n",
    "            text=root_text,\n",
    "            textposition='top center',\n",
    "            hoverinfo='text',\n",
    "            marker=dict(color='lightgreen', size=20, line=dict(width=2, color='black')),\n",
    "            name='Root Concepts'\n",
    "        )\n",
    "        \n",
    "        # Create edge traces\n",
    "        edge_traces = []\n",
    "        \n",
    "        # English edges\n",
    "        en_en_edges = [(u, v) for u, v, attr in G.edges(data=True) if attr.get('type') == 'en-en']\n",
    "        for u, v in en_en_edges:\n",
    "            x0, y0 = pos[u]\n",
    "            x1, y1 = pos[v]\n",
    "            edge_trace = go.Scatter(\n",
    "                x=[x0, x1, None], y=[y0, y1, None],\n",
    "                line=dict(width=1, color='rgba(0,0,255,0.3)'),\n",
    "                hoverinfo='none',\n",
    "                mode='lines',\n",
    "                showlegend=False\n",
    "            )\n",
    "            edge_traces.append(edge_trace)\n",
    "        \n",
    "        # German edges\n",
    "        de_de_edges = [(u, v) for u, v, attr in G.edges(data=True) if attr.get('type') == 'de-de']\n",
    "        for u, v in de_de_edges:\n",
    "            x0, y0 = pos[u]\n",
    "            x1, y1 = pos[v]\n",
    "            edge_trace = go.Scatter(\n",
    "                x=[x0, x1, None], y=[y0, y1, None],\n",
    "                line=dict(width=1, color='rgba(255,0,0,0.3)'),\n",
    "                hoverinfo='none',\n",
    "                mode='lines',\n",
    "                showlegend=False\n",
    "            )\n",
    "            edge_traces.append(edge_trace)\n",
    "        \n",
    "        # Cross-language edges\n",
    "        cross_lang_edges = [(u, v, attr) for u, v, attr in G.edges(data=True) if attr.get('type') == 'cross-lang']\n",
    "        for u, v, attr in cross_lang_edges:\n",
    "            x0, y0 = pos[u]\n",
    "            x1, y1 = pos[v]\n",
    "            weight = attr.get('weight', 0.5)\n",
    "            # Adjust opacity based on weight\n",
    "            opacity = min(0.8, max(0.3, weight))\n",
    "            edge_trace = go.Scatter(\n",
    "                x=[x0, x1, None], y=[y0, y1, None],\n",
    "                line=dict(width=1.5, color=f'rgba(128,0,128,{opacity})', dash='dash'),\n",
    "                hoverinfo='none',\n",
    "                mode='lines',\n",
    "                showlegend=False\n",
    "            )\n",
    "            edge_traces.append(edge_trace)\n",
    "            \n",
    "        # Create figure with all traces\n",
    "        fig = go.Figure(data=edge_traces + [node_trace_en, node_trace_de, node_trace_root])\n",
    "        \n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title=f\"Interactive Cross-Language Mapping: '{en_root}' (EN) ↔ '{de_root}' (DE)\",\n",
    "            showlegend=True,\n",
    "            hovermode='closest',\n",
    "            margin=dict(b=0, l=0, r=0, t=40),\n",
    "            height=800,\n",
    "            width=1000,\n",
    "            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "            plot_bgcolor='rgba(240,240,240,1)'\n",
    "        )\n",
    "        \n",
    "        # Show the figure\n",
    "        fig.show()\n",
    "\n",
    "# Create the cross-language mapper\n",
    "print(\"Cross-Language Semantic Mapper:\")\n",
    "cross_language_mapper = CrossLanguageMapper(english_graph, german_graph)\n",
    "cross_language_mapper.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c406f6b5",
   "metadata": {},
   "source": [
    "## 9. Temporal Semantic Evolution Visualizer\n",
    "\n",
    "Let's create an interactive time-based animation that demonstrates how semantic connections form exponentially over time. This visualizer will allow us to observe the non-linear growth dynamics of semantic networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ff8275",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'english_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 665\u001b[39m\n\u001b[32m    662\u001b[39m             \u001b[38;5;28mself\u001b[39m._display_statistics(\u001b[32m0\u001b[39m)\n\u001b[32m    664\u001b[39m \u001b[38;5;66;03m# Create and display the temporal visualizer for English network\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m temporal_vis = TemporalSemanticVisualizer(\u001b[43menglish_graph\u001b[49m, english_layout, title=\u001b[33m\"\u001b[39m\u001b[33mEnglish Semantic Network Evolution\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    666\u001b[39m temporal_vis.show()\n",
      "\u001b[31mNameError\u001b[39m: name 'english_graph' is not defined"
     ]
    }
   ],
   "source": [
    "class TemporalSemanticVisualizer:\n",
    "    \"\"\"Interactive visualization of semantic network evolution over time with exponential growth\"\"\"\n",
    "    \n",
    "    def __init__(self, graph, layout=None, title=\"Temporal Semantic Evolution\"):\n",
    "        self.graph = graph\n",
    "        self.title = title\n",
    "        self.nodes = list(graph.nodes())\n",
    "        self.edges = list(graph.edges(data=True))\n",
    "        \n",
    "        # Create layout or use provided one\n",
    "        if layout is None:\n",
    "            print(\"Computing network layout...\")\n",
    "            self.layout_pos = nx.spring_layout(graph, k=0.15, iterations=50, seed=42)\n",
    "            # Convert to DataFrame\n",
    "            self.layout = pd.DataFrame({\n",
    "                'node': list(self.layout_pos.keys()),\n",
    "                'x': [self.layout_pos[node][0] for node in self.layout_pos],\n",
    "                'y': [self.layout_pos[node][1] for node in self.layout_pos]\n",
    "            })\n",
    "        else:\n",
    "            # Convert layout to positions dict if needed\n",
    "            self.layout = layout\n",
    "            self.layout_pos = {row['node']: (row['x'], row['y']) \n",
    "                            for _, row in layout.iterrows()}\n",
    "        \n",
    "        # Setup simulation parameters\n",
    "        self._setup_ui()\n",
    "        self._setup_simulation()\n",
    "    \n",
    "    def _setup_ui(self):\n",
    "        \"\"\"Set up user interface for controlling the animation\"\"\"\n",
    "        # Simulation speed\n",
    "        self.speed_slider = widgets.FloatSlider(\n",
    "            value=1.0,\n",
    "            min=0.1,\n",
    "            max=5.0,\n",
    "            step=0.1,\n",
    "            description='Speed:',\n",
    "            disabled=False,\n",
    "            continuous_update=True,\n",
    "            orientation='horizontal',\n",
    "            readout=True,\n",
    "            readout_format='.1f'\n",
    "        )\n",
    "        \n",
    "        # Network seed size\n",
    "        self.seed_slider = widgets.IntSlider(\n",
    "            value=5,\n",
    "            min=1,\n",
    "            max=50,\n",
    "            step=1,\n",
    "            description='Initial Seed:',\n",
    "            disabled=False,\n",
    "            continuous_update=True,\n",
    "            orientation='horizontal',\n",
    "            readout=True\n",
    "        )\n",
    "        \n",
    "        # Growth factor\n",
    "        self.growth_slider = widgets.FloatSlider(\n",
    "            value=2.0,\n",
    "            min=1.1,\n",
    "            max=3.0,\n",
    "            step=0.1,\n",
    "            description='Growth Factor:',\n",
    "            disabled=False,\n",
    "            continuous_update=True,\n",
    "            orientation='horizontal',\n",
    "            readout=True,\n",
    "            readout_format='.1f'\n",
    "        )\n",
    "        \n",
    "        # Growth model \n",
    "        self.growth_model = widgets.Dropdown(\n",
    "            options=['Exponential', 'Preferential Attachment', 'Small World', 'Semantic Proximity'],\n",
    "            value='Exponential',\n",
    "            description='Growth Model:',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        # Starting concept\n",
    "        top_concepts = self._get_top_concepts(25)\n",
    "        self.seed_concept = widgets.Dropdown(\n",
    "            options=top_concepts,\n",
    "            value=top_concepts[0] if top_concepts else None,\n",
    "            description='Seed Concept:',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        # Playback controls\n",
    "        self.play_button = widgets.Button(\n",
    "            description='▶️ Play',\n",
    "            disabled=False,\n",
    "            button_style='success',\n",
    "            tooltip='Start animation'\n",
    "        )\n",
    "        \n",
    "        self.pause_button = widgets.Button(\n",
    "            description='⏸️ Pause',\n",
    "            disabled=True,\n",
    "            button_style='warning',\n",
    "            tooltip='Pause animation'\n",
    "        )\n",
    "        \n",
    "        self.reset_button = widgets.Button(\n",
    "            description='🔄 Reset',\n",
    "            disabled=False,\n",
    "            button_style='danger',\n",
    "            tooltip='Reset animation'\n",
    "        )\n",
    "        \n",
    "        self.save_button = widgets.Button(\n",
    "            description='💾 Save GIF',\n",
    "            disabled=False,\n",
    "            button_style='info',\n",
    "            tooltip='Save animation as GIF'\n",
    "        )\n",
    "        \n",
    "        # Time slider\n",
    "        self.time_slider = widgets.IntSlider(\n",
    "            value=0,\n",
    "            min=0,\n",
    "            max=100,\n",
    "            step=1,\n",
    "            description='Time:',\n",
    "            disabled=False,\n",
    "            continuous_update=True,\n",
    "            orientation='horizontal',\n",
    "            readout=True\n",
    "        )\n",
    "        \n",
    "        # Statistics display\n",
    "        self.stats_output = widgets.Output()\n",
    "        \n",
    "        # Main visualization output\n",
    "        self.output = widgets.Output()\n",
    "        \n",
    "        # Connect events\n",
    "        self.play_button.on_click(self._on_play_clicked)\n",
    "        self.pause_button.on_click(self._on_pause_clicked)\n",
    "        self.reset_button.on_click(self._on_reset_clicked)\n",
    "        self.save_button.on_click(self._on_save_clicked)\n",
    "        self.time_slider.observe(self._on_time_slider_change, names='value')\n",
    "        self.growth_model.observe(self._on_parameter_change, names='value')\n",
    "        self.seed_concept.observe(self._on_parameter_change, names='value')\n",
    "    \n",
    "    def _get_top_concepts(self, n):\n",
    "        \"\"\"Get the top n most connected concepts in the graph\"\"\"\n",
    "        degree_dict = dict(self.graph.degree())\n",
    "        sorted_concepts = sorted(degree_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        return [concept for concept, _ in sorted_concepts[:n]]\n",
    "    \n",
    "    def _setup_simulation(self):\n",
    "        \"\"\"Initialize simulation parameters\"\"\"\n",
    "        # Simulation state\n",
    "        self.is_playing = False\n",
    "        self.current_step = 0\n",
    "        self.max_steps = 100\n",
    "        self.animation_thread = None\n",
    "        self.frame_history = []\n",
    "        \n",
    "        # Generate growth sequence based on exponential model\n",
    "        self._regenerate_growth_sequence()\n",
    "    \n",
    "    def _regenerate_growth_sequence(self):\n",
    "        \"\"\"Generate a growth sequence based on current parameters\"\"\"\n",
    "        # Get parameters\n",
    "        initial_seed = self.seed_slider.value\n",
    "        growth_factor = self.growth_slider.value\n",
    "        model = self.growth_model.value\n",
    "        seed_concept = self.seed_concept.value\n",
    "        \n",
    "        print(f\"Generating {model} growth sequence with seed={initial_seed}, factor={growth_factor}...\")\n",
    "        \n",
    "        # Calculate number of nodes to add at each step\n",
    "        if model == 'Exponential':\n",
    "            # Pure exponential growth\n",
    "            self.growth_sequence = [int(initial_seed * (growth_factor ** (i/10))) \n",
    "                                 for i in range(self.max_steps)]\n",
    "        elif model == 'Preferential Attachment':\n",
    "            # Based on Barabási–Albert model\n",
    "            # Start with initial nodes, then each new node makes connections proportional to degree\n",
    "            # Simulated with a slightly damped exponential\n",
    "            self.growth_sequence = [int(initial_seed * (growth_factor ** (i/15) * (1 - math.exp(-i/20)))) \n",
    "                                 for i in range(self.max_steps)]\n",
    "        elif model == 'Small World':\n",
    "            # Based on Watts–Strogatz model\n",
    "            # More linear at first, then accelerating as small-world effect kicks in\n",
    "            self.growth_sequence = [int(initial_seed + (i**1.8)/2 + (growth_factor**(i/20))/2) \n",
    "                                 for i in range(self.max_steps)]\n",
    "        elif model == 'Semantic Proximity':\n",
    "            # Custom model that simulates how semantic networks might actually grow\n",
    "            # S-curve: slow start, exponential middle, leveling off at end\n",
    "            max_val = len(self.nodes)\n",
    "            self.growth_sequence = [int(max_val / (1 + math.exp(-growth_factor * (i - self.max_steps/2) / 10))) \n",
    "                                 for i in range(self.max_steps)]\n",
    "            # Ensure we start with at least the initial seed\n",
    "            self.growth_sequence = [max(n, initial_seed) for n in self.growth_sequence]\n",
    "        \n",
    "        # Ensure the sequence is always increasing and capped at total nodes\n",
    "        for i in range(1, len(self.growth_sequence)):\n",
    "            self.growth_sequence[i] = max(self.growth_sequence[i], self.growth_sequence[i-1])\n",
    "            self.growth_sequence[i] = min(self.growth_sequence[i], len(self.nodes))\n",
    "        \n",
    "        # Reset simulation state\n",
    "        self.current_step = 0\n",
    "        self.time_slider.max = self.max_steps - 1\n",
    "        self.time_slider.value = 0\n",
    "        \n",
    "        # Generate node sequence based on seed concept\n",
    "        self._generate_node_sequence(seed_concept)\n",
    "    \n",
    "    def _generate_node_sequence(self, seed_concept):\n",
    "        \"\"\"Generate a sequence of nodes to add based on the seed concept\"\"\"\n",
    "        if not seed_concept or seed_concept not in self.graph:\n",
    "            # If no valid seed, sort nodes by degree (highly connected nodes first)\n",
    "            node_degrees = dict(self.graph.degree())\n",
    "            self.node_sequence = sorted(self.nodes, key=lambda n: node_degrees.get(n, 0), reverse=True)\n",
    "            return\n",
    "            \n",
    "        # Start with the seed concept\n",
    "        visited = {seed_concept}\n",
    "        sequence = [seed_concept]\n",
    "        queue = [(seed_concept, 0)]  # (node, distance from seed)\n",
    "        \n",
    "        # Use BFS to get nodes in order of distance from seed\n",
    "        while queue and len(sequence) < len(self.nodes):\n",
    "            node, distance = queue.pop(0)\n",
    "            \n",
    "            # Get all neighbors\n",
    "            neighbors = set(self.graph.neighbors(node)) | set(self.graph.predecessors(node))\n",
    "            \n",
    "            # Sort neighbors by weight and degree\n",
    "            neighbor_scores = []\n",
    "            for neighbor in neighbors:\n",
    "                if neighbor in visited:\n",
    "                    continue\n",
    "                    \n",
    "                # Calculate score based on edge weight and node degree\n",
    "                weight = 0\n",
    "                if self.graph.has_edge(node, neighbor):\n",
    "                    weight = self.graph.get_edge_data(node, neighbor).get('weight', 1.0)\n",
    "                elif self.graph.has_edge(neighbor, node):\n",
    "                    weight = self.graph.get_edge_data(neighbor, node).get('weight', 1.0)\n",
    "                    \n",
    "                degree = self.graph.degree(neighbor)\n",
    "                score = weight * (degree ** 0.5)  # Weight higher than degree\n",
    "                neighbor_scores.append((neighbor, score))\n",
    "            \n",
    "            # Add sorted neighbors to sequence and queue\n",
    "            sorted_neighbors = [n for n, _ in sorted(neighbor_scores, key=lambda x: x[1], reverse=True)]\n",
    "            for neighbor in sorted_neighbors:\n",
    "                if neighbor not in visited:\n",
    "                    visited.add(neighbor)\n",
    "                    sequence.append(neighbor)\n",
    "                    queue.append((neighbor, distance + 1))\n",
    "        \n",
    "        # Add any remaining nodes (disconnected components)\n",
    "        for node in self.nodes:\n",
    "            if node not in visited:\n",
    "                sequence.append(node)\n",
    "                visited.add(node)\n",
    "        \n",
    "        self.node_sequence = sequence\n",
    "    \n",
    "    def _on_parameter_change(self, change):\n",
    "        \"\"\"Handle parameter changes\"\"\"\n",
    "        # Regenerate the growth sequence with new parameters\n",
    "        self._regenerate_growth_sequence()\n",
    "        \n",
    "        # Update the visualization\n",
    "        with self.output:\n",
    "            clear_output(wait=True)\n",
    "            self._render_frame(self.current_step)\n",
    "    \n",
    "    def _on_play_clicked(self, b):\n",
    "        \"\"\"Handle play button click\"\"\"\n",
    "        if self.is_playing:\n",
    "            return\n",
    "            \n",
    "        self.is_playing = True\n",
    "        self.play_button.disabled = True\n",
    "        self.pause_button.disabled = False\n",
    "        \n",
    "        # Start animation in a separate thread\n",
    "        import threading\n",
    "        self.animation_thread = threading.Thread(target=self._animate)\n",
    "        self.animation_thread.daemon = True\n",
    "        self.animation_thread.start()\n",
    "    \n",
    "    def _on_pause_clicked(self, b):\n",
    "        \"\"\"Handle pause button click\"\"\"\n",
    "        self.is_playing = False\n",
    "        self.play_button.disabled = False\n",
    "        self.pause_button.disabled = True\n",
    "    \n",
    "    def _on_reset_clicked(self, b):\n",
    "        \"\"\"Handle reset button click\"\"\"\n",
    "        self.is_playing = False\n",
    "        self.play_button.disabled = False\n",
    "        self.pause_button.disabled = True\n",
    "        self.current_step = 0\n",
    "        self.time_slider.value = 0\n",
    "        self.frame_history = []\n",
    "        \n",
    "        # Regenerate with current parameters\n",
    "        self._regenerate_growth_sequence()\n",
    "        \n",
    "        # Update visualization\n",
    "        with self.output:\n",
    "            clear_output(wait=True)\n",
    "            self._render_frame(0)\n",
    "    \n",
    "    def _on_time_slider_change(self, change):\n",
    "        \"\"\"Handle time slider change\"\"\"\n",
    "        self.current_step = change['new']\n",
    "        \n",
    "        # Update visualization\n",
    "        with self.output:\n",
    "            clear_output(wait=True)\n",
    "            self._render_frame(self.current_step)\n",
    "    \n",
    "    def _on_save_clicked(self, b):\n",
    "        \"\"\"Save the animation as a GIF\"\"\"\n",
    "        import tempfile\n",
    "        import os\n",
    "        import uuid\n",
    "        from matplotlib.animation import FuncAnimation\n",
    "        import matplotlib.animation as animation\n",
    "        \n",
    "        with self.output:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Preparing to save animation as GIF...\")\n",
    "            \n",
    "            # Generate frames for the GIF\n",
    "            if not self.frame_history or len(self.frame_history) < 10:\n",
    "                print(\"Generating frames for the animation...\")\n",
    "                self.frame_history = []\n",
    "                \n",
    "                # Generate evenly spaced frames for smoother animation\n",
    "                steps = min(30, self.max_steps)  # Limit to 30 frames for reasonable file size\n",
    "                step_size = max(1, self.max_steps // steps)\n",
    "                \n",
    "                for step in range(0, self.max_steps, step_size):\n",
    "                    # Create a figure for this step\n",
    "                    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "                    self._render_static_frame(step, fig, ax)\n",
    "                    self.frame_history.append((fig, ax))\n",
    "                    print(f\"Generated frame {len(self.frame_history)}/{steps}\")\n",
    "            \n",
    "            # Create GIF filename\n",
    "            output_dir = \"../Data/Output\"\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            gif_filename = os.path.join(output_dir, f\"semantic_evolution_{uuid.uuid4()}.gif\")\n",
    "            \n",
    "            # Create animation\n",
    "            print(f\"Creating animation with {len(self.frame_history)} frames...\")\n",
    "            \n",
    "            # Save frames as GIF\n",
    "            frames = [fig for fig, _ in self.frame_history]\n",
    "            \n",
    "            # Set up animation writer\n",
    "            writer = animation.PillowWriter(fps=2)\n",
    "            \n",
    "            # Create an animation using the first figure\n",
    "            fig, ax = self.frame_history[0]\n",
    "            ani = FuncAnimation(fig, self._update_animation_frame, frames=len(frames), interval=500)\n",
    "            \n",
    "            # Save the animation\n",
    "            ani.save(gif_filename, writer=writer)\n",
    "            \n",
    "            print(f\"Animation saved as: {gif_filename}\")\n",
    "            \n",
    "            # Display the animation\n",
    "            from IPython.display import Image\n",
    "            display(Image(filename=gif_filename))\n",
    "    \n",
    "    def _update_animation_frame(self, frame_num):\n",
    "        \"\"\"Update function for FuncAnimation\"\"\"\n",
    "        if frame_num < len(self.frame_history):\n",
    "            fig, ax = self.frame_history[frame_num]\n",
    "            # Clear the previous figure content\n",
    "            for artist in ax.get_children():\n",
    "                if not isinstance(artist, plt.Text):\n",
    "                    artist.remove()\n",
    "            \n",
    "            # Draw the current frame\n",
    "            self._render_static_frame(frame_num * (self.max_steps // len(self.frame_history)), fig, ax)\n",
    "            \n",
    "            return ax.get_children()\n",
    "        \n",
    "    def _animate(self):\n",
    "        \"\"\"Animation loop\"\"\"\n",
    "        while self.is_playing and self.current_step < self.max_steps - 1:\n",
    "            # Set the time slider, which will trigger the frame render\n",
    "            self.time_slider.value = self.current_step + 1\n",
    "            \n",
    "            # Sleep based on speed slider\n",
    "            import time\n",
    "            sleep_time = 1.0 / self.speed_slider.value\n",
    "            time.sleep(sleep_time)\n",
    "        \n",
    "        # If we reached the end, disable play and enable pause\n",
    "        if self.current_step >= self.max_steps - 1:\n",
    "            self.is_playing = False\n",
    "            self.play_button.disabled = False\n",
    "            self.pause_button.disabled = True\n",
    "    \n",
    "    def _render_frame(self, step):\n",
    "        \"\"\"Render a single frame of the animation\"\"\"\n",
    "        # Create interactive or static frame based on number of nodes/edges\n",
    "        num_nodes = self.growth_sequence[step]\n",
    "        if num_nodes < 500:  # Use interactive for smaller graphs\n",
    "            self._render_interactive_frame(step)\n",
    "        else:  # Use static for larger graphs\n",
    "            fig, ax = plt.subplots(figsize=(12, 10))\n",
    "            self._render_static_frame(step, fig, ax)\n",
    "            plt.show()\n",
    "        \n",
    "        # Update statistics\n",
    "        with self.stats_output:\n",
    "            clear_output(wait=True)\n",
    "            self._display_statistics(step)\n",
    "    \n",
    "    def _render_interactive_frame(self, step):\n",
    "        \"\"\"Render an interactive frame using Plotly\"\"\"\n",
    "        # Get current number of nodes to display\n",
    "        num_nodes = self.growth_sequence[step]\n",
    "        displayed_nodes = self.node_sequence[:num_nodes]\n",
    "        \n",
    "        # Create a subgraph with only these nodes\n",
    "        subgraph = self.graph.subgraph(displayed_nodes)\n",
    "        \n",
    "        # Extract positions for nodes\n",
    "        node_positions = {node: self.layout_pos[node] for node in displayed_nodes if node in self.layout_pos}\n",
    "        \n",
    "        # Create node trace\n",
    "        node_degrees = dict(subgraph.degree())\n",
    "        node_x = [pos[0] for node, pos in node_positions.items()]\n",
    "        node_y = [pos[1] for node, pos in node_positions.items()]\n",
    "        node_texts = list(node_positions.keys())\n",
    "        node_sizes = [node_degrees.get(node, 1) * 10 for node in node_positions.keys()]\n",
    "        \n",
    "        node_trace = go.Scatter(\n",
    "            x=node_x,\n",
    "            y=node_y,\n",
    "            mode='markers+text',\n",
    "            text=node_texts,\n",
    "            textposition='top center',\n",
    "            hoverinfo='text',\n",
    "            marker=dict(\n",
    "                size=node_sizes,\n",
    "                color=node_sizes,\n",
    "                colorscale='Viridis',\n",
    "                line=dict(width=1, color='black'),\n",
    "                colorbar=dict(title='Connections')\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Create edge traces\n",
    "        edge_traces = []\n",
    "        for u, v, data in subgraph.edges(data=True):\n",
    "            if u in node_positions and v in node_positions:\n",
    "                x0, y0 = node_positions[u]\n",
    "                x1, y1 = node_positions[v]\n",
    "                weight = data.get('weight', 1.0)\n",
    "                \n",
    "                edge_trace = go.Scatter(\n",
    "                    x=[x0, x1, None],\n",
    "                    y=[y0, y1, None],\n",
    "                    line=dict(\n",
    "                        width=weight * 1.5,\n",
    "                        color='rgba(150,150,150,0.5)'\n",
    "                    ),\n",
    "                    hoverinfo='none',\n",
    "                    mode='lines'\n",
    "                )\n",
    "                edge_traces.append(edge_trace)\n",
    "        \n",
    "        # Create figure\n",
    "        fig = go.Figure(\n",
    "            data=edge_traces + [node_trace],\n",
    "            layout=go.Layout(\n",
    "                title=f\"{self.title} - Step {step}/{self.max_steps-1} ({num_nodes} nodes)\",\n",
    "                showlegend=False,\n",
    "                hovermode='closest',\n",
    "                margin=dict(b=20, l=5, r=5, t=40),\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                plot_bgcolor='rgba(240,240,240,1)'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "    \n",
    "    def _render_static_frame(self, step, fig=None, ax=None):\n",
    "        \"\"\"Render a static frame using Matplotlib\"\"\"\n",
    "        if fig is None or ax is None:\n",
    "            fig, ax = plt.subplots(figsize=(12, 10))\n",
    "            \n",
    "        # Get current number of nodes to display\n",
    "        num_nodes = min(self.growth_sequence[step], len(self.node_sequence))\n",
    "        displayed_nodes = self.node_sequence[:num_nodes]\n",
    "        \n",
    "        # Create a subgraph with only these nodes\n",
    "        subgraph = self.graph.subgraph(displayed_nodes)\n",
    "        \n",
    "        # Extract positions for these nodes\n",
    "        pos = {node: self.layout_pos[node] for node in displayed_nodes if node in self.layout_pos}\n",
    "        \n",
    "        # Calculate node sizes based on degree\n",
    "        node_degrees = dict(subgraph.degree())\n",
    "        sizes = [50 + 10 * node_degrees.get(node, 0) for node in pos.keys()]\n",
    "        \n",
    "        # Calculate edge weights\n",
    "        edge_weights = [data.get('weight', 1.0) for _, _, data in subgraph.edges(data=True)]\n",
    "        max_weight = max(edge_weights) if edge_weights else 1.0\n",
    "        normalized_weights = [w / max_weight for w in edge_weights]\n",
    "        \n",
    "        # Draw the network\n",
    "        nodes = nx.draw_networkx_nodes(\n",
    "            subgraph, pos,\n",
    "            node_size=sizes,\n",
    "            node_color=list(node_degrees.values()),\n",
    "            cmap=plt.cm.viridis,\n",
    "            alpha=0.8,\n",
    "            ax=ax\n",
    "        )\n",
    "        \n",
    "        nx.draw_networkx_edges(\n",
    "            subgraph, pos,\n",
    "            alpha=0.4,\n",
    "            width=[w * 2 for w in normalized_weights],\n",
    "            edge_color='gray',\n",
    "            ax=ax\n",
    "        )\n",
    "        \n",
    "        # Only draw labels for high-degree nodes to reduce clutter\n",
    "        threshold = np.percentile(list(node_degrees.values()), 75) if node_degrees else 0\n",
    "        labels = {node: node for node in subgraph if node_degrees.get(node, 0) >= threshold}\n",
    "        nx.draw_networkx_labels(\n",
    "            subgraph, pos,\n",
    "            labels=labels,\n",
    "            font_size=8,\n",
    "            font_weight='bold',\n",
    "            ax=ax\n",
    "        )\n",
    "        \n",
    "        # Add colorbar for node degrees\n",
    "        if nodes is not None:  # Ensure we have nodes to create a colorbar for\n",
    "            plt.colorbar(nodes, ax=ax, label='Node Connections')\n",
    "        \n",
    "        # Add title\n",
    "        model = self.growth_model.value\n",
    "        growth_factor = self.growth_slider.value\n",
    "        ax.set_title(f\"{self.title} - Step {step}/{self.max_steps-1}\\n{model} Growth (factor={growth_factor:.1f})\\n{num_nodes} nodes, {len(subgraph.edges())} connections\")\n",
    "        \n",
    "        # Add network statistics\n",
    "        if num_nodes > 1:\n",
    "            try:\n",
    "                density = nx.density(subgraph)\n",
    "                stats_text = f\"Network Density: {density:.4f}\"\n",
    "                if num_nodes < 1000:  # Skip these expensive calculations for large graphs\n",
    "                    try:\n",
    "                        avg_shortest_path = nx.average_shortest_path_length(subgraph)\n",
    "                        stats_text += f\"\\nAvg. Path Length: {avg_shortest_path:.2f}\"\n",
    "                    except nx.NetworkXError:\n",
    "                        # Graph might not be connected\n",
    "                        stats_text += \"\\nAvg. Path Length: N/A (disconnected)\"\n",
    "                ax.text(0.02, 0.02, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "                      bbox=dict(facecolor='white', alpha=0.7))\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating graph statistics: {e}\")\n",
    "        \n",
    "        ax.axis('off')\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        return fig, ax\n",
    "    \n",
    "    def _display_statistics(self, step):\n",
    "        \"\"\"Display network growth statistics\"\"\"\n",
    "        num_nodes = self.growth_sequence[step]\n",
    "        displayed_nodes = self.node_sequence[:num_nodes]\n",
    "        \n",
    "        # Create a subgraph with only these nodes\n",
    "        subgraph = self.graph.subgraph(displayed_nodes)\n",
    "        \n",
    "        print(f\"--- Network Statistics at Step {step} ---\")\n",
    "        print(f\"Growth Model: {self.growth_model.value}\")\n",
    "        print(f\"Growth Factor: {self.growth_slider.value:.1f}\")\n",
    "        print(f\"Nodes: {num_nodes}\")\n",
    "        print(f\"Connections: {len(subgraph.edges())}\")\n",
    "        print(f\"Avg. Connections per Node: {2*len(subgraph.edges())/num_nodes:.2f}\")\n",
    "        \n",
    "        # Compute network density\n",
    "        if num_nodes > 1:\n",
    "            density = nx.density(subgraph)\n",
    "            print(f\"Network Density: {density:.6f}\")\n",
    "            \n",
    "            # Only compute these for smaller networks (performance reasons)\n",
    "            if num_nodes < 500:\n",
    "                try:\n",
    "                    # Get largest connected component\n",
    "                    largest_cc = max(nx.connected_components(subgraph.to_undirected()), key=len)\n",
    "                    largest_cc_size = len(largest_cc)\n",
    "                    print(f\"Largest Connected Component: {largest_cc_size} nodes ({largest_cc_size/num_nodes:.1%} of network)\")\n",
    "                    \n",
    "                    # Calculate average path length in largest component\n",
    "                    cc_subgraph = subgraph.subgraph(largest_cc)\n",
    "                    if len(cc_subgraph) > 1:\n",
    "                        avg_path = nx.average_shortest_path_length(cc_subgraph)\n",
    "                        print(f\"Average Path Length: {avg_path:.2f}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error calculating advanced statistics: {e}\")\n",
    "        \n",
    "        # Display exponential growth rate\n",
    "        if step > 0:\n",
    "            growth_rate = self.growth_sequence[step] / self.growth_sequence[step-1]\n",
    "            print(f\"Growth Rate (from previous step): {growth_rate:.2f}x\")\n",
    "            \n",
    "            # Calculate projected network size\n",
    "            if step < self.max_steps - 1:\n",
    "                projected_size = int(num_nodes * growth_rate)\n",
    "                print(f\"Projected Next Step Size: {projected_size} nodes\")\n",
    "                \n",
    "                # Show if projection exceeds actual graph size\n",
    "                if projected_size > len(self.nodes):\n",
    "                    print(f\"Note: Growth will be capped at {len(self.nodes)} nodes (full network)\")\n",
    "    \n",
    "    def show(self):\n",
    "        \"\"\"Display the interactive evolution visualizer\"\"\"\n",
    "        # Create control panel\n",
    "        parameters = widgets.VBox([\n",
    "            widgets.HBox([self.seed_concept, self.seed_slider]),\n",
    "            widgets.HBox([self.growth_model, self.growth_slider]),\n",
    "            widgets.HBox([self.speed_slider, self.time_slider])\n",
    "        ])\n",
    "        \n",
    "        controls = widgets.HBox([\n",
    "            self.play_button,\n",
    "            self.pause_button,\n",
    "            self.reset_button,\n",
    "            self.save_button\n",
    "        ])\n",
    "        \n",
    "        # Main layout\n",
    "        layout = widgets.VBox([\n",
    "            parameters,\n",
    "            controls,\n",
    "            self.stats_output,\n",
    "            self.output\n",
    "        ])\n",
    "        \n",
    "        display(layout)\n",
    "        \n",
    "        # Render initial frame\n",
    "        with self.output:\n",
    "            self._render_frame(0)\n",
    "        \n",
    "        # Show initial statistics\n",
    "        with self.stats_output:\n",
    "            self._display_statistics(0)\n",
    "\n",
    "# Create and display the temporal visualizer for English network\n",
    "temporal_vis = TemporalSemanticVisualizer(english_graph, english_layout, title=\"English Semantic Network Evolution\")\n",
    "temporal_vis.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26719f7e",
   "metadata": {},
   "source": [
    "## 8. Future Enhancement Opportunities\n",
    "\n",
    "This interactive visualization system can be enhanced in several ways:\n",
    "\n",
    "1. **3D Visualization**: Extend to 3D space for even more immersive exploration\n",
    "2. **Real-time Cross-Language Mapping**: Add real-time translation and semantic mapping\n",
    "3. **Semantic Search**: Implement GPU-accelerated semantic search capabilities\n",
    "4. **Dynamic Graph Updates**: Support streaming updates to the semantic graph\n",
    "5. **Community Detection**: Add GPU-accelerated community detection algorithms\n",
    "6. **Path Analysis Improvements**: Enhance the semantic path finder with:\n",
    "   - Support for bidirectional search\n",
    "   - Path ranking by semantic relevance\n",
    "   - Cross-language path finding\n",
    "7. **Embedded Vector Visualization**: Integrate with embedding models (Word2Vec, BERT, etc.)\n",
    "8. **Animation**: Create dynamic animations showing semantic evolution\n",
    "9. **Custom Rendering**: Implement custom WebGL or Three.js rendering for even better performance\n",
    "10. **Scalability Improvements**: Optimize for handling millions of semantic relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ee1cf1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
