{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc93c8ff",
   "metadata": {},
   "source": [
    "# Data Loading and Setup\n",
    "\n",
    "First, we'll set up our environment and load the data once, making it available to both Phase 1 and Phase 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb84fa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ConceptNet data from Google Drive...\n",
      "Using cached data at ../Data/Input/conceptnet-assertions-5.7.0.en.tsv\n",
      "English ConceptNet loaded with 3423004 assertions.\n",
      "Using cached data at ../Data/Input/conceptnet-assertions-5.7.0.de.tsv\n",
      "German ConceptNet loaded with 1078946 assertions.\n",
      "Data loading complete. Datasets available: True\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "import random\n",
    "import io\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import uuid\n",
    "import warnings\n",
    "import traceback\n",
    "import json\n",
    "from scipy.spatial.distance import cosine\n",
    "import matplotlib\n",
    "import requests\n",
    "from io import StringIO\n",
    "import gdown\n",
    "matplotlib.use('Agg')  # Use non-interactive backend for better memory handling\n",
    "\n",
    "# Create necessary directories\n",
    "output_dir = '../Data/Output'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Load ConceptNet data from Google Drive links\n",
    "print(\"Loading ConceptNet data from Google Drive...\")\n",
    "\n",
    "# Define the Google Drive links\n",
    "english_dataset_id = \"1zBwy1rhJh-7ESQWVENkz1z1_G2aleu7-\"  # ID from the Google Drive link\n",
    "german_dataset_id = \"10Rb0sn4uZVUJSufp08t1wzrLL1jAnRHH\"  # ID from the Google Drive link\n",
    "\n",
    "# Define file paths for caching\n",
    "english_cache_path = '../Data/Input/conceptnet-assertions-5.7.0.en.tsv'\n",
    "german_cache_path = '../Data/Input/conceptnet-assertions-5.7.0.de.tsv'\n",
    "\n",
    "# Create the Input directory if it doesn't exist\n",
    "input_dir = '../Data/Input'\n",
    "if not os.path.exists(input_dir):\n",
    "    os.makedirs(input_dir)\n",
    "\n",
    "# Function to download data\n",
    "def download_from_gdrive(file_id, output_path):\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"Using cached data at {output_path}\")\n",
    "        return True\n",
    "    \n",
    "    print(f\"Downloading data to {output_path}...\")\n",
    "    try:\n",
    "        gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_path, quiet=False)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file: {e}\")\n",
    "        return False\n",
    "\n",
    "# Download and load the datasets\n",
    "english_conceptnet = None\n",
    "german_conceptnet = None\n",
    "\n",
    "# Try to download English dataset\n",
    "if download_from_gdrive(english_dataset_id, english_cache_path):\n",
    "    english_conceptnet = pd.read_csv(\n",
    "        english_cache_path,\n",
    "        sep='\\t',\n",
    "        names=['URI', 'rel', 'start', 'end', 'weight', 'source', 'id', 'dataset', 'surfaceText']\n",
    "    )\n",
    "    print(f\"English ConceptNet loaded with {len(english_conceptnet)} assertions.\")\n",
    "else:\n",
    "    print(\"Failed to load English dataset. Will use a smaller test dataset if available.\")\n",
    "\n",
    "# Try to download German dataset\n",
    "if download_from_gdrive(german_dataset_id, german_cache_path):\n",
    "    german_conceptnet = pd.read_csv(\n",
    "        german_cache_path,\n",
    "        sep='\\t',\n",
    "        names=['URI', 'rel', 'start', 'end', 'weight', 'source', 'id', 'dataset', 'surfaceText']\n",
    "    )\n",
    "    print(f\"German ConceptNet loaded with {len(german_conceptnet)} assertions.\")\n",
    "else:\n",
    "    print(\"Failed to load German dataset. Will use a smaller test dataset if available.\")\n",
    "\n",
    "# If downloading fails, try to use any existing files\n",
    "if english_conceptnet is None and os.path.exists(english_cache_path):\n",
    "    try:\n",
    "        english_conceptnet = pd.read_csv(\n",
    "            english_cache_path,\n",
    "            sep='\\t',\n",
    "            names=['URI', 'rel', 'start', 'end', 'weight', 'source', 'id', 'dataset', 'surfaceText']\n",
    "        )\n",
    "        print(f\"Using existing English ConceptNet with {len(english_conceptnet)} assertions.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading existing English data: {e}\")\n",
    "\n",
    "if german_conceptnet is None and os.path.exists(german_cache_path):\n",
    "    try:\n",
    "        german_conceptnet = pd.read_csv(\n",
    "            german_cache_path,\n",
    "            sep='\\t',\n",
    "            names=['URI', 'rel', 'start', 'end', 'weight', 'source', 'id', 'dataset', 'surfaceText']\n",
    "        )\n",
    "        print(f\"Using existing German ConceptNet with {len(german_conceptnet)} assertions.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading existing German data: {e}\")\n",
    "\n",
    "# Set a flag to track if we need to run Phase 1 data processing\n",
    "data_loaded = english_conceptnet is not None or german_conceptnet is not None\n",
    "print(f\"Data loading complete. Datasets available: {data_loaded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deec642b",
   "metadata": {},
   "source": [
    "# Semantica relation GRaph visualized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d84ca",
   "metadata": {},
   "source": [
    "# Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2118648f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e1d20ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "import random\n",
    "import io\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import uuid\n",
    "import warnings\n",
    "import traceback\n",
    "import json  # Added missing import\n",
    "from scipy.spatial.distance import cosine  # Added missing import\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-interactive backend for better memory handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a19c8254",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConceptNetProcessor:\n",
    "    \"\"\"\n",
    "    Process ConceptNet data for semantic visualization\n",
    "    \"\"\"\n",
    "    def __init__(self, english_data=None, german_data=None):\n",
    "        self.english_data = english_data\n",
    "        self.german_data = german_data\n",
    "        self.semantic_graph = nx.DiGraph()\n",
    "        self.concept_vectors = {}\n",
    "        self.relation_types = set()\n",
    "        \n",
    "        print(\"ConceptNetProcessor initialized\")\n",
    "    \n",
    "    def clean_concept_name(self, concept_str):\n",
    "        \"\"\"Extract clean concept name from ConceptNet format\"\"\"\n",
    "        if not isinstance(concept_str, str):\n",
    "            return \"unknown\"\n",
    "            \n",
    "        # Extract the concept name from the ConceptNet URI format\n",
    "        parts = concept_str.split('/')\n",
    "        if len(parts) >= 4:\n",
    "            # Format is typically /c/LANG/CONCEPT\n",
    "            concept = parts[-1]\n",
    "            # Remove part-of-speech tags if present\n",
    "            if '/' in concept:\n",
    "                concept = concept.split('/')[0]\n",
    "            return concept\n",
    "        return concept_str\n",
    "    \n",
    "    def extract_relation_type(self, relation_str):\n",
    "        \"\"\"Extract relation type from ConceptNet format\"\"\"\n",
    "        if not isinstance(relation_str, str):\n",
    "            return \"unknown\"\n",
    "            \n",
    "        parts = relation_str.split('/')\n",
    "        if len(parts) >= 3:\n",
    "            # Format is typically /r/RELATION_TYPE\n",
    "            return parts[-1]\n",
    "        return relation_str\n",
    "    \n",
    "    def extract_language(self, concept_str):\n",
    "        \"\"\"Extract language from ConceptNet concept URI\"\"\"\n",
    "        if not isinstance(concept_str, str):\n",
    "            return \"unknown\"\n",
    "            \n",
    "        parts = concept_str.split('/')\n",
    "        if len(parts) >= 4:\n",
    "            # Format is typically /c/LANG/CONCEPT\n",
    "            return parts[2]\n",
    "        return \"unknown\"\n",
    "    \n",
    "    def parse_weight(self, weight_str):\n",
    "        \"\"\"Parse weight JSON string to extract numeric weight\"\"\"\n",
    "        if not isinstance(weight_str, str):\n",
    "            return 1.0\n",
    "            \n",
    "        try:\n",
    "            weight_data = json.loads(weight_str)\n",
    "            # ConceptNet weights are typically in 'weight' field\n",
    "            return float(weight_data.get('weight', 1.0))\n",
    "        except:\n",
    "            return 1.0\n",
    "    \n",
    "    def build_semantic_graph(self, max_concepts=200, min_weight=1.0, sample_size=0.25):\n",
    "        \"\"\"Build semantic graph from ConceptNet data\"\"\"\n",
    "        print(\"Building semantic graph from ConceptNet data...\")\n",
    "        \n",
    "        if self.english_data is None and self.german_data is None:\n",
    "            print(\"No ConceptNet data provided.\")\n",
    "            return\n",
    "        \n",
    "        # Combine datasets\n",
    "        all_data = []\n",
    "        if self.english_data is not None:\n",
    "            print(f\"Processing {len(self.english_data)} English ConceptNet assertions...\")\n",
    "            sample_size_en = int(len(self.english_data) * sample_size)\n",
    "            print(f\"Will sample {sample_size_en} English assertions\")\n",
    "            all_data.append(('en', self.english_data))\n",
    "        \n",
    "        if self.german_data is not None:\n",
    "            print(f\"Processing {len(self.german_data)} German ConceptNet assertions...\")\n",
    "            sample_size_de = int(len(self.german_data) * sample_size)\n",
    "            print(f\"Will sample {sample_size_de} German assertions\")\n",
    "            all_data.append(('de', self.german_data))\n",
    "        \n",
    "        # Track concepts and their occurrence count\n",
    "        concept_counts = {}\n",
    "        \n",
    "        # Process each language dataset\n",
    "        for lang, data in all_data:\n",
    "            curr_sample_size = int(len(data) * sample_size)\n",
    "            data_sample = data.sample(n=curr_sample_size, random_state=42)\n",
    "            print(f\"Sampling {curr_sample_size} assertions from {len(data)} {lang} assertions\")\n",
    "            \n",
    "            # Process assertions\n",
    "            for _, row in tqdm(data_sample.iterrows(), desc=f\"Processing {lang} assertions\", total=len(data_sample)):\n",
    "                try:\n",
    "                    # Extract source and target concepts\n",
    "                    source_concept = self.clean_concept_name(row['start'])\n",
    "                    target_concept = self.clean_concept_name(row['end'])\n",
    "                    \n",
    "                    # Extract relation type\n",
    "                    relation_type = self.extract_relation_type(row['rel'])\n",
    "                    self.relation_types.add(relation_type)\n",
    "                    \n",
    "                    # Extract languages\n",
    "                    source_lang = self.extract_language(row['start'])\n",
    "                    target_lang = self.extract_language(row['end'])\n",
    "                    \n",
    "                    # Parse weight\n",
    "                    weight = self.parse_weight(row['weight'])\n",
    "                    \n",
    "                    # Skip low-weight relationships\n",
    "                    if weight < min_weight:\n",
    "                        continue\n",
    "                    \n",
    "                    # Track concept occurrences\n",
    "                    concept_counts[source_concept] = concept_counts.get(source_concept, 0) + 1\n",
    "                    concept_counts[target_concept] = concept_counts.get(target_concept, 0) + 1\n",
    "                    \n",
    "                    # Add to graph\n",
    "                    self.semantic_graph.add_node(\n",
    "                        source_concept,\n",
    "                        lang=source_lang,\n",
    "                        count=concept_counts[source_concept]\n",
    "                    )\n",
    "                    \n",
    "                    self.semantic_graph.add_node(\n",
    "                        target_concept,\n",
    "                        lang=target_lang,\n",
    "                        count=concept_counts[target_concept]\n",
    "                    )\n",
    "                    \n",
    "                    # Add edge with relation data\n",
    "                    self.semantic_graph.add_edge(\n",
    "                        source_concept,\n",
    "                        target_concept,\n",
    "                        relation=relation_type,\n",
    "                        weight=weight\n",
    "                    )\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    warnings.warn(f\"Error processing assertion: {e}\")\n",
    "        \n",
    "        # Limit to top concepts if needed\n",
    "        if len(concept_counts) > max_concepts:\n",
    "            print(f\"Limiting graph to top {max_concepts} concepts...\")\n",
    "            top_concepts = sorted(concept_counts.items(), key=lambda x: x[1], reverse=True)[:max_concepts]\n",
    "            top_concept_names = {c[0] for c in top_concepts}\n",
    "            \n",
    "            # Create subgraph with only top concepts\n",
    "            subgraph = nx.DiGraph()\n",
    "            \n",
    "            for node in top_concept_names:\n",
    "                if self.semantic_graph.has_node(node):\n",
    "                    subgraph.add_node(\n",
    "                        node,\n",
    "                        **self.semantic_graph.nodes[node]\n",
    "                    )\n",
    "            \n",
    "            for source, target, data in self.semantic_graph.edges(data=True):\n",
    "                if source in top_concept_names and target in top_concept_names:\n",
    "                    subgraph.add_edge(\n",
    "                        source,\n",
    "                        target,\n",
    "                        **data\n",
    "                    )\n",
    "            \n",
    "            self.semantic_graph = subgraph\n",
    "        \n",
    "        print(f\"Semantic graph built with {self.semantic_graph.number_of_nodes()} nodes and {self.semantic_graph.number_of_edges()} edges\")\n",
    "        \n",
    "        # Infer semantic categories\n",
    "        self.infer_semantic_categories()\n",
    "        \n",
    "        return self.semantic_graph\n",
    "    \n",
    "    def infer_semantic_categories(self):\n",
    "        \"\"\"Infer semantic categories for concepts based on relationships\"\"\"\n",
    "        print(\"Inferring semantic categories...\")\n",
    "        categories = {}\n",
    "        \n",
    "        # Count relationship types for each concept\n",
    "        for node in self.semantic_graph.nodes():\n",
    "            # Initialize as generic\n",
    "            categories[node] = 'generic'\n",
    "            \n",
    "            # Get all relationships involving this concept\n",
    "            in_edges = self.semantic_graph.in_edges(node, data=True)\n",
    "            out_edges = self.semantic_graph.out_edges(node, data=True)\n",
    "            \n",
    "            # Count relationship types\n",
    "            person_relations = 0\n",
    "            place_relations = 0\n",
    "            animal_relations = 0\n",
    "            \n",
    "            for _, _, data in in_edges:\n",
    "                rel = data.get('relation', '')\n",
    "                if rel in {'IsA/person', 'CapableOf', 'HasA'}:\n",
    "                    person_relations += 1\n",
    "                elif rel in {'AtLocation', 'LocatedNear', 'HasA'}:\n",
    "                    place_relations += 1\n",
    "                elif rel in {'IsA/animal', 'CapableOf'}:\n",
    "                    animal_relations += 1\n",
    "            \n",
    "            for _, _, data in out_edges:\n",
    "                rel = data.get('relation', '')\n",
    "                if rel in {'IsA/person', 'CapableOf', 'HasA'}:\n",
    "                    person_relations += 1\n",
    "                elif rel in {'AtLocation', 'LocatedNear', 'HasA'}:\n",
    "                    place_relations += 1\n",
    "                elif rel in {'IsA/animal', 'CapableOf'}:\n",
    "                    animal_relations += 1\n",
    "            \n",
    "            # Assign category based on dominant relationships\n",
    "            max_relations = max(person_relations, place_relations, animal_relations)\n",
    "            if max_relations > 0:\n",
    "                if max_relations == person_relations:\n",
    "                    categories[node] = 'person'\n",
    "                elif max_relations == place_relations:\n",
    "                    categories[node] = 'place'\n",
    "                elif max_relations == animal_relations:\n",
    "                    categories[node] = 'animal'\n",
    "        \n",
    "        # Update graph with categories\n",
    "        nx.set_node_attributes(self.semantic_graph, categories, 'category')\n",
    "        \n",
    "        # Print category statistics\n",
    "        category_counts = {}\n",
    "        for cat in categories.values():\n",
    "            category_counts[cat] = category_counts.get(cat, 0) + 1\n",
    "        print(f\"Inferred categories: {category_counts}\")\n",
    "    \n",
    "    def compute_important_relationships(self, threshold=0.5, max_relationships=30):\n",
    "        \"\"\"Compute the most important relationships between concepts based on vector similarity\"\"\"\n",
    "        important_relationships = []\n",
    "        \n",
    "        # Get all pairs of concepts\n",
    "        concepts = list(self.concept_vectors.keys())\n",
    "        for i, concept1 in enumerate(concepts):\n",
    "            for concept2 in concepts[i+1:]:\n",
    "                # Get vectors\n",
    "                vec1 = self.concept_vectors[concept1]['vector']\n",
    "                vec2 = self.concept_vectors[concept2]['vector']\n",
    "                \n",
    "                # Compute cosine similarity\n",
    "                similarity = 1 - cosine(vec1, vec2)\n",
    "                \n",
    "                if similarity > threshold:\n",
    "                    important_relationships.append({\n",
    "                        'source': concept1,\n",
    "                        'target': concept2,\n",
    "                        'similarity': similarity\n",
    "                    })\n",
    "        \n",
    "        # Sort by similarity and take top N\n",
    "        important_relationships.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "        return important_relationships[:max_relationships]\n",
    "    \n",
    "    def generate_concept_vectors(self, dimensions=5):\n",
    "        \"\"\"Generate concept vectors based on graph structure\"\"\"\n",
    "        print(f\"Generating {dimensions}-dimensional concept vectors...\")\n",
    "        \n",
    "        # Use node2vec or similar embedding\n",
    "        nodes = list(self.semantic_graph.nodes())\n",
    "        \n",
    "        # Simple embedding based on connectivity patterns\n",
    "        adjacency_matrix = nx.adjacency_matrix(self.semantic_graph).todense()\n",
    "        \n",
    "        # Use SVD to reduce dimensionality\n",
    "        U, _, _ = np.linalg.svd(adjacency_matrix)\n",
    "        embeddings = U[:, :dimensions]\n",
    "        \n",
    "        # Normalize embeddings\n",
    "        embeddings = (embeddings - embeddings.mean(axis=0)) / embeddings.std(axis=0)\n",
    "        \n",
    "        # Convert to dictionary with structured data\n",
    "        for i, node in enumerate(nodes):\n",
    "            self.concept_vectors[node] = {\n",
    "                'vector': embeddings[i],\n",
    "                'category': self.semantic_graph.nodes[node].get('category', 'generic')\n",
    "            }\n",
    "        \n",
    "        print(f\"Generated vectors for {len(self.concept_vectors)} concepts\")\n",
    "        return self.concept_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eb322a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SemanticVisualizer:\n",
    "    def __init__(self, concept_processor=None):\n",
    "        self.concept_processor = concept_processor\n",
    "        self.fig = None\n",
    "        self.ax = None\n",
    "        self.category_colors = {\n",
    "            'person': '#FF6B6B',  # Warm red\n",
    "            'place': '#4ECDC4',   # Teal\n",
    "            'animal': '#FFD93D',  # Bright yellow\n",
    "            'generic': '#95A5A6'  # Neutral gray\n",
    "        }\n",
    "        self.category_descriptions = {\n",
    "            'person': 'Human Entities & Roles',\n",
    "            'place': 'Locations & Spaces',\n",
    "            'animal': 'Living Creatures',\n",
    "            'generic': 'Abstract Concepts'\n",
    "        }\n",
    "\n",
    "    def visualize_concepts_improved(self, output_dir, num_frames=30):\n",
    "        \"\"\"Create an enhanced visualization with labels, legends, and smooth transitions\"\"\"\n",
    "        try:\n",
    "            print(\"Creating enhanced semantic visualization...\")\n",
    "            \n",
    "            if not self.concept_processor or not self.concept_processor.concept_vectors:\n",
    "                raise ValueError(\"Concept processor not initialized or no vectors generated\")\n",
    "            \n",
    "            # Get important relationships\n",
    "            try:\n",
    "                important_relationships = self.concept_processor.compute_important_relationships(\n",
    "                    threshold=0.5, \n",
    "                    max_relationships=30\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not compute relationships: {str(e)}\")\n",
    "                important_relationships = []\n",
    "\n",
    "            # Setup figure with high DPI for crisp text\n",
    "            plt.close('all')\n",
    "            fig = plt.figure(figsize=(20, 14), facecolor='black', dpi=150)\n",
    "            ax = fig.add_subplot(111, projection='3d', facecolor='black')\n",
    "            \n",
    "            # Add a title with project info\n",
    "            fig.suptitle('Semantic Concept Space Visualization\\nRelational Semantic Convergence (RSC) Theory', \n",
    "                        color='white', y=0.95, fontsize=16, fontweight='bold')\n",
    "\n",
    "            def update(frame):\n",
    "                try:\n",
    "                    ax.clear()\n",
    "                    ax.set_facecolor('black')\n",
    "                    \n",
    "                    # Configure axis appearance\n",
    "                    ax.grid(True, alpha=0.1, color='white')\n",
    "                    ax.xaxis.pane.fill = False\n",
    "                    ax.yaxis.pane.fill = False\n",
    "                    ax.zaxis.pane.fill = False\n",
    "                    \n",
    "                    # Remove axis labels but keep tick marks\n",
    "                    ax.set_xticklabels([])\n",
    "                    ax.set_yticklabels([])\n",
    "                    ax.set_zticklabels([])\n",
    "                    \n",
    "                    # Calculate smooth rotation angle\n",
    "                    theta = (frame / num_frames) * 2 * np.pi\n",
    "                    \n",
    "                    # Convert concept vectors to 3D points with rotation\n",
    "                    points = {}\n",
    "                    for concept, data in self.concept_processor.concept_vectors.items():\n",
    "                        vector = data['vector'][:3]\n",
    "                        \n",
    "                        # Apply smooth rotation matrix\n",
    "                        x, y, z = vector\n",
    "                        x_rot = x * np.cos(theta) - y * np.sin(theta)\n",
    "                        y_rot = x * np.sin(theta) + y * np.cos(theta)\n",
    "                        \n",
    "                        points[concept] = (x_rot, y_rot, z)\n",
    "                    \n",
    "                    # Plot points by category with enhanced visual elements\n",
    "                    legend_elements = []\n",
    "                    for category, color in self.category_colors.items():\n",
    "                        cat_points = [\n",
    "                            (concept, (x, y, z)) for concept, (x, y, z) in points.items()\n",
    "                            if self.concept_processor.concept_vectors[concept]['category'] == category\n",
    "                        ]\n",
    "                        \n",
    "                        if cat_points:\n",
    "                            concepts, coords = zip(*cat_points)\n",
    "                            xs, ys, zs = zip(*coords)\n",
    "                            \n",
    "                            # Create scatter plot with glowing effect\n",
    "                            scatter = ax.scatter(xs, ys, zs, \n",
    "                                              c=color, \n",
    "                                              alpha=0.8, \n",
    "                                              s=100,  # Larger points\n",
    "                                              edgecolors='white',\n",
    "                                              linewidth=0.5)\n",
    "                            \n",
    "                            # Add category to legend\n",
    "                            legend_elements.append(plt.Line2D([0], [0], \n",
    "                                                            marker='o', \n",
    "                                                            color='none',\n",
    "                                                            markerfacecolor=color,\n",
    "                                                            markeredgecolor='white',\n",
    "                                                            markersize=10,\n",
    "                                                            label=self.category_descriptions[category]))\n",
    "                            \n",
    "                            # Add labels for important concepts\n",
    "                            for concept, (x, y, z) in zip(concepts, coords):\n",
    "                                if len(concept) > 2:  # Only label non-trivial concepts\n",
    "                                    ax.text(x, y, z, \n",
    "                                          concept,\n",
    "                                          color='white',\n",
    "                                          fontsize=8,\n",
    "                                          alpha=0.7,\n",
    "                                          backgroundcolor=(0, 0, 0, 0.3))\n",
    "                    \n",
    "                    # Add connections between related concepts\n",
    "                    if important_relationships and frame == 0:  # Only on first frame for performance\n",
    "                        for rel in important_relationships[:10]:  # Limit to top 10 relationships\n",
    "                            if rel['source'] in points and rel['target'] in points:\n",
    "                                x1, y1, z1 = points[rel['source']]\n",
    "                                x2, y2, z2 = points[rel['target']]\n",
    "                                ax.plot([x1, x2], [y1, y2], [z1, z2], \n",
    "                                      color='white',\n",
    "                                      alpha=0.2,\n",
    "                                      linestyle='--')\n",
    "                    \n",
    "                    # Add legend with enhanced styling\n",
    "                    legend = ax.legend(handles=legend_elements,\n",
    "                                     loc='center left',\n",
    "                                     bbox_to_anchor=(1.15, 0.5),\n",
    "                                     title='Semantic Categories',\n",
    "                                     facecolor='black',\n",
    "                                     edgecolor='white',\n",
    "                                     framealpha=0.8)\n",
    "                    legend.get_title().set_color('white')\n",
    "                    for text in legend.get_texts():\n",
    "                        text.set_color('white')\n",
    "                    \n",
    "                    # Add RSC theory info\n",
    "                    ax.text2D(0.02, 0.02, \n",
    "                             'RSC Theory Visualization\\nShowing semantic relationships and concept clustering',\n",
    "                             transform=ax.transAxes,\n",
    "                             color='white',\n",
    "                             alpha=0.7,\n",
    "                             fontsize=8)\n",
    "                    \n",
    "                    return ax\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error in update frame {frame}: {str(e)}\")\n",
    "                    return ax\n",
    "\n",
    "            # Create animation with enhanced parameters\n",
    "            anim = animation.FuncAnimation(\n",
    "                fig, \n",
    "                update,\n",
    "                frames=num_frames,\n",
    "                interval=50,  # Faster frame rate for smoother animation\n",
    "                blit=False\n",
    "            )\n",
    "            \n",
    "            # Create a static preview image\n",
    "            print(\"Creating enhanced static preview...\")\n",
    "            update(0)\n",
    "            \n",
    "            # Save with high quality settings\n",
    "            static_path = os.path.join(output_dir, f'semantica_readable_preview_{uuid.uuid4()}.png')\n",
    "            plt.savefig(static_path, dpi=150, bbox_inches='tight')\n",
    "            \n",
    "            # Save animation with enhanced quality\n",
    "            output_path = os.path.join(output_dir, f'semantica_readable_{uuid.uuid4()}.gif')\n",
    "            # Use a more robust method to save the animation\n",
    "            frames = []\n",
    "            frame_files = []  # Keep track of temporary files\n",
    "            tmp_dir = os.path.join(output_dir, 'tmp_frames')\n",
    "            \n",
    "            # Create temporary directory for frames\n",
    "            if not os.path.exists(tmp_dir):\n",
    "                os.makedirs(tmp_dir)\n",
    "                \n",
    "            try:\n",
    "                print(\"Generating frames...\")\n",
    "                for i in range(num_frames):\n",
    "                    # Update the figure for this frame\n",
    "                    update(i)\n",
    "                    \n",
    "                    # Save frame to a temporary file instead of keeping in memory\n",
    "                    tmp_file = os.path.join(tmp_dir, f'frame_{i:04d}.png')\n",
    "                    plt.savefig(tmp_file, dpi=150, bbox_inches='tight',\n",
    "                               facecolor=self.bg_gradient['bottom'])\n",
    "                    frame_files.append(tmp_file)\n",
    "                    \n",
    "                    # Print progress\n",
    "                    if i % 10 == 0 or i == num_frames - 1:\n",
    "                        print(f\"Generated frame {i+1}/{num_frames}\")\n",
    "                \n",
    "                # Create GIF using external library\n",
    "                print(\"Saving animation...\")\n",
    "                from PIL import Image\n",
    "                \n",
    "                # Load all frames from files\n",
    "                frames = [Image.open(f) for f in frame_files]\n",
    "                \n",
    "                # Ensure all frames are the same size\n",
    "                if frames:\n",
    "                    size = frames[0].size\n",
    "                    frames = [f.resize(size) for f in frames]\n",
    "                    \n",
    "                    # Save as GIF\n",
    "                    frames[0].save(\n",
    "                        output_path,\n",
    "                        save_all=True,\n",
    "                        append_images=frames[1:],\n",
    "                        optimize=False,\n",
    "                        duration=1000/30,  # 30 FPS\n",
    "                        loop=0\n",
    "                    )\n",
    "                    \n",
    "                    # Close all frames\n",
    "                    for f in frames:\n",
    "                        f.close()\n",
    "                    \n",
    "                    print(f\"Enhanced visualization saved successfully to {output_path}\")\n",
    "            finally:\n",
    "                # Clean up temporary files\n",
    "                for file in frame_files:\n",
    "                    try:\n",
    "                        if os.path.exists(file):\n",
    "                            os.remove(file)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Warning: Could not remove temporary file {file}: {e}\")\n",
    "                        \n",
    "                # Try to remove temp directory\n",
    "                try:\n",
    "                    if os.path.exists(tmp_dir):\n",
    "                        os.rmdir(tmp_dir)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not remove temporary directory: {e}\")\n",
    "            \n",
    "            plt.close()\n",
    "            return output_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating visualization: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6ca1289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ConceptNetProcessor with loaded datasets...\n",
      "ConceptNetProcessor initialized\n",
      "Building semantic graph from ConceptNet data...\n",
      "Processing 3423004 English ConceptNet assertions...\n",
      "Will sample 171150 English assertions\n",
      "Processing 1078946 German ConceptNet assertions...\n",
      "Will sample 53947 German assertions\n",
      "Sampling 171150 assertions from 3423004 en assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing en assertions: 100%|██████████| 171150/171150 [00:04<00:00, 39983.64it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 53947 assertions from 1078946 de assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing de assertions: 100%|██████████| 53947/53947 [00:01<00:00, 36625.40it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limiting graph to top 100 concepts...\n",
      "Semantic graph built with 100 nodes and 697 edges\n",
      "Inferring semantic categories...\n",
      "Inferred categories: {'generic': 100}\n",
      "Generating 5-dimensional concept vectors...\n",
      "Generated vectors for 100 concepts\n",
      "Creating enhanced semantic visualization...\n",
      "Creating enhanced static preview...\n",
      "Generating frames...\n",
      "Error creating visualization: 'SemanticVisualizer' object has no attribute 'bg_gradient'\n",
      "Visualization created at: None\n",
      "Generating frames...\n",
      "Error creating visualization: 'SemanticVisualizer' object has no attribute 'bg_gradient'\n",
      "Visualization created at: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Erich Curtis\\AppData\\Local\\Temp\\ipykernel_61348\\574494523.py\", line 190, in visualize_concepts_improved\n",
      "    facecolor=self.bg_gradient['bottom'])\n",
      "              ^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'SemanticVisualizer' object has no attribute 'bg_gradient'\n"
     ]
    }
   ],
   "source": [
    "# Initialize processor with the datasets we loaded at the beginning\n",
    "print(\"Initializing ConceptNetProcessor with loaded datasets...\")\n",
    "processor = ConceptNetProcessor(english_conceptnet, german_conceptnet)\n",
    "\n",
    "# Build semantic graph with 25% sampling\n",
    "processor.build_semantic_graph(\n",
    "    max_concepts=100,  # Keep reasonable number of concepts for visualization\n",
    "    min_weight=1.0,\n",
    "    sample_size=0.05  # Use 25% of the data\n",
    ")\n",
    "\n",
    "# Generate concept vectors\n",
    "processor.generate_concept_vectors(dimensions=5)\n",
    "\n",
    "# Initialize visualizer\n",
    "visualizer = SemanticVisualizer(processor)\n",
    "\n",
    "# Create improved visualization with more frames for smoother animation\n",
    "output_path = visualizer.visualize_concepts_improved(\n",
    "    output_dir,\n",
    "    num_frames=300  # Increased number of frames for smoother animation\n",
    ")\n",
    "\n",
    "print(f\"Visualization created at: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bda2ec4",
   "metadata": {},
   "source": [
    "# Phase 2: Enhanced Visualization\n",
    "\n",
    "Based on feedback, we're improving the visualization to make it more intuitive and appealing for both technical and general audiences. Key enhancements include:\n",
    "\n",
    "1. **Progress indicator** - Shows current frame and total frames so viewers know where they are in the animation\n",
    "2. **Improved visual relationships** - Clear connection lines between related concepts with directional arrows\n",
    "3. **Interactive elements** - Hover tooltips and concept highlighting (for interactive environments)\n",
    "4. **Better storytelling** - Explanatory text and conceptual grouping visualizations\n",
    "5. **Visual appeal** - Enhanced color scheme, lighting effects, and background gradients\n",
    "6. **Clearer concept representation** - Size nodes based on importance, add labels for key concepts\n",
    "7. **Animation transitions** - Smoother transitions and camera movements between frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e717fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedSemanticVisualizer:\n",
    "    def __init__(self, concept_processor=None):\n",
    "        self.concept_processor = concept_processor\n",
    "        self.fig = None\n",
    "        self.ax = None\n",
    "        # Enhanced color palette with deeper, more vibrant colors\n",
    "        self.category_colors = {\n",
    "            'person': '#FF5E7E',     # Vibrant pink/red\n",
    "            'place': '#36EAFF',      # Bright cyan\n",
    "            'animal': '#FFDD3C',     # Golden yellow\n",
    "            'generic': '#B8C6DB'     # Soft lavender\n",
    "        }\n",
    "        # More descriptive category labels\n",
    "        self.category_descriptions = {\n",
    "            'person': 'Human Concepts & Relationships',\n",
    "            'place': 'Spatial & Location Concepts',\n",
    "            'animal': 'Living Entities & Nature',\n",
    "            'generic': 'Abstract & General Concepts'\n",
    "        }\n",
    "        # Background gradient colors\n",
    "        self.bg_gradient = {\n",
    "            'top': '#0F2027',       # Dark blue-black\n",
    "            'middle': '#203A43',    # Deep teal\n",
    "            'bottom': '#2C5364'     # Navy blue\n",
    "        }\n",
    "        # Store background rectangles\n",
    "        self.bg_rects = []\n",
    "        # Store progress indicator elements\n",
    "        self.progress_elements = []\n",
    "        \n",
    "    def _create_background_gradient(self, fig, ax):\n",
    "        \"\"\"Create a beautiful gradient background\"\"\"\n",
    "        # Clear any existing background rectangles\n",
    "        for rect in self.bg_rects:\n",
    "            if rect in fig.patches:\n",
    "                fig.patches.remove(rect)\n",
    "        self.bg_rects = []\n",
    "        \n",
    "        # Create new background rectangles\n",
    "        bottom_rect = plt.Rectangle(\n",
    "            (0, 0), 1, 1,\n",
    "            transform=fig.transFigure,\n",
    "            color=self.bg_gradient['bottom'],\n",
    "            alpha=0.9, zorder=-1\n",
    "        )\n",
    "        middle_rect = plt.Rectangle(\n",
    "            (0, 0.3), 1, 0.4,\n",
    "            transform=fig.transFigure,\n",
    "            color=self.bg_gradient['middle'],\n",
    "            alpha=0.7, zorder=-1\n",
    "        )\n",
    "        top_rect = plt.Rectangle(\n",
    "            (0, 0.7), 1, 0.3,\n",
    "            transform=fig.transFigure,\n",
    "            color=self.bg_gradient['top'],\n",
    "            alpha=0.8, zorder=-1\n",
    "        )\n",
    "        \n",
    "        # Add rectangles to figure\n",
    "        fig.patches.extend([bottom_rect, middle_rect, top_rect])\n",
    "        self.bg_rects = [bottom_rect, middle_rect, top_rect]\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def _add_progress_indicator(self, fig, frame, total_frames):\n",
    "        \"\"\"Add a visual progress indicator showing current frame and total\"\"\"\n",
    "        # Clear previous progress indicator elements\n",
    "        for element in self.progress_elements:\n",
    "            if isinstance(element, matplotlib.text.Text) and element in fig.texts:\n",
    "                fig.texts.remove(element)\n",
    "            elif isinstance(element, matplotlib.patches.Rectangle) and element in fig.patches:\n",
    "                fig.patches.remove(element)\n",
    "        self.progress_elements = []\n",
    "                \n",
    "        # Calculate percentage complete\n",
    "        percentage = (frame / total_frames) * 100\n",
    "        \n",
    "        # Create progress text\n",
    "        progress_text = fig.text(\n",
    "            0.01, 0.01,\n",
    "            f\"Frame: {frame+1}/{total_frames} ({percentage:.1f}%)\",\n",
    "            color='white',\n",
    "            fontsize=10,\n",
    "            alpha=0.8,\n",
    "            transform=fig.transFigure\n",
    "        )\n",
    "        self.progress_elements.append(progress_text)\n",
    "        \n",
    "        # Add progress bar background\n",
    "        progress_bar_bg = plt.Rectangle(\n",
    "            (0.01, 0.03), 0.2, 0.01,\n",
    "            transform=fig.transFigure,\n",
    "            color='white', alpha=0.3\n",
    "        )\n",
    "        fig.patches.append(progress_bar_bg)\n",
    "        self.progress_elements.append(progress_bar_bg)\n",
    "        \n",
    "        # Add progress bar fill\n",
    "        progress_bar_fill = plt.Rectangle(\n",
    "            (0.01, 0.03), 0.2 * (frame / total_frames), 0.01,\n",
    "            transform=fig.transFigure,\n",
    "            color='#36EAFF', alpha=0.8\n",
    "        )\n",
    "        fig.patches.append(progress_bar_fill)\n",
    "        self.progress_elements.append(progress_bar_fill)\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def _add_relationship_lines(self, ax, points, important_relationships, frame_pct):\n",
    "        \"\"\"Add visually appealing relationship lines between concepts\"\"\"\n",
    "        # Only show the top relationships for clarity\n",
    "        if not important_relationships:\n",
    "            return ax\n",
    "            \n",
    "        # Create a pulsing effect based on frame percentage\n",
    "        pulse = 0.5 + 0.5 * np.sin(frame_pct * 2 * np.pi * 2)  # 2 pulses per cycle\n",
    "        \n",
    "        # Draw connections with gradient colors and pulse effect\n",
    "        for i, rel in enumerate(important_relationships[:15]):  # Limit to top relationships\n",
    "            if rel['source'] in points and rel['target'] in points:\n",
    "                src = points[rel['source']]\n",
    "                tgt = points[rel['target']]\n",
    "                \n",
    "                # Gradually reveal relationships throughout the animation\n",
    "                reveal_threshold = i / 15  # Stagger appearance\n",
    "                if frame_pct < reveal_threshold:\n",
    "                    continue\n",
    "                    \n",
    "                # Calculate line alpha based on similarity strength and pulse\n",
    "                alpha = min(0.7, rel['similarity'] * pulse)\n",
    "                \n",
    "                # Determine relationship color based on similarity\n",
    "                if rel['similarity'] > 0.8:\n",
    "                    color = '#FF5E7E'  # Strong relationship - pink\n",
    "                elif rel['similarity'] > 0.65:\n",
    "                    color = '#36EAFF'  # Medium relationship - cyan\n",
    "                else:\n",
    "                    color = '#FFFFFF'  # Weak relationship - white\n",
    "                    \n",
    "                # Draw the relationship line with gradient effect\n",
    "                line = ax.plot([src[0], tgt[0]], [src[1], tgt[1]], [src[2], tgt[2]],\n",
    "                      color=color,\n",
    "                      alpha=alpha,\n",
    "                      linewidth=1.5,\n",
    "                      zorder=1)\n",
    "                \n",
    "                # Add small arrow to indicate relationship direction\n",
    "                if rel['similarity'] > 0.7:  # Only for stronger relationships\n",
    "                    # Calculate midpoint with slight offset toward target\n",
    "                    midpoint = tuple(0.6*src[i] + 0.4*tgt[i] for i in range(3))\n",
    "                    \n",
    "                    # Draw small sphere at midpoint to represent connection type\n",
    "                    ax.scatter([midpoint[0]], [midpoint[1]], [midpoint[2]],\n",
    "                             color=color,\n",
    "                             s=30,\n",
    "                             alpha=alpha*1.2,\n",
    "                             edgecolors='white',\n",
    "                             linewidth=0.5)\n",
    "        \n",
    "        return ax\n",
    "        \n",
    "    def _add_glow_effect(self, ax, xs, ys, zs, color, size):\n",
    "        \"\"\"Add a subtle glow effect to make points more visually appealing\"\"\"\n",
    "        # Create glow by adding multiple layers of decreasing opacity\n",
    "        for glow_size, alpha in [(size*3, 0.03), (size*2, 0.05), (size*1.5, 0.1)]:\n",
    "            ax.scatter(xs, ys, zs,\n",
    "                     color=color,\n",
    "                     s=glow_size,\n",
    "                     alpha=alpha,\n",
    "                     edgecolors='none')\n",
    "        \n",
    "        return ax\n",
    "    \n",
    "    def _add_explanatory_elements(self, fig, ax, frame_pct):\n",
    "        \"\"\"Add explanatory text and visual elements to guide understanding\"\"\"\n",
    "        # Title with project info and frame context\n",
    "        title_txt = fig.text(\n",
    "            0.5, 0.95,\n",
    "            'Semantic Concept Space Visualization',\n",
    "            ha='center',\n",
    "            color='white',\n",
    "            fontsize=18,\n",
    "            fontweight='bold',\n",
    "            alpha=0.9,\n",
    "            transform=fig.transFigure\n",
    "        )\n",
    "        \n",
    "        # Subtitle with RSC theory explanation\n",
    "        subtitle_txt = fig.text(\n",
    "            0.5, 0.92,\n",
    "            'Relational Semantic Convergence (RSC) Theory',\n",
    "            ha='center',\n",
    "            color='white',\n",
    "            fontsize=14,\n",
    "            fontweight='normal',\n",
    "            alpha=0.8,\n",
    "            transform=fig.transFigure\n",
    "        )\n",
    "        \n",
    "        # Rotating explanation text that changes throughout the animation\n",
    "        explanations = [\n",
    "            \"Visualizing how concepts form relationships in semantic space\",\n",
    "            \"Connected concepts share semantic properties and relationships\",\n",
    "            \"Colored clusters represent different semantic categories\",\n",
    "            \"Discover how meaning emerges from conceptual connections\"\n",
    "        ]\n",
    "        \n",
    "        # Select explanation based on frame position\n",
    "        explanation_idx = int(frame_pct * len(explanations)) % len(explanations)\n",
    "        explanation_txt = fig.text(\n",
    "            0.5, 0.89,\n",
    "            explanations[explanation_idx],\n",
    "            ha='center',\n",
    "            color='white',\n",
    "            fontsize=11,\n",
    "            fontstyle='italic',\n",
    "            alpha=0.7,\n",
    "            transform=fig.transFigure\n",
    "        )\n",
    "        \n",
    "        # Add a visual indicator for rotation direction\n",
    "        arrow_angle = frame_pct * 2 * np.pi\n",
    "        arrow_x = 0.97 + 0.02 * np.cos(arrow_angle)\n",
    "        arrow_y = 0.5 + 0.02 * np.sin(arrow_angle)\n",
    "        rotation_indicator = fig.text(\n",
    "            0.97, 0.5,\n",
    "            '↻',  # Rotation symbol\n",
    "            ha='center',\n",
    "            va='center',\n",
    "            color='white',\n",
    "            fontsize=14,\n",
    "            alpha=0.6,\n",
    "            transform=fig.transFigure\n",
    "        )\n",
    "        \n",
    "        # Add copyright and attribution\n",
    "        fig.text(\n",
    "            0.99, 0.01,\n",
    "            '© Semantica RSC Project ' + time.strftime('%Y'),\n",
    "            ha='right',\n",
    "            color='white',\n",
    "            fontsize=8,\n",
    "            alpha=0.5,\n",
    "            transform=fig.transFigure\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def _add_visual_cues(self, ax, points, frame_pct):\n",
    "        \"\"\"Add visual cues to highlight important features\"\"\"\n",
    "        # Find the most central points to highlight\n",
    "        center = np.array([0, 0, 0])\n",
    "        distances = {concept: np.linalg.norm(np.array(pos) - center) \n",
    "                    for concept, pos in points.items()}\n",
    "        \n",
    "        # Get 3 closest points to center\n",
    "        central_concepts = sorted(distances.items(), key=lambda x: x[1])[:3]\n",
    "        \n",
    "        # Highlight these central concepts with pulsing focus rings\n",
    "        pulse = 0.5 + 0.5 * np.sin(frame_pct * 2 * np.pi * 3)  # 3 pulses per cycle\n",
    "        \n",
    "        for concept, distance in central_concepts:\n",
    "            if concept in points:\n",
    "                x, y, z = points[concept]\n",
    "                \n",
    "                # Draw focus ring\n",
    "                theta = np.linspace(0, 2*np.pi, 20)\n",
    "                radius = 0.2 + 0.05 * pulse\n",
    "                \n",
    "                # Create a small circle around the point\n",
    "                circle_x = x + radius * np.cos(theta)\n",
    "                circle_y = y + radius * np.sin(theta)\n",
    "                circle_z = np.full_like(theta, z)\n",
    "                \n",
    "                ax.plot(circle_x, circle_y, circle_z, \n",
    "                      color='white', \n",
    "                      alpha=0.3*pulse,\n",
    "                      linewidth=1)\n",
    "        \n",
    "        return ax\n",
    "    \n",
    "    def visualize_concepts_enhanced(self, output_dir, num_frames=60):\n",
    "        \"\"\"Create a highly enhanced visualization with improved visual appeal and clarity\"\"\"\n",
    "        try:\n",
    "            print(\"Creating enhanced semantic visualization...\")\n",
    "            \n",
    "            if not self.concept_processor or not self.concept_processor.concept_vectors:\n",
    "                raise ValueError(\"Concept processor not initialized or no vectors generated\")\n",
    "            \n",
    "            # Get important relationships\n",
    "            try:\n",
    "                important_relationships = self.concept_processor.compute_important_relationships(\n",
    "                    threshold=0.5, \n",
    "                    max_relationships=30\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not compute relationships: {str(e)}\")\n",
    "                important_relationships = []\n",
    "\n",
    "            # Setup figure with high DPI for crisp text\n",
    "            plt.close('all')\n",
    "            fig = plt.figure(figsize=(16, 12), dpi=150)\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            \n",
    "            # Apply the background gradient\n",
    "            self._create_background_gradient(fig, ax)\n",
    "            \n",
    "            # Calculate node importance based on connectivity\n",
    "            node_importance = {}\n",
    "            for concept in self.concept_processor.concept_vectors.keys():\n",
    "                # Count occurrences in important relationships\n",
    "                count = sum(1 for rel in important_relationships \n",
    "                           if rel['source'] == concept or rel['target'] == concept)\n",
    "                node_importance[concept] = 30 + (count * 20)  # Base size + importance factor\n",
    "            \n",
    "            # Lists to keep track of text objects\n",
    "            text_objects = []\n",
    "            \n",
    "            def update(frame):\n",
    "                try:\n",
    "                    # Clear previous frame\n",
    "                    ax.clear()\n",
    "                    \n",
    "                    # Handle text objects removal more safely\n",
    "                    for txt in fig.texts[:]:\n",
    "                        fig.texts.remove(txt)\n",
    "                    \n",
    "                    # Calculate frame percentage for animations\n",
    "                    frame_pct = frame / num_frames\n",
    "                    \n",
    "                    # Configure axis appearance\n",
    "                    ax.grid(False)  # Remove grid for cleaner look\n",
    "                    ax.xaxis.pane.fill = False\n",
    "                    ax.yaxis.pane.fill = False\n",
    "                    ax.zaxis.pane.fill = False\n",
    "                    \n",
    "                    # Make panes completely transparent\n",
    "                    ax.xaxis.pane.set_edgecolor('none')\n",
    "                    ax.yaxis.pane.set_edgecolor('none')\n",
    "                    ax.zaxis.pane.set_edgecolor('none')\n",
    "                    \n",
    "                    # Remove axis labels and ticks for cleaner look\n",
    "                    ax.set_xticklabels([])\n",
    "                    ax.set_yticklabels([])\n",
    "                    ax.set_zticklabels([])\n",
    "                    ax.set_xticks([])\n",
    "                    ax.set_yticks([])\n",
    "                    ax.set_zticks([])\n",
    "                    \n",
    "                    # Calculate dynamic camera angle for smoother rotation\n",
    "                    theta = frame_pct * 2 * np.pi\n",
    "                    phi = 0.2 * np.sin(frame_pct * 2 * np.pi * 0.5) + 0.3  # Gentle up/down motion\n",
    "                    \n",
    "                    # Set viewing angle with smooth transitions\n",
    "                    ax.view_init(30 + 5 * np.sin(phi), 45 + 180 * frame_pct)\n",
    "                    \n",
    "                    # Convert concept vectors to 3D points with dynamic positioning\n",
    "                    points = {}\n",
    "                    for concept, data in self.concept_processor.concept_vectors.items():\n",
    "                        vector = data['vector'][:3]\n",
    "                        \n",
    "                        # Apply dynamic rotation matrix\n",
    "                        x, y, z = vector\n",
    "                        x_rot = x * np.cos(theta) - y * np.sin(theta)\n",
    "                        y_rot = x * np.sin(theta) + y * np.cos(theta)\n",
    "                        z_rot = z + 0.05 * np.sin(theta * 2 + x)  # Add gentle wave motion\n",
    "                        \n",
    "                        points[concept] = (x_rot, y_rot, z_rot)\n",
    "                    \n",
    "                    # Add relationship lines first (so they appear behind points)\n",
    "                    self._add_relationship_lines(ax, points, important_relationships, frame_pct)\n",
    "                    \n",
    "                    # Plot points by category with enhanced visual elements\n",
    "                    legend_elements = []\n",
    "                    for category, color in self.category_colors.items():\n",
    "                        cat_points = [\n",
    "                            (concept, points[concept], node_importance[concept]) \n",
    "                            for concept in self.concept_processor.concept_vectors\n",
    "                            if concept in points and \n",
    "                            self.concept_processor.concept_vectors[concept]['category'] == category\n",
    "                        ]\n",
    "                        \n",
    "                        if cat_points:\n",
    "                            # Split the data for plotting\n",
    "                            concepts, coords, sizes = zip(*cat_points)\n",
    "                            xs, ys, zs = zip(*coords)\n",
    "                            \n",
    "                            # Add glow effect for nicer visuals\n",
    "                            self._add_glow_effect(ax, xs, ys, zs, color, 30)\n",
    "                            \n",
    "                            # Create scatter plot with improved styling\n",
    "                            scatter = ax.scatter(xs, ys, zs, \n",
    "                                              c=color, \n",
    "                                              alpha=0.9, \n",
    "                                              s=sizes,  # Size based on importance\n",
    "                                              edgecolors='white',\n",
    "                                              linewidth=0.5,\n",
    "                                              zorder=10)\n",
    "                            \n",
    "                            # Add category to legend with improved styling\n",
    "                            legend_elements.append(plt.Line2D(\n",
    "                                [0], [0], \n",
    "                                marker='o', \n",
    "                                color='none',\n",
    "                                markerfacecolor=color,\n",
    "                                markeredgecolor='white',\n",
    "                                markersize=10,\n",
    "                                label=self.category_descriptions[category]))\n",
    "                            \n",
    "                            # Add labels for important concepts with improved styling\n",
    "                            for concept, (x, y, z), size in zip(concepts, coords, sizes):\n",
    "                                # Only label significant concepts for clarity\n",
    "                                if len(concept) > 2 and size > 50:  # Important nodes with meaningful names\n",
    "                                    # Calculate label transparency based on size\n",
    "                                    label_alpha = min(0.9, size / 100)\n",
    "                                    \n",
    "                                    # Create more visible text with better contrast\n",
    "                                    ax.text(x, y, z + 0.05,  # Slight offset\n",
    "                                          concept,\n",
    "                                          color='white',\n",
    "                                          fontsize=8,\n",
    "                                          fontweight='bold',\n",
    "                                          alpha=label_alpha,\n",
    "                                          backgroundcolor=(0, 0, 0, 0.4),\n",
    "                                          ha='center',\n",
    "                                          zorder=20)\n",
    "                    \n",
    "                    # Add visual cues to highlight key areas\n",
    "                    self._add_visual_cues(ax, points, frame_pct)\n",
    "                    \n",
    "                    # Add legend with enhanced styling\n",
    "                    legend = ax.legend(handles=legend_elements,\n",
    "                                     loc='upper right',\n",
    "                                     bbox_to_anchor=(0.99, 0.99),\n",
    "                                     title='Semantic Categories',\n",
    "                                     facecolor=(0.1, 0.1, 0.1, 0.7),\n",
    "                                     edgecolor='white',\n",
    "                                     fontsize=10)\n",
    "                    \n",
    "                    if legend:\n",
    "                        legend.get_title().set_color('white')\n",
    "                        for text in legend.get_texts():\n",
    "                            text.set_color('white')\n",
    "                    \n",
    "                    # Add progress indicator\n",
    "                    self._add_progress_indicator(fig, frame, num_frames)\n",
    "                    \n",
    "                    # Add explanatory text and elements\n",
    "                    self._add_explanatory_elements(fig, ax, frame_pct)\n",
    "                    \n",
    "                    return fig\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error in update frame {frame}: {str(e)}\")\n",
    "                    traceback.print_exc()\n",
    "                    return fig\n",
    "\n",
    "            # Create animation with enhanced parameters\n",
    "            anim = animation.FuncAnimation(\n",
    "                fig, \n",
    "                update,\n",
    "                frames=num_frames,\n",
    "                interval=40,  # Faster frame rate for smoother animation\n",
    "                blit=False\n",
    "            )\n",
    "            \n",
    "            # Create a static preview image\n",
    "            print(\"Creating enhanced static preview...\")\n",
    "            update(0)\n",
    "            \n",
    "            # Save with high quality settings\n",
    "            static_path = os.path.join(output_dir, f'semantica_enhanced_preview_{uuid.uuid4()}.png')\n",
    "            plt.savefig(static_path, dpi=150, bbox_inches='tight')\n",
    "            print(f\"Preview image saved to: {static_path}\")\n",
    "            \n",
    "            # Save animation with enhanced quality\n",
    "            output_path = os.path.join(output_dir, f'semantica_enhanced_{uuid.uuid4()}.gif')\n",
    "            print(f\"Generating animation (this may take some time)...\")\n",
    "            \n",
    "            # Add a timestamp to the animation\n",
    "            timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            fig.text(\n",
    "                0.5, 0.01,\n",
    "                f\"Generated: {timestamp}\",\n",
    "                ha='center',\n",
    "                color='white',\n",
    "                fontsize=8,\n",
    "                alpha=0.6,\n",
    "                transform=fig.transFigure\n",
    "            )\n",
    "            \n",
    "            # Use a more robust method to save the animation\n",
    "            frames = []\n",
    "            frame_files = []  # Keep track of temporary files\n",
    "            tmp_dir = os.path.join(output_dir, 'tmp_frames')\n",
    "            \n",
    "            # Create temporary directory for frames\n",
    "            if not os.path.exists(tmp_dir):\n",
    "                os.makedirs(tmp_dir)\n",
    "                \n",
    "            try:\n",
    "                print(\"Generating frames...\")\n",
    "                for i in range(num_frames):\n",
    "                    # Update the figure for this frame\n",
    "                    update(i)\n",
    "                    \n",
    "                    # Save frame to a temporary file instead of keeping in memory\n",
    "                    tmp_file = os.path.join(tmp_dir, f'frame_{i:04d}.png')\n",
    "                    plt.savefig(tmp_file, dpi=150, bbox_inches='tight',\n",
    "                               facecolor=self.bg_gradient['bottom'])\n",
    "                    frame_files.append(tmp_file)\n",
    "                    \n",
    "                    # Print progress\n",
    "                    if i % 10 == 0 or i == num_frames - 1:\n",
    "                        print(f\"Generated frame {i+1}/{num_frames}\")\n",
    "                \n",
    "                # Create GIF using external library\n",
    "                print(\"Saving animation...\")\n",
    "                from PIL import Image\n",
    "                \n",
    "                # Load all frames from files\n",
    "                frames = [Image.open(f) for f in frame_files]\n",
    "                \n",
    "                # Ensure all frames are the same size\n",
    "                if frames:\n",
    "                    size = frames[0].size\n",
    "                    frames = [f.resize(size) for f in frames]\n",
    "                    \n",
    "                    # Save as GIF\n",
    "                    frames[0].save(\n",
    "                        output_path,\n",
    "                        save_all=True,\n",
    "                        append_images=frames[1:],\n",
    "                        optimize=False,\n",
    "                        duration=1000/30,  # 30 FPS\n",
    "                        loop=0\n",
    "                    )\n",
    "                    \n",
    "                    # Close all frames\n",
    "                    for f in frames:\n",
    "                        f.close()\n",
    "                    \n",
    "                    print(f\"Enhanced visualization saved successfully to {output_path}\")\n",
    "            finally:\n",
    "                # Clean up temporary files\n",
    "                for file in frame_files:\n",
    "                    try:\n",
    "                        if os.path.exists(file):\n",
    "                            os.remove(file)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Warning: Could not remove temporary file {file}: {e}\")\n",
    "                        \n",
    "                # Try to remove temp directory\n",
    "                try:\n",
    "                    if os.path.exists(tmp_dir):\n",
    "                        os.rmdir(tmp_dir)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not remove temporary directory: {e}\")\n",
    "            \n",
    "            plt.close()\n",
    "            return output_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating visualization: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d7ce40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Phase 2: Enhanced visualization generation...\n",
      "Initializing ConceptNetProcessor with loaded datasets...\n",
      "ConceptNetProcessor initialized\n",
      "Building semantic graph from ConceptNet data...\n",
      "Processing 3423004 English ConceptNet assertions...\n",
      "Will sample 1711502 English assertions\n",
      "Processing 1078946 German ConceptNet assertions...\n",
      "Will sample 539473 German assertions\n",
      "Sampling 1711502 assertions from 3423004 en assertions\n",
      "Sampling 1711502 assertions from 3423004 en assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing en assertions:  56%|█████▌    | 958006/1711502 [00:24<00:18, 41419.05it/s]"
     ]
    }
   ],
   "source": [
    "# Phase 2: Generate the enhanced visualization\n",
    "print(\"Starting Phase 2: Enhanced visualization generation...\")\n",
    "\n",
    "# Create enhanced visualizer with the same processor\n",
    "enhanced_visualizer = EnhancedSemanticVisualizer(processor)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize processor with the datasets we loaded at the beginning\n",
    "print(\"Initializing ConceptNetProcessor with loaded datasets...\")\n",
    "processor = ConceptNetProcessor(english_conceptnet, german_conceptnet)\n",
    "\n",
    "# Build semantic graph with 25% sampling\n",
    "processor.build_semantic_graph(\n",
    "    max_concepts=10_000,  # Keep reasonable number of concepts for visualization\n",
    "    min_weight=1.0,\n",
    "    sample_size=0.5  # Use 25% of the data\n",
    ")\n",
    "\n",
    "# Generate concept vectors\n",
    "processor.generate_concept_vectors(dimensions=5)\n",
    "\n",
    "# Create the enhanced visualization with more frames for smoother animation\n",
    "# and additional visual elements for clarity and appeal\n",
    "output_path = enhanced_visualizer.visualize_concepts_enhanced(\n",
    "    output_dir,\n",
    "    num_frames=500  # Reasonable number of frames for smooth animation but faster rendering\n",
    ")\n",
    "\n",
    "print(f\"Enhanced visualization created at: {output_path}\")\n",
    "print(\"\\nKey improvements in Phase 2:\")\n",
    "print(\"1. Progress indicator showing current frame/total frames\")\n",
    "print(\"2. Beautiful gradient background instead of plain gray\")\n",
    "print(\"3. Clear relationship lines between related concepts\")\n",
    "print(\"4. Explanatory text elements that change throughout the animation\")\n",
    "print(\"5. Node sizing based on concept importance\")\n",
    "print(\"6. Improved color scheme and glow effects\")\n",
    "print(\"7. Smooth camera angles and transitions\")\n",
    "print(\"8. Visual cues highlighting important concepts\")\n",
    "print(\"9. Timestamp and attribution information\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde55e64",
   "metadata": {},
   "source": [
    "# Phase 3: Advanced Visualization Refinements\n",
    "\n",
    "After reviewing Phase 2's visualization, we've identified several areas for further enhancement:\n",
    "\n",
    "1. **Connection clarity** - Improve relationship line visibility and make the semantic connections clearer\n",
    "2. **Text legibility** - Enhance contrast and positioning of labels for better readability\n",
    "3. **Depth perception** - Add subtle depth cues to improve 3D space comprehension\n",
    "4. **Camera dynamics** - Create more meaningful camera movements to highlight concept clusters\n",
    "5. **Visual storytelling** - Add contextual information to explain the relationships between concepts\n",
    "6. **Performance optimization** - Improve rendering efficiency for smoother animations\n",
    "7. **Interactive elements** - Add visual responses to highlight related concepts when specific nodes are in focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6e52945",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedSemanticVisualizer(EnhancedSemanticVisualizer):\n",
    "    def __init__(self, concept_processor=None):\n",
    "        # Initialize parent class\n",
    "        super().__init__(concept_processor)\n",
    "        \n",
    "        # Enhanced color palette with even better perceptual separation\n",
    "        self.category_colors = {\n",
    "            'person': '#FF3D7F',     # Brighter pink/red for better visibility\n",
    "            'place': '#32CCFE',      # Clearer cyan\n",
    "            'animal': '#FFCC00',     # More saturated gold\n",
    "            'generic': '#C8D6E5'     # Lighter lavender for better contrast\n",
    "        }\n",
    "        \n",
    "        # More descriptive category labels\n",
    "        self.category_descriptions = {\n",
    "            'person': 'Human Concepts & Relationships',\n",
    "            'place': 'Spatial & Location Concepts',\n",
    "            'animal': 'Living Entities & Natural World',\n",
    "            'generic': 'Abstract & General Concepts'\n",
    "        }\n",
    "        \n",
    "        # Improved background gradient colors for better depth perception\n",
    "        self.bg_gradient = {\n",
    "            'top': '#0A1921',       # Deeper dark blue for better contrast\n",
    "            'middle': '#1C3342',    # Richer teal\n",
    "            'bottom': '#2A4E60'     # Slightly brighter navy blue\n",
    "        }\n",
    "        \n",
    "        # For tracking related concepts for interactive highlighting\n",
    "        self.highlighted_concepts = set()\n",
    "        \n",
    "    def _add_depth_cues(self, ax, points):\n",
    "        \"\"\"Add subtle depth cues to enhance 3D perception\"\"\"\n",
    "        # Create a subtle ground plane grid for better spatial orientation\n",
    "        x_min, x_max = -1.5, 1.5\n",
    "        y_min, y_max = -1.5, 1.5\n",
    "        z_min = min(z for _, _, z in points.values()) - 0.1\n",
    "        \n",
    "        # Draw a subtle ground grid\n",
    "        grid_alpha = 0.05\n",
    "        grid_spacing = 0.2\n",
    "        \n",
    "        for x in np.arange(x_min, x_max + grid_spacing, grid_spacing):\n",
    "            ax.plot([x, x], [y_min, y_max], [z_min, z_min], \n",
    "                   color='white', alpha=grid_alpha, linewidth=0.5)\n",
    "                   \n",
    "        for y in np.arange(y_min, y_max + grid_spacing, grid_spacing):\n",
    "            ax.plot([x_min, x_max], [y, y], [z_min, z_min], \n",
    "                   color='white', alpha=grid_alpha, linewidth=0.5)\n",
    "        \n",
    "        # Add faint coordinate axes for reference\n",
    "        axis_alpha = 0.15\n",
    "        ax.plot([0, 1], [0, 0], [z_min, z_min], color='#FF5E7E', alpha=axis_alpha, linewidth=1)  # X-axis\n",
    "        ax.plot([0, 0], [0, 1], [z_min, z_min], color='#36EAFF', alpha=axis_alpha, linewidth=1)  # Y-axis\n",
    "        \n",
    "        return ax\n",
    "    \n",
    "    def _enhance_relationship_lines(self, ax, points, important_relationships, frame_pct):\n",
    "        \"\"\"Enhanced version of relationship lines with better visual cues\"\"\"\n",
    "        # Build on the parent class method\n",
    "        ax = self._add_relationship_lines(ax, points, important_relationships, frame_pct)\n",
    "        \n",
    "        # Calculate dynamic opacity based on camera angle to improve visibility\n",
    "        # as the visualization rotates\n",
    "        theta = frame_pct * 2 * np.pi\n",
    "        view_factor = abs(np.sin(theta))  # Increases visibility when viewing from certain angles\n",
    "        \n",
    "        # Add additional visual elements for the most important relationships\n",
    "        top_relationships = sorted(\n",
    "            [rel for rel in important_relationships if rel['source'] in points and rel['target'] in points],\n",
    "            key=lambda x: x['similarity'], \n",
    "            reverse=True\n",
    "        )[:5]  # Top 5 strongest relationships\n",
    "        \n",
    "        for rel in top_relationships:\n",
    "            src = points[rel['source']]\n",
    "            tgt = points[rel['target']]\n",
    "            \n",
    "            # Calculate midpoint for label placement\n",
    "            midpoint = [(src[i] + tgt[i])/2 for i in range(3)]\n",
    "            \n",
    "            # Only show labels when the opacity is higher for readability\n",
    "            if view_factor > 0.6 and rel['similarity'] > 0.75:\n",
    "                # Add small connection label at midpoint\n",
    "                ax.text(midpoint[0], midpoint[1], midpoint[2],\n",
    "                      f\"{rel['similarity']:.2f}\",\n",
    "                      color='white',\n",
    "                      alpha=0.7 * view_factor,\n",
    "                      fontsize=7,\n",
    "                      ha='center',\n",
    "                      bbox=dict(facecolor='black', alpha=0.4, pad=1),\n",
    "                      zorder=15)\n",
    "        \n",
    "        return ax\n",
    "    \n",
    "    def _add_improved_glow_effect(self, ax, xs, ys, zs, color, sizes):\n",
    "        \"\"\"Add enhanced glow effect with size variation based on importance\"\"\"\n",
    "        # Base glow effect from parent class\n",
    "        ax = self._add_glow_effect(ax, xs, ys, zs, color, 30)\n",
    "        \n",
    "        # Add pulsing halos to the most important nodes\n",
    "        # Find top 3 largest points (most important)\n",
    "        if len(xs) > 3:\n",
    "            top_indices = np.argsort(sizes)[-3:]\n",
    "            \n",
    "            for idx in top_indices:\n",
    "                # Additional outer glow for important nodes\n",
    "                ax.scatter([xs[idx]], [ys[idx]], [zs[idx]],\n",
    "                         color=color,\n",
    "                         s=sizes[idx] * 2.5,  # Much larger glow\n",
    "                         alpha=0.05,         # Very subtle\n",
    "                         edgecolors='none')\n",
    "        \n",
    "        return ax\n",
    "        \n",
    "    def _add_interactive_highlighting(self, ax, points, frame_pct, node_importance):\n",
    "        \"\"\"Add visual responses highlighting related concept groups\"\"\"\n",
    "        # Simulate interactive highlighting by changing the focus over time\n",
    "        highlight_rotation = int((frame_pct * 4) % 4)  # Rotate through 4 concept groups\n",
    "        \n",
    "        if highlight_rotation == 0:\n",
    "            focus_category = 'person'\n",
    "        elif highlight_rotation == 1:\n",
    "            focus_category = 'place'\n",
    "        elif highlight_rotation == 2:\n",
    "            focus_category = 'animal'\n",
    "        else:\n",
    "            focus_category = 'generic'\n",
    "            \n",
    "        # Find concepts in the focus category\n",
    "        focus_concepts = [\n",
    "            concept for concept in self.concept_processor.concept_vectors\n",
    "            if concept in points and \n",
    "            self.concept_processor.concept_vectors[concept]['category'] == focus_category\n",
    "        ]\n",
    "        \n",
    "        # Only highlight if we have at least one concept in this category\n",
    "        if not focus_concepts:\n",
    "            return ax\n",
    "            \n",
    "        # Choose a single focus concept that changes over time\n",
    "        idx = int((frame_pct * len(focus_concepts) * 10) % len(focus_concepts))\n",
    "        focus_concept = focus_concepts[idx]\n",
    "        \n",
    "        # Draw a subtle highlight indicator\n",
    "        if focus_concept in points:\n",
    "            x, y, z = points[focus_concept]\n",
    "            size = node_importance.get(focus_concept, 40)\n",
    "            \n",
    "            # Draw pulsing highlight\n",
    "            pulse = 0.5 + 0.5 * np.sin(frame_pct * 2 * np.pi * 5)  # Fast pulse\n",
    "            \n",
    "            # Draw focus indicator\n",
    "            ax.scatter([x], [y], [z],\n",
    "                     color='white',\n",
    "                     s=size * (1.5 + pulse * 0.5),\n",
    "                     alpha=0.2 * pulse,\n",
    "                     edgecolors='white',\n",
    "                     linewidth=1)\n",
    "            \n",
    "            # Add subtle focus label\n",
    "            category = self.concept_processor.concept_vectors[focus_concept]['category']\n",
    "            color = self.category_colors[category]\n",
    "            \n",
    "            ax.text(x, y, z + 0.1,\n",
    "                  f\"↓ {focus_concept} ↓\",\n",
    "                  color=color,\n",
    "                  fontsize=9,\n",
    "                  fontweight='bold',\n",
    "                  ha='center',\n",
    "                  va='bottom',\n",
    "                  alpha=0.8 * pulse,\n",
    "                  bbox=dict(facecolor='black', alpha=0.4, pad=2),\n",
    "                  zorder=100)\n",
    "        \n",
    "        return ax\n",
    "    \n",
    "    def _add_advanced_explanatory_elements(self, fig, ax, frame_pct):\n",
    "        \"\"\"Add more informative explanatory elements\"\"\"\n",
    "        # Base explanatory elements from parent class\n",
    "        fig = self._add_explanatory_elements(fig, ax, frame_pct)\n",
    "        \n",
    "        # Add concept count information\n",
    "        concept_count = len(self.concept_processor.concept_vectors)\n",
    "        \n",
    "        # Add visualization statistics\n",
    "        stats_text = fig.text(\n",
    "            0.01, 0.07,\n",
    "            f\"Visualizing {concept_count} concepts\\n\"\n",
    "            f\"Dimensions: 3D projection of semantic space\",\n",
    "            color='white',\n",
    "            fontsize=8,\n",
    "            alpha=0.7,\n",
    "            transform=fig.transFigure\n",
    "        )\n",
    "        \n",
    "        # Add category counts as small colored indicators\n",
    "        categories = {'person': 0, 'place': 0, 'animal': 0, 'generic': 0}\n",
    "        for concept, data in self.concept_processor.concept_vectors.items():\n",
    "            cat = data['category']\n",
    "            categories[cat] = categories.get(cat, 0) + 1\n",
    "            \n",
    "        # Position for category indicators\n",
    "        y_pos = 0.89\n",
    "        x_start = 0.01\n",
    "        width = 0.03\n",
    "        height = 0.01\n",
    "        spacing = 0.005\n",
    "        \n",
    "        # Add category count indicators\n",
    "        for i, (cat, count) in enumerate(categories.items()):\n",
    "            color = self.category_colors[cat]\n",
    "            \n",
    "            # Category color box\n",
    "            cat_rect = plt.Rectangle(\n",
    "                (x_start, y_pos - (i * (height + spacing))),\n",
    "                width, height,\n",
    "                transform=fig.transFigure,\n",
    "                color=color,\n",
    "                alpha=0.8\n",
    "            )\n",
    "            fig.patches.append(cat_rect)\n",
    "            \n",
    "            # Category count text\n",
    "            fig.text(\n",
    "                x_start + width + spacing, \n",
    "                y_pos - (i * (height + spacing)) + height/2,\n",
    "                f\"{cat.capitalize()}: {count}\",\n",
    "                color='white',\n",
    "                fontsize=7,\n",
    "                alpha=0.8,\n",
    "                va='center',\n",
    "                transform=fig.transFigure\n",
    "            )\n",
    "        \n",
    "        return fig\n",
    "        \n",
    "    def visualize_concepts_advanced(self, output_dir, num_frames=60):\n",
    "        \"\"\"Create an advanced visualization with refined visual elements and better clarity\"\"\"\n",
    "        try:\n",
    "            print(\"Creating advanced semantic visualization...\")\n",
    "            \n",
    "            if not self.concept_processor or not self.concept_processor.concept_vectors:\n",
    "                raise ValueError(\"Concept processor not initialized or no vectors generated\")\n",
    "            \n",
    "            # Get important relationships with higher threshold for better clarity\n",
    "            try:\n",
    "                important_relationships = self.concept_processor.compute_important_relationships(\n",
    "                    threshold=0.6,  # Higher threshold for clearer relationships\n",
    "                    max_relationships=40  # More relationships for richer visualization\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not compute relationships: {str(e)}\")\n",
    "                important_relationships = []\n",
    "            \n",
    "            # Setup figure with high DPI for crisp text\n",
    "            plt.close('all')\n",
    "            fig = plt.figure(figsize=(16, 12), dpi=180)  # Higher DPI for better quality\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            \n",
    "            # Apply the background gradient\n",
    "            self._create_background_gradient(fig, ax)\n",
    "            \n",
    "            # Calculate node importance based on connectivity\n",
    "            node_importance = {}\n",
    "            for concept in self.concept_processor.concept_vectors.keys():\n",
    "                # Count occurrences in important relationships\n",
    "                count = sum(1 for rel in important_relationships \n",
    "                           if rel['source'] == concept or rel['target'] == concept)\n",
    "                # Add a minimum size and scale importance more dramatically\n",
    "                node_importance[concept] = 30 + (count * 25)  # Base size + importance factor\n",
    "            \n",
    "            def update(frame):\n",
    "                try:\n",
    "                    # Clear previous frame\n",
    "                    ax.clear()\n",
    "                    \n",
    "                    # Handle text objects removal\n",
    "                    for txt in fig.texts[:]:\n",
    "                        fig.texts.remove(txt)\n",
    "                    \n",
    "                    # Calculate frame percentage for animations\n",
    "                    frame_pct = frame / num_frames\n",
    "                    \n",
    "                    # Configure axis appearance\n",
    "                    ax.grid(False)\n",
    "                    ax.xaxis.pane.fill = False\n",
    "                    ax.yaxis.pane.fill = False\n",
    "                    ax.zaxis.pane.fill = False\n",
    "                    \n",
    "                    # Make panes completely transparent\n",
    "                    ax.xaxis.pane.set_edgecolor('none')\n",
    "                    ax.yaxis.pane.set_edgecolor('none')\n",
    "                    ax.zaxis.pane.set_edgecolor('none')\n",
    "                    \n",
    "                    # Remove axis labels and ticks\n",
    "                    ax.set_xticklabels([])\n",
    "                    ax.set_yticklabels([])\n",
    "                    ax.set_zticklabels([])\n",
    "                    ax.set_xticks([])\n",
    "                    ax.set_yticks([])\n",
    "                    ax.set_zticks([])\n",
    "                    \n",
    "                    # Calculate dynamic camera angle with more complex movement\n",
    "                    theta = frame_pct * 2 * np.pi\n",
    "                    # Add a secondary oscillation for more interesting camera movement\n",
    "                    phi = 0.2 * np.sin(frame_pct * 2 * np.pi * 0.5) + 0.3\n",
    "                    # Add a slight zoom effect\n",
    "                    zoom = 1 - 0.1 * np.sin(frame_pct * 2 * np.pi * 0.3)\n",
    "                    \n",
    "                    # Set viewing angle with enhanced transitions\n",
    "                    ax.view_init(30 + 10 * np.sin(phi), 45 + 180 * frame_pct)\n",
    "                    ax.dist = 8 * zoom  # Dynamic zoom level\n",
    "                    \n",
    "                    # Convert concept vectors to 3D points with dynamic positioning\n",
    "                    points = {}\n",
    "                    for concept, data in self.concept_processor.concept_vectors.items():\n",
    "                        vector = data['vector'][:3]\n",
    "                        \n",
    "                        # Apply dynamic rotation matrix\n",
    "                        x, y, z = vector\n",
    "                        x_rot = x * np.cos(theta) - y * np.sin(theta)\n",
    "                        y_rot = x * np.sin(theta) + y * np.cos(theta)\n",
    "                        z_rot = z + 0.05 * np.sin(theta * 2 + x)  # Add gentle wave motion\n",
    "                        \n",
    "                        points[concept] = (x_rot, y_rot, z_rot)\n",
    "                    \n",
    "                    # Add depth cues first\n",
    "                    self._add_depth_cues(ax, points)\n",
    "                    \n",
    "                    # Add enhanced relationship lines\n",
    "                    self._enhance_relationship_lines(ax, points, important_relationships, frame_pct)\n",
    "                    \n",
    "                    # Plot points by category with enhanced visual elements\n",
    "                    legend_elements = []\n",
    "                    for category, color in self.category_colors.items():\n",
    "                        cat_points = [\n",
    "                            (concept, points[concept], node_importance[concept]) \n",
    "                            for concept in self.concept_processor.concept_vectors\n",
    "                            if concept in points and \n",
    "                            self.concept_processor.concept_vectors[concept]['category'] == category\n",
    "                        ]\n",
    "                        \n",
    "                        if cat_points:\n",
    "                            # Split the data for plotting\n",
    "                            concepts, coords, sizes = zip(*cat_points)\n",
    "                            xs, ys, zs = zip(*coords)\n",
    "                            \n",
    "                            # Add improved glow effect\n",
    "                            self._add_improved_glow_effect(ax, xs, ys, zs, color, sizes)\n",
    "                            \n",
    "                            # Create scatter plot with improved styling\n",
    "                            scatter = ax.scatter(xs, ys, zs, \n",
    "                                              c=color, \n",
    "                                              alpha=0.9, \n",
    "                                              s=sizes,\n",
    "                                              edgecolors='white',\n",
    "                                              linewidth=0.5,\n",
    "                                              zorder=10)\n",
    "                            \n",
    "                            # Add category to legend with improved styling\n",
    "                            legend_elements.append(plt.Line2D(\n",
    "                                [0], [0], \n",
    "                                marker='o', \n",
    "                                color='none',\n",
    "                                markerfacecolor=color,\n",
    "                                markeredgecolor='white',\n",
    "                                markersize=10,\n",
    "                                label=self.category_descriptions[category]))\n",
    "                            \n",
    "                            # Add labels for important concepts with improved styling\n",
    "                            for concept, (x, y, z), size in zip(concepts, coords, sizes):\n",
    "                                # Only label significant concepts for clarity\n",
    "                                if len(concept) > 2 and size > 50:\n",
    "                                    # Calculate label transparency based on size and position\n",
    "                                    label_alpha = min(0.9, size / 100)\n",
    "                                    \n",
    "                                    # Create more visible text with better contrast\n",
    "                                    ax.text(x, y, z + 0.05,\n",
    "                                          concept,\n",
    "                                          color='white',\n",
    "                                          fontsize=8,\n",
    "                                          fontweight='bold',\n",
    "                                          alpha=label_alpha,\n",
    "                                          backgroundcolor=(0, 0, 0, 0.5),\n",
    "                                          ha='center',\n",
    "                                          zorder=20)\n",
    "                    \n",
    "                    # Add interactive highlighting effect\n",
    "                    self._add_interactive_highlighting(ax, points, frame_pct, node_importance)\n",
    "                    \n",
    "                    # Add visual cues to highlight key areas\n",
    "                    self._add_visual_cues(ax, points, frame_pct)\n",
    "                    \n",
    "                    # Add legend with enhanced styling\n",
    "                    legend = ax.legend(handles=legend_elements,\n",
    "                                     loc='upper right',\n",
    "                                     bbox_to_anchor=(0.99, 0.99),\n",
    "                                     title='Semantic Categories',\n",
    "                                     facecolor=(0.05, 0.05, 0.05, 0.8),\n",
    "                                     edgecolor='white',\n",
    "                                     fontsize=9)\n",
    "                    \n",
    "                    if legend:\n",
    "                        legend.get_title().set_color('white')\n",
    "                        for text in legend.get_texts():\n",
    "                            text.set_color('white')\n",
    "                    \n",
    "                    # Add progress indicator\n",
    "                    self._add_progress_indicator(fig, frame, num_frames)\n",
    "                    \n",
    "                    # Add advanced explanatory text and elements\n",
    "                    self._add_advanced_explanatory_elements(fig, ax, frame_pct)\n",
    "                    \n",
    "                    return fig\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error in update frame {frame}: {str(e)}\")\n",
    "                    traceback.print_exc()\n",
    "                    return fig\n",
    "            \n",
    "            # Create animation with enhanced parameters\n",
    "            anim = animation.FuncAnimation(\n",
    "                fig, \n",
    "                update,\n",
    "                frames=num_frames,\n",
    "                interval=40,\n",
    "                blit=False\n",
    "            )\n",
    "            \n",
    "            # Create a static preview image\n",
    "            print(\"Creating advanced static preview...\")\n",
    "            update(0)\n",
    "            \n",
    "            # Save with high quality settings\n",
    "            static_path = os.path.join(output_dir, f'semantica_advanced_preview_{uuid.uuid4()}.png')\n",
    "            plt.savefig(static_path, dpi=180, bbox_inches='tight')\n",
    "            print(f\"Preview image saved to: {static_path}\")\n",
    "            \n",
    "            # Save animation with enhanced quality\n",
    "            output_path = os.path.join(output_dir, f'semantica_advanced_{uuid.uuid4()}.gif')\n",
    "            print(f\"Generating animation (this may take some time)...\")\n",
    "            \n",
    "            # Add a timestamp to the animation\n",
    "            timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            fig.text(\n",
    "                0.5, 0.01,\n",
    "                f\"Generated: {timestamp}\",\n",
    "                ha='center',\n",
    "                color='white',\n",
    "                fontsize=8,\n",
    "                alpha=0.6,\n",
    "                transform=fig.transFigure\n",
    "            )\n",
    "            \n",
    "            # Use a more robust method to save the animation\n",
    "            frames = []\n",
    "            frame_files = []\n",
    "            tmp_dir = os.path.join(output_dir, 'tmp_frames')\n",
    "            \n",
    "            # Create temporary directory for frames\n",
    "            if not os.path.exists(tmp_dir):\n",
    "                os.makedirs(tmp_dir)\n",
    "                \n",
    "            try:\n",
    "                print(\"Generating frames...\")\n",
    "                for i in range(num_frames):\n",
    "                    # Update the figure for this frame\n",
    "                    update(i)\n",
    "                    \n",
    "                    # Save frame to a temporary file\n",
    "                    tmp_file = os.path.join(tmp_dir, f'frame_{i:04d}.png')\n",
    "                    plt.savefig(tmp_file, dpi=180, bbox_inches='tight',\n",
    "                               facecolor=self.bg_gradient['bottom'])\n",
    "                    frame_files.append(tmp_file)\n",
    "                    \n",
    "                    # Print progress\n",
    "                    if i % 10 == 0 or i == num_frames - 1:\n",
    "                        print(f\"Generated frame {i+1}/{num_frames}\")\n",
    "                \n",
    "                # Create GIF using PIL\n",
    "                print(\"Saving animation...\")\n",
    "                from PIL import Image\n",
    "                \n",
    "                # Load all frames from files\n",
    "                frames = [Image.open(f) for f in frame_files]\n",
    "                \n",
    "                # Ensure all frames are the same size\n",
    "                if frames:\n",
    "                    size = frames[0].size\n",
    "                    frames = [f.resize(size) for f in frames]\n",
    "                    \n",
    "                    # Save as GIF\n",
    "                    frames[0].save(\n",
    "                        output_path,\n",
    "                        save_all=True,\n",
    "                        append_images=frames[1:],\n",
    "                        optimize=False,\n",
    "                        duration=1000/30,\n",
    "                        loop=0\n",
    "                    )\n",
    "                    \n",
    "                    # Close all frames\n",
    "                    for f in frames:\n",
    "                        f.close()\n",
    "                    \n",
    "                    print(f\"Advanced visualization saved successfully to {output_path}\")\n",
    "            finally:\n",
    "                # Clean up temporary files\n",
    "                for file in frame_files:\n",
    "                    try:\n",
    "                        if os.path.exists(file):\n",
    "                            os.remove(file)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Warning: Could not remove temporary file {file}: {e}\")\n",
    "                        \n",
    "                # Try to remove temp directory\n",
    "                try:\n",
    "                    if os.path.exists(tmp_dir):\n",
    "                        os.rmdir(tmp_dir)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not remove temporary directory: {e}\")\n",
    "            \n",
    "            plt.close()\n",
    "            return output_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating visualization: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "247a4913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Phase 3: Advanced visualization generation...\n",
      "Initializing ConceptNetProcessor with loaded datasets...\n",
      "ConceptNetProcessor initialized\n",
      "Building semantic graph...\n",
      "Building semantic graph from ConceptNet data...\n",
      "Processing 3423004 English ConceptNet assertions...\n",
      "Will sample 1711502 English assertions\n",
      "Processing 1078946 German ConceptNet assertions...\n",
      "Will sample 539473 German assertions\n",
      "Sampling 1711502 assertions from 3423004 en assertions\n",
      "Sampling 1711502 assertions from 3423004 en assertions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Phase 3: Advanced visualization generation...\n",
      "Initializing ConceptNetProcessor with loaded datasets...\n",
      "ConceptNetProcessor initialized\n",
      "Building semantic graph...\n",
      "Building semantic graph from ConceptNet data...\n",
      "Processing 3423004 English ConceptNet assertions...\n",
      "Will sample 1711502 English assertions\n",
      "Processing 1078946 German ConceptNet assertions...\n",
      "Will sample 539473 German assertions\n",
      "Sampling 1711502 assertions from 3423004 en assertions\n",
      "Sampling 1711502 assertions from 3423004 en assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing en assertions: 100%|██████████| 1711502/1711502 [00:42<00:00, 40174.13it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Phase 3: Advanced visualization generation...\n",
      "Initializing ConceptNetProcessor with loaded datasets...\n",
      "ConceptNetProcessor initialized\n",
      "Building semantic graph...\n",
      "Building semantic graph from ConceptNet data...\n",
      "Processing 3423004 English ConceptNet assertions...\n",
      "Will sample 1711502 English assertions\n",
      "Processing 1078946 German ConceptNet assertions...\n",
      "Will sample 539473 German assertions\n",
      "Sampling 1711502 assertions from 3423004 en assertions\n",
      "Sampling 1711502 assertions from 3423004 en assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing en assertions: 100%|██████████| 1711502/1711502 [00:42<00:00, 40174.13it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 539473 assertions from 1078946 de assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing de assertions: 100%|██████████| 539473/539473 [00:14<00:00, 38478.26it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Phase 3: Advanced visualization generation...\n",
      "Initializing ConceptNetProcessor with loaded datasets...\n",
      "ConceptNetProcessor initialized\n",
      "Building semantic graph...\n",
      "Building semantic graph from ConceptNet data...\n",
      "Processing 3423004 English ConceptNet assertions...\n",
      "Will sample 1711502 English assertions\n",
      "Processing 1078946 German ConceptNet assertions...\n",
      "Will sample 539473 German assertions\n",
      "Sampling 1711502 assertions from 3423004 en assertions\n",
      "Sampling 1711502 assertions from 3423004 en assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing en assertions: 100%|██████████| 1711502/1711502 [00:42<00:00, 40174.13it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 539473 assertions from 1078946 de assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing de assertions: 100%|██████████| 539473/539473 [00:14<00:00, 38478.26it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limiting graph to top 10000 concepts...\n",
      "Semantic graph built with 10000 nodes and 65544 edges\n",
      "Inferring semantic categories...\n",
      "Inferred categories: {'generic': 8088, 'person': 470, 'place': 1442}\n",
      "Generating concept vectors...\n",
      "Generating 5-dimensional concept vectors...\n",
      "Semantic graph built with 10000 nodes and 65544 edges\n",
      "Inferring semantic categories...\n",
      "Inferred categories: {'generic': 8088, 'person': 470, 'place': 1442}\n",
      "Generating concept vectors...\n",
      "Generating 5-dimensional concept vectors...\n",
      "Generated vectors for 10000 concepts\n",
      "Creating advanced semantic visualization...\n",
      "Generated vectors for 10000 concepts\n",
      "Creating advanced semantic visualization...\n",
      "Creating advanced static preview...\n",
      "Creating advanced static preview...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Phase 3: Advanced visualization generation...\n",
      "Initializing ConceptNetProcessor with loaded datasets...\n",
      "ConceptNetProcessor initialized\n",
      "Building semantic graph...\n",
      "Building semantic graph from ConceptNet data...\n",
      "Processing 3423004 English ConceptNet assertions...\n",
      "Will sample 1711502 English assertions\n",
      "Processing 1078946 German ConceptNet assertions...\n",
      "Will sample 539473 German assertions\n",
      "Sampling 1711502 assertions from 3423004 en assertions\n",
      "Sampling 1711502 assertions from 3423004 en assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing en assertions: 100%|██████████| 1711502/1711502 [00:42<00:00, 40174.13it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 539473 assertions from 1078946 de assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing de assertions: 100%|██████████| 539473/539473 [00:14<00:00, 38478.26it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limiting graph to top 10000 concepts...\n",
      "Semantic graph built with 10000 nodes and 65544 edges\n",
      "Inferring semantic categories...\n",
      "Inferred categories: {'generic': 8088, 'person': 470, 'place': 1442}\n",
      "Generating concept vectors...\n",
      "Generating 5-dimensional concept vectors...\n",
      "Semantic graph built with 10000 nodes and 65544 edges\n",
      "Inferring semantic categories...\n",
      "Inferred categories: {'generic': 8088, 'person': 470, 'place': 1442}\n",
      "Generating concept vectors...\n",
      "Generating 5-dimensional concept vectors...\n",
      "Generated vectors for 10000 concepts\n",
      "Creating advanced semantic visualization...\n",
      "Generated vectors for 10000 concepts\n",
      "Creating advanced semantic visualization...\n",
      "Creating advanced static preview...\n",
      "Creating advanced static preview...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Erich Curtis\\AppData\\Local\\Temp\\ipykernel_61348\\2616853387.py:313: MatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n",
      "  ax.dist = 8 * zoom  # Dynamic zoom level\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Phase 3: Advanced visualization generation...\n",
      "Initializing ConceptNetProcessor with loaded datasets...\n",
      "ConceptNetProcessor initialized\n",
      "Building semantic graph...\n",
      "Building semantic graph from ConceptNet data...\n",
      "Processing 3423004 English ConceptNet assertions...\n",
      "Will sample 1711502 English assertions\n",
      "Processing 1078946 German ConceptNet assertions...\n",
      "Will sample 539473 German assertions\n",
      "Sampling 1711502 assertions from 3423004 en assertions\n",
      "Sampling 1711502 assertions from 3423004 en assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing en assertions: 100%|██████████| 1711502/1711502 [00:42<00:00, 40174.13it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 539473 assertions from 1078946 de assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing de assertions: 100%|██████████| 539473/539473 [00:14<00:00, 38478.26it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limiting graph to top 10000 concepts...\n",
      "Semantic graph built with 10000 nodes and 65544 edges\n",
      "Inferring semantic categories...\n",
      "Inferred categories: {'generic': 8088, 'person': 470, 'place': 1442}\n",
      "Generating concept vectors...\n",
      "Generating 5-dimensional concept vectors...\n",
      "Semantic graph built with 10000 nodes and 65544 edges\n",
      "Inferring semantic categories...\n",
      "Inferred categories: {'generic': 8088, 'person': 470, 'place': 1442}\n",
      "Generating concept vectors...\n",
      "Generating 5-dimensional concept vectors...\n",
      "Generated vectors for 10000 concepts\n",
      "Creating advanced semantic visualization...\n",
      "Generated vectors for 10000 concepts\n",
      "Creating advanced semantic visualization...\n",
      "Creating advanced static preview...\n",
      "Creating advanced static preview...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Erich Curtis\\AppData\\Local\\Temp\\ipykernel_61348\\2616853387.py:313: MatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n",
      "  ax.dist = 8 * zoom  # Dynamic zoom level\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview image saved to: ../Data/Output\\semantica_advanced_preview_69816660-0a18-486b-b517-59b5c21c84be.png\n",
      "Generating animation (this may take some time)...\n",
      "Generating frames...\n",
      "Generated frame 1/300\n",
      "Generated frame 1/300\n",
      "Generated frame 11/300\n",
      "Generated frame 11/300\n",
      "Generated frame 21/300\n",
      "Generated frame 21/300\n",
      "Generated frame 31/300\n",
      "Generated frame 31/300\n",
      "Generated frame 41/300\n",
      "Generated frame 41/300\n",
      "Generated frame 51/300\n",
      "Generated frame 51/300\n",
      "Generated frame 61/300\n",
      "Generated frame 61/300\n",
      "Generated frame 71/300\n",
      "Generated frame 71/300\n",
      "Generated frame 81/300\n",
      "Generated frame 81/300\n",
      "Generated frame 91/300\n",
      "Generated frame 91/300\n",
      "Generated frame 101/300\n",
      "Generated frame 101/300\n",
      "Generated frame 111/300\n",
      "Generated frame 111/300\n",
      "Generated frame 121/300\n",
      "Generated frame 121/300\n",
      "Generated frame 131/300\n",
      "Generated frame 131/300\n",
      "Generated frame 141/300\n",
      "Generated frame 141/300\n",
      "Generated frame 151/300\n",
      "Generated frame 151/300\n",
      "Generated frame 161/300\n",
      "Generated frame 161/300\n",
      "Generated frame 171/300\n",
      "Generated frame 171/300\n",
      "Generated frame 181/300\n",
      "Generated frame 181/300\n",
      "Generated frame 191/300\n",
      "Generated frame 191/300\n",
      "Generated frame 201/300\n",
      "Generated frame 201/300\n",
      "Generated frame 211/300\n",
      "Generated frame 211/300\n",
      "Generated frame 221/300\n",
      "Generated frame 221/300\n",
      "Generated frame 231/300\n",
      "Generated frame 231/300\n",
      "Generated frame 241/300\n",
      "Generated frame 241/300\n",
      "Generated frame 251/300\n",
      "Generated frame 251/300\n",
      "Generated frame 261/300\n",
      "Generated frame 261/300\n",
      "Generated frame 271/300\n",
      "Generated frame 271/300\n",
      "Generated frame 281/300\n",
      "Generated frame 281/300\n",
      "Generated frame 291/300\n",
      "Generated frame 291/300\n",
      "Generated frame 300/300\n",
      "Saving animation...\n",
      "Generated frame 300/300\n",
      "Saving animation...\n",
      "Advanced visualization saved successfully to ../Data/Output\\semantica_advanced_a270f0c9-d3fb-46a4-a73a-633c602e5c49.gif\n",
      "Advanced visualization created at: ../Data/Output\\semantica_advanced_a270f0c9-d3fb-46a4-a73a-633c602e5c49.gif\n",
      "\n",
      "Key improvements in Phase 3:\n",
      "1. Enhanced depth perception with subtle grid reference\n",
      "2. Improved text legibility with better contrast backgrounds\n",
      "3. Interactive concept highlighting that changes focus over time\n",
      "4. Relationship strength indicators on important connections\n",
      "5. More informative category statistics and counts\n",
      "6. Dynamic camera movements with smooth zoom effects\n",
      "7. Enhanced visual prioritization of important concepts\n",
      "8. Higher resolution output for better detail\n",
      "Advanced visualization saved successfully to ../Data/Output\\semantica_advanced_a270f0c9-d3fb-46a4-a73a-633c602e5c49.gif\n",
      "Advanced visualization created at: ../Data/Output\\semantica_advanced_a270f0c9-d3fb-46a4-a73a-633c602e5c49.gif\n",
      "\n",
      "Key improvements in Phase 3:\n",
      "1. Enhanced depth perception with subtle grid reference\n",
      "2. Improved text legibility with better contrast backgrounds\n",
      "3. Interactive concept highlighting that changes focus over time\n",
      "4. Relationship strength indicators on important connections\n",
      "5. More informative category statistics and counts\n",
      "6. Dynamic camera movements with smooth zoom effects\n",
      "7. Enhanced visual prioritization of important concepts\n",
      "8. Higher resolution output for better detail\n"
     ]
    }
   ],
   "source": [
    "# Phase 3: Generate the advanced visualization\n",
    "print(\"Starting Phase 3: Advanced visualization generation...\")\n",
    "\n",
    "# Initialize processor with the datasets we loaded at the beginning\n",
    "print(\"Initializing ConceptNetProcessor with loaded datasets...\")\n",
    "processor = ConceptNetProcessor(english_conceptnet, german_conceptnet)\n",
    "\n",
    "# Build semantic graph with reasonable sampling\n",
    "print(\"Building semantic graph...\")\n",
    "processor.build_semantic_graph(\n",
    "    max_concepts=10_000,  # Keep reasonable number of concepts for visualization\n",
    "    min_weight=1.0,\n",
    "    sample_size=0.5  # Use smaller sample for faster processing\n",
    ")\n",
    "\n",
    "# Check if the graph has nodes before generating vectors\n",
    "if processor.semantic_graph.number_of_nodes() == 0:\n",
    "    print(\"Warning: Semantic graph is empty. Creating a sample graph for visualization...\")\n",
    "    # Create a sample graph for demonstration purposes\n",
    "    sample_concepts = {\n",
    "        'person': ['human', 'woman', 'man', 'child', 'friend', 'family'],\n",
    "        'place': ['home', 'city', 'park', 'office', 'school', 'mountain'],\n",
    "        'animal': ['dog', 'cat', 'bird', 'fish', 'lion', 'tiger'],\n",
    "        'generic': ['object', 'idea', 'concept', 'thought', 'action', 'time']\n",
    "    }\n",
    "    \n",
    "    # Add nodes to graph\n",
    "    for category, concepts in sample_concepts.items():\n",
    "        for concept in concepts:\n",
    "            processor.semantic_graph.add_node(concept, category=category)\n",
    "            \n",
    "    # Add some edges\n",
    "    for category, concepts in sample_concepts.items():\n",
    "        for i in range(len(concepts)-1):\n",
    "            processor.semantic_graph.add_edge(concepts[i], concepts[i+1], relation='RelatedTo', weight=1.0)\n",
    "    \n",
    "    # Add cross-category relationships\n",
    "    cross_relations = [\n",
    "        (sample_concepts['person'][0], sample_concepts['place'][0]),\n",
    "        (sample_concepts['person'][1], sample_concepts['animal'][0]),\n",
    "        (sample_concepts['place'][2], sample_concepts['animal'][2]),\n",
    "        (sample_concepts['generic'][0], sample_concepts['person'][3]),\n",
    "        (sample_concepts['generic'][1], sample_concepts['place'][3]),\n",
    "        (sample_concepts['generic'][2], sample_concepts['animal'][3])\n",
    "    ]\n",
    "    \n",
    "    for source, target in cross_relations:\n",
    "        processor.semantic_graph.add_edge(source, target, relation='RelatedTo', weight=1.0)\n",
    "    \n",
    "    print(f\"Created sample graph with {processor.semantic_graph.number_of_nodes()} nodes and {processor.semantic_graph.number_of_edges()} edges\")\n",
    "\n",
    "# Generate concept vectors\n",
    "print(\"Generating concept vectors...\")\n",
    "processor.generate_concept_vectors(dimensions=5)\n",
    "\n",
    "# Create advanced visualizer with the processor\n",
    "advanced_visualizer = AdvancedSemanticVisualizer(processor)\n",
    "\n",
    "# Create the advanced visualization with improved depth cues\n",
    "# and enhanced interactive elements\n",
    "output_path = advanced_visualizer.visualize_concepts_advanced(\n",
    "    output_dir,\n",
    "    num_frames=300  # Reduced frames for faster rendering while still showing the features\n",
    ")\n",
    "\n",
    "print(f\"Advanced visualization created at: {output_path}\")\n",
    "print(\"\\nKey improvements in Phase 3:\")\n",
    "print(\"1. Enhanced depth perception with subtle grid reference\")\n",
    "print(\"2. Improved text legibility with better contrast backgrounds\")\n",
    "print(\"3. Interactive concept highlighting that changes focus over time\")\n",
    "print(\"4. Relationship strength indicators on important connections\")\n",
    "print(\"5. More informative category statistics and counts\")\n",
    "print(\"6. Dynamic camera movements with smooth zoom effects\")\n",
    "print(\"7. Enhanced visual prioritization of important concepts\")\n",
    "print(\"8. Higher resolution output for better detail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c54341",
   "metadata": {},
   "source": [
    "# Phase 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd82159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
