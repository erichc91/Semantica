{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deec642b",
   "metadata": {},
   "source": [
    "# Semantica relation GRaph visualized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d84ca",
   "metadata": {},
   "source": [
    "# Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2118648f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ConceptNet data...\n",
      "English ConceptNet loaded with 3423004 assertions.\n",
      "German ConceptNet loaded with 1078946 assertions.\n",
      "Starting ConceptNet processing pipeline...\n",
      "ConceptNetProcessor initialized\n",
      "Building semantic graph from ConceptNet data...\n",
      "Processing 3423004 English ConceptNet assertions...\n",
      "Processing 1078946 German ConceptNet assertions...\n",
      "Sampled 5000 assertions from 3423004 en assertions\n",
      "English ConceptNet loaded with 3423004 assertions.\n",
      "German ConceptNet loaded with 1078946 assertions.\n",
      "Starting ConceptNet processing pipeline...\n",
      "ConceptNetProcessor initialized\n",
      "Building semantic graph from ConceptNet data...\n",
      "Processing 3423004 English ConceptNet assertions...\n",
      "Processing 1078946 German ConceptNet assertions...\n",
      "Sampled 5000 assertions from 3423004 en assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing en assertions: 100%|██████████| 5000/5000 [00:00<00:00, 31645.62it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 5000 assertions from 1078946 de assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing de assertions: 100%|██████████| 5000/5000 [00:00<00:00, 33433.43it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limiting graph to top 150 concepts...\n",
      "Semantic graph built with 150 nodes and 234 edges\n",
      "Inferring semantic categories...\n",
      "Inferred categories: {'generic': 139, 'animal': 4, 'place': 5, 'person': 2}\n",
      "Generating 5-dimensional concept vectors...\n",
      "Generated vectors for 150 concepts\n",
      "Creating readable 3D visualization...\n",
      "Creating improved readable visualization...\n",
      "Creating static preview...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'concept_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 999\u001b[0m\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGerman ConceptNet loaded with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(german_conceptnet)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m assertions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    998\u001b[0m \u001b[38;5;66;03m# Process data and create visualizations\u001b[39;00m\n\u001b[1;32m--> 999\u001b[0m processor, viz_paths \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_conceptnet_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43menglish_conceptnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgerman_conceptnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisualization_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreadable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use the new readable visualization\u001b[39;49;00m\n\u001b[0;32m   1004\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcess complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 951\u001b[0m, in \u001b[0;36mprocess_conceptnet_data\u001b[1;34m(english_data, german_data, output_dir, visualization_type)\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualization_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadable\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    950\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating readable 3D visualization...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 951\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mvisualizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualize_concepts_improved\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# More frames for smoother, slower movement\u001b[39;49;00m\n\u001b[0;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    955\u001b[0m     output_paths\u001b[38;5;241m.\u001b[39mappend(output_path)\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualization_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbasic\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "Cell \u001b[1;32mIn[12], line 831\u001b[0m, in \u001b[0;36mSemanticVisualizer.visualize_concepts_improved\u001b[1;34m(self, output_dir, num_frames)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Create a static preview image\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating static preview...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 831\u001b[0m \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use first frame for preview\u001b[39;00m\n\u001b[0;32m    833\u001b[0m static_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msemantica_readable_preview_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muuid\u001b[38;5;241m.\u001b[39muuid4()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    834\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(static_path, dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m, bbox_inches\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 571\u001b[0m, in \u001b[0;36mSemanticVisualizer.visualize_concepts_improved.<locals>.update\u001b[1;34m(frame)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;66;03m# Create a smoother, slower oscillation factor\u001b[39;00m\n\u001b[0;32m    569\u001b[0m time_factor \u001b[38;5;241m=\u001b[39m frame \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m  \u001b[38;5;66;03m# Reduced speed\u001b[39;00m\n\u001b[1;32m--> 571\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m concept, data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mconcept_vectors\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    572\u001b[0m     vector \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m'\u001b[39m][:\u001b[38;5;241m3\u001b[39m]  \u001b[38;5;66;03m# First 3 dimensions\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;66;03m# Add subtle animation with very slow movement\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'concept_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "import random\n",
    "import io\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import uuid\n",
    "import warnings\n",
    "import traceback\n",
    "import json  # Added missing import\n",
    "from scipy.spatial.distance import cosine  # Added missing import\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-interactive backend for better memory handling\n",
    "\n",
    "class ConceptNetProcessor:\n",
    "    \"\"\"\n",
    "    Process ConceptNet data for semantic visualization\n",
    "    \"\"\"\n",
    "    def __init__(self, english_data=None, german_data=None):\n",
    "        self.english_data = english_data\n",
    "        self.german_data = german_data\n",
    "        self.semantic_graph = nx.DiGraph()\n",
    "        self.concept_vectors = {}\n",
    "        self.relation_types = set()\n",
    "        \n",
    "        print(\"ConceptNetProcessor initialized\")\n",
    "    \n",
    "    def clean_concept_name(self, concept_str):\n",
    "        \"\"\"Extract clean concept name from ConceptNet format\"\"\"\n",
    "        if not isinstance(concept_str, str):\n",
    "            return \"unknown\"\n",
    "            \n",
    "        # Extract the concept name from the ConceptNet URI format\n",
    "        parts = concept_str.split('/')\n",
    "        if len(parts) >= 4:\n",
    "            # Format is typically /c/LANG/CONCEPT\n",
    "            concept = parts[-1]\n",
    "            # Remove part-of-speech tags if present\n",
    "            if '/' in concept:\n",
    "                concept = concept.split('/')[0]\n",
    "            return concept\n",
    "        return concept_str\n",
    "    \n",
    "    def extract_relation_type(self, relation_str):\n",
    "        \"\"\"Extract relation type from ConceptNet format\"\"\"\n",
    "        if not isinstance(relation_str, str):\n",
    "            return \"unknown\"\n",
    "            \n",
    "        parts = relation_str.split('/')\n",
    "        if len(parts) >= 3:\n",
    "            # Format is typically /r/RELATION_TYPE\n",
    "            return parts[-1]\n",
    "        return relation_str\n",
    "    \n",
    "    def extract_language(self, concept_str):\n",
    "        \"\"\"Extract language from ConceptNet concept URI\"\"\"\n",
    "        if not isinstance(concept_str, str):\n",
    "            return \"unknown\"\n",
    "            \n",
    "        parts = concept_str.split('/')\n",
    "        if len(parts) >= 4:\n",
    "            # Format is typically /c/LANG/CONCEPT\n",
    "            return parts[2]\n",
    "        return \"unknown\"\n",
    "    \n",
    "    def parse_weight(self, weight_str):\n",
    "        \"\"\"Parse weight JSON string to extract numeric weight\"\"\"\n",
    "        if not isinstance(weight_str, str):\n",
    "            return 1.0\n",
    "            \n",
    "        try:\n",
    "            weight_data = json.loads(weight_str)\n",
    "            # ConceptNet weights are typically in 'weight' field\n",
    "            return float(weight_data.get('weight', 1.0))\n",
    "        except:\n",
    "            return 1.0\n",
    "    \n",
    "    def build_semantic_graph(self, max_concepts=200, min_weight=1.0, sample_size=5000):\n",
    "        \"\"\"Build semantic graph from ConceptNet data\"\"\"\n",
    "        print(\"Building semantic graph from ConceptNet data...\")\n",
    "        \n",
    "        if self.english_data is None and self.german_data is None:\n",
    "            print(\"No ConceptNet data provided.\")\n",
    "            return\n",
    "        \n",
    "        # Combine datasets\n",
    "        all_data = []\n",
    "        if self.english_data is not None:\n",
    "            print(f\"Processing {len(self.english_data)} English ConceptNet assertions...\")\n",
    "            all_data.append(('en', self.english_data))\n",
    "        \n",
    "        if self.german_data is not None:\n",
    "            print(f\"Processing {len(self.german_data)} German ConceptNet assertions...\")\n",
    "            all_data.append(('de', self.german_data))\n",
    "        \n",
    "        # Track concepts and their occurrence count\n",
    "        concept_counts = {}\n",
    "        \n",
    "        # Process each language dataset\n",
    "        for lang, data in all_data:\n",
    "            # Sample to ensure manageable size if needed\n",
    "            if len(data) > sample_size:\n",
    "                data_sample = data.sample(sample_size, random_state=42)\n",
    "                print(f\"Sampled {sample_size} assertions from {len(data)} {lang} assertions\")\n",
    "            else:\n",
    "                data_sample = data\n",
    "            \n",
    "            # Process assertions\n",
    "            for _, row in tqdm(data_sample.iterrows(), desc=f\"Processing {lang} assertions\", total=len(data_sample)):\n",
    "                try:\n",
    "                    # Extract source and target concepts\n",
    "                    source_concept = self.clean_concept_name(row['start'])\n",
    "                    target_concept = self.clean_concept_name(row['end'])\n",
    "                    \n",
    "                    # Extract relation type\n",
    "                    relation_type = self.extract_relation_type(row['rel'])\n",
    "                    self.relation_types.add(relation_type)\n",
    "                    \n",
    "                    # Extract languages\n",
    "                    source_lang = self.extract_language(row['start'])\n",
    "                    target_lang = self.extract_language(row['end'])\n",
    "                    \n",
    "                    # Parse weight\n",
    "                    weight = self.parse_weight(row['weight'])\n",
    "                    \n",
    "                    # Skip low-weight relationships\n",
    "                    if weight < min_weight:\n",
    "                        continue\n",
    "                    \n",
    "                    # Track concept occurrences\n",
    "                    concept_counts[source_concept] = concept_counts.get(source_concept, 0) + 1\n",
    "                    concept_counts[target_concept] = concept_counts.get(target_concept, 0) + 1\n",
    "                    \n",
    "                    # Add to graph\n",
    "                    self.semantic_graph.add_node(\n",
    "                        source_concept,\n",
    "                        lang=source_lang,\n",
    "                        count=concept_counts[source_concept]\n",
    "                    )\n",
    "                    \n",
    "                    self.semantic_graph.add_node(\n",
    "                        target_concept,\n",
    "                        lang=target_lang,\n",
    "                        count=concept_counts[target_concept]\n",
    "                    )\n",
    "                    \n",
    "                    # Add edge with relation data\n",
    "                    self.semantic_graph.add_edge(\n",
    "                        source_concept,\n",
    "                        target_concept,\n",
    "                        relation=relation_type,\n",
    "                        weight=weight\n",
    "                    )\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    warnings.warn(f\"Error processing assertion: {e}\")\n",
    "        \n",
    "        # Limit to top concepts if needed\n",
    "        if len(concept_counts) > max_concepts:\n",
    "            print(f\"Limiting graph to top {max_concepts} concepts...\")\n",
    "            top_concepts = sorted(concept_counts.items(), key=lambda x: x[1], reverse=True)[:max_concepts]\n",
    "            top_concept_names = {c[0] for c in top_concepts}\n",
    "            \n",
    "            # Create subgraph with only top concepts\n",
    "            subgraph = nx.DiGraph()\n",
    "            \n",
    "            for node in top_concept_names:\n",
    "                if self.semantic_graph.has_node(node):\n",
    "                    subgraph.add_node(\n",
    "                        node,\n",
    "                        **self.semantic_graph.nodes[node]\n",
    "                    )\n",
    "            \n",
    "            for source, target, data in self.semantic_graph.edges(data=True):\n",
    "                if source in top_concept_names and target in top_concept_names:\n",
    "                    subgraph.add_edge(\n",
    "                        source,\n",
    "                        target,\n",
    "                        **data\n",
    "                    )\n",
    "            \n",
    "            self.semantic_graph = subgraph\n",
    "        \n",
    "        print(f\"Semantic graph built with {self.semantic_graph.number_of_nodes()} nodes and {self.semantic_graph.number_of_edges()} edges\")\n",
    "        \n",
    "        # Infer semantic categories\n",
    "        self.infer_semantic_categories()\n",
    "        \n",
    "        return self.semantic_graph\n",
    "    \n",
    "    def infer_semantic_categories(self):\n",
    "        \"\"\"Infer semantic categories for concepts in the graph\"\"\"\n",
    "        print(\"Inferring semantic categories...\")\n",
    "        \n",
    "        # Define category patterns\n",
    "        category_patterns = {\n",
    "            'fruit': ['apple', 'banana', 'orange', 'fruit', 'berry', 'apfel'],\n",
    "            'color': ['red', 'blue', 'green', 'yellow', 'color', 'rot', 'blau', 'grün', 'gelb', 'farbe'],\n",
    "            'taste': ['sweet', 'sour', 'bitter', 'taste', 'süß', 'sauer', 'geschmack'],\n",
    "            'vehicle': ['car', 'bus', 'train', 'vehicle', 'auto', 'fahrzeug'],\n",
    "            'temperature': ['hot', 'cold', 'warm', 'cool', 'heiß', 'kalt', 'temperatur'],\n",
    "            'size': ['big', 'small', 'large', 'tiny', 'groß', 'klein', 'größe'],\n",
    "            'time': ['minute', 'hour', 'day', 'week', 'month', 'year', 'zeit', 'tag', 'woche'],\n",
    "            'animal': ['dog', 'cat', 'bird', 'animal', 'hund', 'katze', 'vogel', 'tier'],\n",
    "            'person': ['man', 'woman', 'child', 'person', 'mann', 'frau', 'kind'],\n",
    "            'place': ['city', 'country', 'house', 'room', 'stadt', 'land', 'haus', 'zimmer']\n",
    "        }\n",
    "        \n",
    "        # Use relation types to help infer categories\n",
    "        relation_category_map = {\n",
    "            'IsA': 'type',\n",
    "            'PartOf': 'part',\n",
    "            'HasA': 'property',\n",
    "            'UsedFor': 'function',\n",
    "            'CapableOf': 'capability',\n",
    "            'AtLocation': 'location',\n",
    "            'HasProperty': 'property'\n",
    "        }\n",
    "        \n",
    "        # Assign categories\n",
    "        for node in self.semantic_graph.nodes():\n",
    "            # Initialize with unknown category\n",
    "            self.semantic_graph.nodes[node]['category'] = 'generic'\n",
    "            \n",
    "            # Check for pattern matches\n",
    "            node_lower = str(node).lower()\n",
    "            \n",
    "            for category, patterns in category_patterns.items():\n",
    "                if any(pattern in node_lower for pattern in patterns):\n",
    "                    self.semantic_graph.nodes[node]['category'] = category\n",
    "                    break\n",
    "            \n",
    "            # Use incoming edges to help determine category\n",
    "            incoming_edges = list(self.semantic_graph.in_edges(node, data=True))\n",
    "            if incoming_edges:\n",
    "                for source, _, data in incoming_edges:\n",
    "                    relation = data.get('relation', '')\n",
    "                    if relation in relation_category_map:\n",
    "                        # Use the source node's category for certain relations\n",
    "                        if relation in ['IsA', 'PartOf'] and 'category' in self.semantic_graph.nodes[source]:\n",
    "                            source_category = self.semantic_graph.nodes[source]['category']\n",
    "                            if source_category != 'generic':\n",
    "                                self.semantic_graph.nodes[node]['category'] = source_category\n",
    "                                break\n",
    "        \n",
    "        # Count categories\n",
    "        categories = {}\n",
    "        for node, data in self.semantic_graph.nodes(data=True):\n",
    "            category = data.get('category', 'generic')\n",
    "            categories[category] = categories.get(category, 0) + 1\n",
    "        \n",
    "        print(\"Inferred categories:\", categories)\n",
    "    \n",
    "    def generate_concept_vectors(self, dimensions=5):\n",
    "        \"\"\"Generate semantic vectors for concepts in the graph\"\"\"\n",
    "        print(f\"Generating {dimensions}-dimensional concept vectors...\")\n",
    "        \n",
    "        if not self.semantic_graph:\n",
    "            print(\"No semantic graph available.\")\n",
    "            return {}\n",
    "        \n",
    "        # Group concepts by category\n",
    "        concepts_by_category = {}\n",
    "        for node, data in self.semantic_graph.nodes(data=True):\n",
    "            category = data.get('category', 'generic')\n",
    "            if category not in concepts_by_category:\n",
    "                concepts_by_category[category] = []\n",
    "            concepts_by_category[category].append(node)\n",
    "        \n",
    "        # Generate base vectors for each category\n",
    "        category_base_vectors = {}\n",
    "        for category in concepts_by_category.keys():\n",
    "            # Use deterministic seed for consistency, but ensure it's within valid range\n",
    "            seed_value = abs(hash(category)) % (2**32 - 1)  # Safe seed range for NumPy\n",
    "            np.random.seed(seed_value)\n",
    "            category_base_vectors[category] = np.random.randn(dimensions)\n",
    "            # Normalize to unit length\n",
    "            category_base_vectors[category] = category_base_vectors[category] / np.linalg.norm(category_base_vectors[category])\n",
    "        \n",
    "        # Generate vectors for concepts within each category\n",
    "        for category, concepts in concepts_by_category.items():\n",
    "            base_vector = category_base_vectors[category]\n",
    "            \n",
    "            for concept in concepts:\n",
    "                # Get node data\n",
    "                node_data = self.semantic_graph.nodes[concept]\n",
    "                count = node_data.get('count', 1)\n",
    "                lang = node_data.get('lang', 'unknown')\n",
    "                \n",
    "                # Create language-specific seed value\n",
    "                lang_seed = 0\n",
    "                if lang == 'en':\n",
    "                    lang_seed = 1\n",
    "                elif lang == 'de':\n",
    "                    lang_seed = 2\n",
    "                \n",
    "                # Scale by frequency/importance\n",
    "                importance_factor = np.log1p(count) / 10\n",
    "                \n",
    "                # Add controlled variation with proper seed range\n",
    "                # Fix: Ensure seed value is within valid range for NumPy\n",
    "                concept_hash = abs(hash(concept)) % (2**32 - 1)  # Get positive hash in valid range\n",
    "                seed_value = (concept_hash + lang_seed) % (2**32 - 1)  # Combine with language seed safely\n",
    "                np.random.seed(seed_value)\n",
    "                variation = np.random.randn(dimensions) * 0.2\n",
    "                \n",
    "                # Calculate final vector\n",
    "                concept_vector = base_vector * (1.0 + importance_factor) + variation\n",
    "                # Normalize for consistent visualization\n",
    "                concept_vector = concept_vector / np.linalg.norm(concept_vector) * 1.5\n",
    "                \n",
    "                # Store vector with metadata\n",
    "                self.concept_vectors[concept] = {\n",
    "                    'vector': concept_vector,\n",
    "                    'category': category,\n",
    "                    'lang': lang,\n",
    "                    'count': count,\n",
    "                    'potential': min(1.5, 0.5 + importance_factor)  # For visualization sizing\n",
    "                }\n",
    "        \n",
    "        # Process translation equivalents\n",
    "        self.process_translations()\n",
    "        \n",
    "        # Adjust vectors based on graph connections\n",
    "        self.adjust_vectors_by_relationships()\n",
    "        \n",
    "        print(f\"Generated vectors for {len(self.concept_vectors)} concepts\")\n",
    "        return self.concept_vectors\n",
    "    \n",
    "    def process_translations(self):\n",
    "        \"\"\"\n",
    "        Process translation equivalents to ensure they're positioned near each other\n",
    "        \"\"\"\n",
    "        # Look for translation pairs using typical patterns in ConceptNet\n",
    "        translation_pairs = []\n",
    "        \n",
    "        for source, target, data in self.semantic_graph.edges(data=True):\n",
    "            relation = data.get('relation', '')\n",
    "            \n",
    "            # Check for translation relationships\n",
    "            if relation in ['TranslationOf', 'Synonym']:\n",
    "                if source in self.concept_vectors and target in self.concept_vectors:\n",
    "                    source_lang = self.semantic_graph.nodes[source].get('lang', 'unknown')\n",
    "                    target_lang = self.semantic_graph.nodes[target].get('lang', 'unknown')\n",
    "                    \n",
    "                    # Only consider cross-language pairs or clear synonyms\n",
    "                    if source_lang != target_lang or relation == 'Synonym':\n",
    "                        translation_pairs.append((source, target))\n",
    "        \n",
    "        # Adjust vectors for translation pairs\n",
    "        for source, target in translation_pairs:\n",
    "            if source in self.concept_vectors and target in self.concept_vectors:\n",
    "                # Get vectors\n",
    "                source_vector = self.concept_vectors[source]['vector']\n",
    "                target_vector = self.concept_vectors[target]['vector']\n",
    "                \n",
    "                # Calculate average vector\n",
    "                avg_vector = (source_vector + target_vector) / 2\n",
    "                \n",
    "                # Move both vectors closer to average\n",
    "                self.concept_vectors[source]['vector'] = 0.7 * source_vector + 0.3 * avg_vector\n",
    "                self.concept_vectors[target]['vector'] = 0.7 * target_vector + 0.3 * avg_vector\n",
    "                \n",
    "                # Mark as translation pair\n",
    "                self.concept_vectors[source]['translation_pair'] = target\n",
    "                self.concept_vectors[target]['translation_pair'] = source\n",
    "    \n",
    "    def adjust_vectors_by_relationships(self):\n",
    "        \"\"\"\n",
    "        Adjust vectors based on semantic relationships\n",
    "        \"\"\"\n",
    "        # Iterate to refine positions\n",
    "        for _ in range(3):  \n",
    "            for source, target, data in self.semantic_graph.edges(data=True):\n",
    "                if source in self.concept_vectors and target in self.concept_vectors:\n",
    "                    weight = data.get('weight', 1.0)\n",
    "                    relation = data.get('relation', '')\n",
    "                    \n",
    "                    # Adjust factor based on relation type\n",
    "                    relation_factor = 0.1  # Default\n",
    "                    \n",
    "                    if relation in ['IsA', 'PartOf', 'MadeOf']:\n",
    "                        relation_factor = 0.2  # Stronger pull for hierarchical relations\n",
    "                    elif relation in ['HasProperty', 'HasA', 'CapableOf']:\n",
    "                        relation_factor = 0.15  # Medium pull\n",
    "                    elif relation in ['Antonym', 'DistinctFrom']:\n",
    "                        relation_factor = -0.1  # Push apart for opposite relationships\n",
    "                    \n",
    "                    # Apply adjustment factor\n",
    "                    source_vec = self.concept_vectors[source]['vector']\n",
    "                    target_vec = self.concept_vectors[target]['vector']\n",
    "                    \n",
    "                    # Calculate move vectors - weighted by relation\n",
    "                    diff_vec = (target_vec - source_vec) * weight * relation_factor\n",
    "                    \n",
    "                    # Move vectors\n",
    "                    self.concept_vectors[source]['vector'] += diff_vec\n",
    "                    \n",
    "                    # Only move target for positive relationships\n",
    "                    if relation_factor > 0:\n",
    "                        self.concept_vectors[target]['vector'] -= diff_vec * 0.5\n",
    "                    \n",
    "                    # Renormalize\n",
    "                    self.concept_vectors[source]['vector'] = self.concept_vectors[source]['vector'] / np.linalg.norm(self.concept_vectors[source]['vector']) * 1.5\n",
    "                    self.concept_vectors[target]['vector'] = self.concept_vectors[target]['vector'] / np.linalg.norm(self.concept_vectors[target]['vector']) * 1.5\n",
    "    \n",
    "    def compute_important_relationships(self, threshold=0.5, max_relationships=30):\n",
    "        \"\"\"Compute important relationships for visualization\"\"\"\n",
    "        relationships = []\n",
    "        \n",
    "        for source, target, data in self.semantic_graph.edges(data=True):\n",
    "            if source in self.concept_vectors and target in self.concept_vectors:\n",
    "                weight = data.get('weight', 0.0)\n",
    "                relation = data.get('relation', 'related')\n",
    "                \n",
    "                # Only include relationships above threshold\n",
    "                if weight >= threshold:\n",
    "                    source_vec = self.concept_vectors[source]['vector']\n",
    "                    target_vec = self.concept_vectors[target]['vector']\n",
    "                    \n",
    "                    # Calculate actual vector distance\n",
    "                    try:\n",
    "                        distance = cosine(source_vec, target_vec)\n",
    "                    except:\n",
    "                        distance = 0.5\n",
    "                    \n",
    "                    relationships.append({\n",
    "                        'source': source,\n",
    "                        'target': target,\n",
    "                        'weight': weight,\n",
    "                        'relation': relation,\n",
    "                        'distance': distance\n",
    "                    })\n",
    "        \n",
    "        # Sort by weight and take top relationships\n",
    "        relationships = sorted(relationships, key=lambda x: x['weight'], reverse=True)[:max_relationships]\n",
    "        \n",
    "        return relationships\n",
    "\n",
    "\n",
    "class SemanticVisualizer:\n",
    "    \"\"\"\n",
    "    Enhanced semantic field visualizer using ConceptNet data\n",
    "    \"\"\"\n",
    "    def __init__(self, concept_processor=None):\n",
    "        self.concept_processor = concept_processor\n",
    "        self.fig = None\n",
    "        self.ax = None\n",
    "    \n",
    "    def setup_visualization(self):\n",
    "        \"\"\"Set up the visualization environment\"\"\"\n",
    "        # Create figure with elegant dark theme\n",
    "        plt.style.use('dark_background')\n",
    "        self.fig = plt.figure(figsize=(16, 12), facecolor='#0A0A1E')\n",
    "        self.ax = self.fig.add_subplot(111, projection='3d', facecolor='#0A0A1E')\n",
    "        \n",
    "        # Remove panes to reduce visual clutter\n",
    "        self.ax.xaxis.pane.fill = False\n",
    "        self.ax.yaxis.pane.fill = False\n",
    "        self.ax.zaxis.pane.fill = False\n",
    "        \n",
    "        # Make grid semi-transparent\n",
    "        self.ax.xaxis.pane.set_edgecolor('w')\n",
    "        self.ax.yaxis.pane.set_edgecolor('w')\n",
    "        self.ax.zaxis.pane.set_edgecolor('w')\n",
    "        self.ax.xaxis.pane.set_alpha(0.1)\n",
    "        self.ax.yaxis.pane.set_alpha(0.1)\n",
    "        self.ax.zaxis.pane.set_alpha(0.1)\n",
    "        \n",
    "        # Set title with elegant typography\n",
    "        self.fig.suptitle('Semantica: Semantic Convergence', \n",
    "                     color='white', fontsize=24, fontweight='light', y=0.98)\n",
    "        \n",
    "        # Set axis colors and labels\n",
    "        self.ax.set_xlabel('Semantic Dimension 1', color='white', fontsize=12, labelpad=10)\n",
    "        self.ax.set_ylabel('Semantic Dimension 2', color='white', fontsize=12, labelpad=10)\n",
    "        self.ax.set_zlabel('Semantic Depth', color='white', fontsize=12, labelpad=10)\n",
    "        \n",
    "        # Set tick colors\n",
    "        self.ax.tick_params(axis='x', colors='white', labelsize=9)\n",
    "        self.ax.tick_params(axis='y', colors='white', labelsize=9)\n",
    "        self.ax.tick_params(axis='z', colors='white', labelsize=9)\n",
    "        \n",
    "        # Set a subtle grid\n",
    "        self.ax.grid(True, linestyle=':', alpha=0.2, color='white')\n",
    "        \n",
    "        return self.fig, self.ax\n",
    "    \n",
    "    def visualize_concepts_improved(self, output_dir, num_frames=30):\n",
    "        \"\"\"\n",
    "        Create a more readable and interpretable visualization\n",
    "        with slower rotation and better labeling\n",
    "        \"\"\"\n",
    "        print(\"Creating improved readable visualization...\")\n",
    "        \n",
    "        # Set up visualization with larger figure size\n",
    "        plt.close('all')  # Close all existing figures first\n",
    "        fig = plt.figure(figsize=(20, 14), facecolor='black')  # Increased from (14, 10)\n",
    "        ax = fig.add_subplot(111, projection='3d', facecolor='black')\n",
    "        \n",
    "        # Adjust subplot parameters to give more room for the graph\n",
    "        plt.subplots_adjust(left=0.02, right=0.85)  # This reserves space on the right for the legend\n",
    "        \n",
    "        # Enhanced color scheme for categories - more distinct and contrasting colors\n",
    "        category_colors = {\n",
    "            'fruit': '#FF5722',      # Deep Orange\n",
    "            'color': '#2196F3',      # Blue\n",
    "            'taste': '#FFC107',      # Amber\n",
    "            'vehicle': '#4CAF50',    # Green\n",
    "            'temperature': '#9C27B0', # Purple\n",
    "            'size': '#00BCD4',       # Cyan\n",
    "            'time': '#FF9800',       # Orange\n",
    "            'animal': '#8BC34A',     # Light Green\n",
    "            'person': '#E91E63',     # Pink\n",
    "            'place': '#3F51B5',      # Indigo\n",
    "            'generic': '#BDBDBD'     # Lighter Gray for better visibility\n",
    "        }\n",
    "        \n",
    "        # Category names with better labels\n",
    "        category_labels = {\n",
    "            'fruit': 'Fruit Concepts',\n",
    "            'color': 'Color Concepts',\n",
    "            'taste': 'Taste Concepts',\n",
    "            'vehicle': 'Vehicle Concepts',\n",
    "            'temperature': 'Temperature Concepts',\n",
    "            'size': 'Size Concepts',\n",
    "            'time': 'Time Concepts',\n",
    "            'animal': 'Animal Concepts',\n",
    "            'person': 'Person Concepts',\n",
    "            'place': 'Place Concepts',\n",
    "            'generic': 'General Concepts'\n",
    "        }\n",
    "        \n",
    "        # Enhanced size settings for better visibility\n",
    "        base_point_size = 100\n",
    "        highlight_size_factor = 1.5\n",
    "        \n",
    "        # Create a function to update the plot with better readability\n",
    "        def update(frame):\n",
    "            ax.clear()\n",
    "            \n",
    "            # Set up a clean visualization space with depth\n",
    "            ax.set_facecolor('black')\n",
    "            ax.xaxis.pane.fill = False\n",
    "            ax.yaxis.pane.fill = False\n",
    "            ax.zaxis.pane.fill = False\n",
    "            ax.grid(True, linestyle=':', alpha=0.3, color='white')\n",
    "            \n",
    "            # Set consistent limits and view\n",
    "            ax.set_xlim([-2.5, 2.5])\n",
    "            ax.set_ylim([-2.5, 2.5])\n",
    "            ax.set_zlim([-2.5, 2.5])\n",
    "            \n",
    "            # Extract points with minimal animation\n",
    "            points = {}\n",
    "            plot_points = []\n",
    "            plot_colors = []\n",
    "            plot_sizes = []\n",
    "            plot_labels = []\n",
    "            plot_categories = []\n",
    "            \n",
    "            # Create a smoother, slower oscillation factor\n",
    "            time_factor = frame * 0.1  # Reduced speed\n",
    "            \n",
    "            for concept, data in concept_vectors.items():\n",
    "                vector = data['vector'][:3]  # First 3 dimensions\n",
    "                \n",
    "                # Add subtle animation with very slow movement\n",
    "                concept_phase = (hash(concept) % 100) / 100.0\n",
    "                \n",
    "                oscillation = np.array([\n",
    "                    0.05 * np.sin(time_factor + concept_phase * 6.28),\n",
    "                    0.05 * np.cos(time_factor * 0.7 + concept_phase * 6.28),\n",
    "                    0.05 * np.sin(time_factor * 0.5 + concept_phase * 6.28)\n",
    "                ])\n",
    "                \n",
    "                # Apply minimal oscillation\n",
    "                oscillation *= 0.5 * data.get('potential', 1.0)\n",
    "                \n",
    "                position = vector + oscillation\n",
    "                points[concept] = position\n",
    "                \n",
    "                # Get color based on category\n",
    "                category = data.get('category', 'generic')\n",
    "                color = category_colors.get(category, '#BDBDBD')\n",
    "                \n",
    "                # Size based on importance with better scaling\n",
    "                size = base_point_size * data.get('potential', 1.0)\n",
    "                \n",
    "                # Collect plot data\n",
    "                plot_points.append(position)\n",
    "                plot_colors.append(color)\n",
    "                plot_sizes.append(size)\n",
    "                plot_labels.append(concept)\n",
    "                plot_categories.append(category)\n",
    "            \n",
    "            # Convert to numpy array\n",
    "            if plot_points:\n",
    "                plot_points = np.array(plot_points)\n",
    "            else:\n",
    "                # Fallback if no points\n",
    "                plot_points = np.array([[0, 0, 0]])\n",
    "                plot_colors = ['white']\n",
    "                plot_sizes = [base_point_size]\n",
    "                plot_labels = ['default']\n",
    "                plot_categories = ['generic']\n",
    "            \n",
    "            # Plot points with better aesthetics and visibility\n",
    "            scatter = ax.scatter(\n",
    "                plot_points[:, 0], plot_points[:, 1], plot_points[:, 2], \n",
    "                c=plot_colors, s=plot_sizes, alpha=0.9, \n",
    "                edgecolor='white', linewidth=1.0,  # Thicker outline\n",
    "                depthshade=True\n",
    "            )\n",
    "            \n",
    "            # Draw relationships with clear styling\n",
    "            for i, rel in enumerate(important_relationships[:5]):  # Show only top 5 for clarity\n",
    "                source = rel['source']\n",
    "                target = rel['target']\n",
    "                relation_type = rel['relation']\n",
    "                \n",
    "                if source in points and target in points:\n",
    "                    # Draw line with clear styling based on relation type\n",
    "                    if relation_type in ['IsA', 'PartOf', 'MadeOf']:\n",
    "                        line_color = '#00FFFF'  # Bright cyan for hierarchy\n",
    "                        line_style = '-'\n",
    "                        line_width = 2.5\n",
    "                    elif relation_type in ['HasProperty', 'HasA', 'CapableOf']:\n",
    "                        line_color = '#00FF00'  # Bright green for properties\n",
    "                        line_style = '-'\n",
    "                        line_width = 2.5\n",
    "                    elif relation_type in ['Antonym', 'DistinctFrom']:\n",
    "                        line_color = '#FF0000'  # Bright red for opposites\n",
    "                        line_style = '--'\n",
    "                        line_width = 2.5\n",
    "                    else:\n",
    "                        line_color = '#FFFFFF'  # White for others\n",
    "                        line_style = '-'\n",
    "                        line_width = 2.0\n",
    "                    \n",
    "                    # Draw connection with consistent visibility\n",
    "                    ax.plot(\n",
    "                        [points[source][0], points[target][0]], \n",
    "                        [points[source][1], points[target][1]], \n",
    "                        [points[source][2], points[target][2]], \n",
    "                        color=line_color, alpha=0.9,\n",
    "                        linewidth=line_width, linestyle=line_style\n",
    "                    )\n",
    "                    \n",
    "                    # Add relationship label at midpoint for important relationships\n",
    "                    if i < 3:  # Only label top 3 relationships to avoid clutter\n",
    "                        midpoint = [(points[source][i] + points[target][i])/2 for i in range(3)]\n",
    "                        ax.text(\n",
    "                            midpoint[0], midpoint[1], midpoint[2],\n",
    "                            relation_type,\n",
    "                            color='white',\n",
    "                            fontsize=10,\n",
    "                            fontweight='bold',\n",
    "                            bbox=dict(\n",
    "                                facecolor=(0, 0, 0, 0.7),\n",
    "                                edgecolor='white',\n",
    "                                boxstyle='round',\n",
    "                                alpha=0.9\n",
    "                            ),\n",
    "                            ha='center',\n",
    "                            va='center'\n",
    "                        )\n",
    "            \n",
    "            # Determine important concepts to label\n",
    "            # Focus on important central concepts\n",
    "            concepts_to_label = []\n",
    "            \n",
    "            # Add relationship participants\n",
    "            for rel in important_relationships[:3]:\n",
    "                concepts_to_label.append(rel['source'])\n",
    "                concepts_to_label.append(rel['target'])\n",
    "            \n",
    "            # Add examples of each category\n",
    "            for category in set(plot_categories):\n",
    "                category_concepts = [c for i, c in enumerate(plot_labels) if plot_categories[i] == category]\n",
    "                if category_concepts:\n",
    "                    concepts_to_label.append(category_concepts[0])\n",
    "            \n",
    "            # Add labels with consistent styling and positioning\n",
    "            for concept in list(set(concepts_to_label))[:12]:  # Convert set to list before slicing\n",
    "                if concept in points:\n",
    "                    pos = points[concept]\n",
    "                    \n",
    "                    # Create consistent offset for label\n",
    "                    offset = np.array([0.15, 0.15, 0.15])\n",
    "                    if concept in plot_labels:\n",
    "                        idx = plot_labels.index(concept)\n",
    "                        # Get category information for styling\n",
    "                        cat = plot_categories[idx]\n",
    "                        \n",
    "                    # Add label with high-contrast styling\n",
    "                    ax.text(\n",
    "                        pos[0] + offset[0], \n",
    "                        pos[1] + offset[1], \n",
    "                        pos[2] + offset[2],\n",
    "                        concept, \n",
    "                        color='white', \n",
    "                        fontsize=12,  # Larger font\n",
    "                        fontweight='bold',\n",
    "                        bbox=dict(\n",
    "                            facecolor=(0, 0, 0, 0.8),  # Darker background\n",
    "                            edgecolor='white',         # White border\n",
    "                            boxstyle='round,pad=0.3',  # More padding\n",
    "                            alpha=0.9                  # More opaque\n",
    "                        ),\n",
    "                        ha='left', \n",
    "                        va='bottom',\n",
    "                        zorder=100  # Keep labels on top\n",
    "                    )\n",
    "            \n",
    "            # Create clear legend for categories\n",
    "            # Use a consistent, static legend\n",
    "            legend_elements = []\n",
    "            \n",
    "            # Only show categories that actually appear in the data\n",
    "            visible_categories = set(plot_categories)\n",
    "            \n",
    "            for category in visible_categories:\n",
    "                color = category_colors.get(category, '#BDBDBD')\n",
    "                # Use more descriptive labels\n",
    "                label = category_labels.get(category, category.capitalize())\n",
    "                legend_elements.append(plt.Line2D(\n",
    "                    [0], [0], \n",
    "                    marker='o', \n",
    "                    color='w', \n",
    "                    label=label, \n",
    "                    markerfacecolor=color,\n",
    "                    markersize=10  # Larger marker\n",
    "                ))\n",
    "            \n",
    "            # Add legend with new position\n",
    "            legend = ax.legend(\n",
    "                handles=legend_elements, \n",
    "                loc='center left',  # Changed from 'upper right' to 'center left'\n",
    "                bbox_to_anchor=(1.15, 0.5),  # Places legend outside the plot\n",
    "                fontsize=11,\n",
    "                framealpha=0.9,\n",
    "                edgecolor='white',\n",
    "                facecolor=(0, 0, 0, 0.8)\n",
    "            )\n",
    "            \n",
    "            # Set legend text color to white with bold font\n",
    "            for text in legend.get_texts():\n",
    "                text.set_color('white')\n",
    "                text.set_fontweight('bold')\n",
    "            \n",
    "            # Add informative frame counter with better visibility\n",
    "            ax.text2D(\n",
    "                0.02, 0.98, \n",
    "                f\"Frame: {frame+1}/{num_frames}\", \n",
    "                transform=ax.transAxes, \n",
    "                color='white', \n",
    "                fontsize=12,  # Larger font\n",
    "                fontweight='bold',\n",
    "                bbox=dict(\n",
    "                    facecolor=(0, 0, 0, 0.8),\n",
    "                    edgecolor='white',\n",
    "                    boxstyle='round,pad=0.3',\n",
    "                    alpha=0.9\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Add an explanatory panel describing what's being shown\n",
    "            explanation_text = (\n",
    "                \"Semantica Visualization:\\n\"\n",
    "                \"• Points represent concepts in semantic space\\n\"\n",
    "                \"• Colors indicate concept categories\\n\"\n",
    "                \"• Connected concepts have semantic relationships\\n\"\n",
    "                \"• Spatial proximity indicates semantic similarity\"\n",
    "            )\n",
    "            \n",
    "            ax.text2D(\n",
    "                0.02, 0.12,  # Position near bottom left\n",
    "                explanation_text,\n",
    "                transform=ax.transAxes,\n",
    "                color='white',\n",
    "                fontsize=10,\n",
    "                fontweight='bold',\n",
    "                bbox=dict(\n",
    "                    facecolor=(0, 0, 0, 0.8),\n",
    "                    edgecolor='white',\n",
    "                    boxstyle='round,pad=0.5',\n",
    "                    alpha=0.9\n",
    "                ),\n",
    "                linespacing=1.5  # More space between lines\n",
    "            )\n",
    "            \n",
    "            # MUCH slower camera movement for better readability\n",
    "            # Just a gentle rotation to show 3D structure\n",
    "            # Using modulo to create a smooth oscillation between specific angles\n",
    "            \n",
    "            # Full rotation every 120 frames (4x slower than before)\n",
    "            rotation_angle = (frame * 3) % 360  # Very slow rotation\n",
    "            \n",
    "            # Gentle camera bobbing between 20 and 30 degrees elevation\n",
    "            elevation = 20 + 5 * np.sin(frame * 0.1)  # Subtle elevation change\n",
    "            \n",
    "            ax.view_init(elev=elevation, azim=rotation_angle)\n",
    "            \n",
    "            # Add static title with no animation\n",
    "            plt.title(\n",
    "                'Semantica: Relational Semantic Convergence', \n",
    "                color='white',\n",
    "                fontsize=16,  # Larger font\n",
    "                fontweight='bold',\n",
    "                pad=20\n",
    "            )\n",
    "            \n",
    "            # Print progress occasionally\n",
    "            if frame % max(1, num_frames // 10) == 0:\n",
    "                print(f\"Rendering frame {frame+1}/{num_frames}\")\n",
    "            \n",
    "            return ax\n",
    "        \n",
    "        # Create output directory if needed\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Create a static preview image\n",
    "        print(\"Creating static preview...\")\n",
    "        update(0)  # Use first frame for preview\n",
    "        \n",
    "        static_path = os.path.join(output_dir, f'semantica_readable_preview_{uuid.uuid4()}.png')\n",
    "        plt.savefig(static_path, dpi=120, bbox_inches='tight')\n",
    "        print(f\"Static preview saved to {static_path}\")\n",
    "        \n",
    "        # Create animation with optimized settings for readability\n",
    "        try:\n",
    "            print(f\"Creating improved readable animation with {num_frames} frames...\")\n",
    "            \n",
    "            # Memory management: Clear the figure and recreate\n",
    "            plt.close('all')\n",
    "            fig = plt.figure(figsize=(14, 10), facecolor='black')\n",
    "            ax = fig.add_subplot(111, projection='3d', facecolor='black')\n",
    "            \n",
    "            # Create animation with more frames for smoother, slower movement\n",
    "            anim = animation.FuncAnimation(\n",
    "                fig, update, frames=num_frames, \n",
    "                interval=200,  # Slower frame rate (200ms vs 100ms)\n",
    "                blit=False\n",
    "            )\n",
    "            \n",
    "            # Use PillowWriter with optimized settings for readability\n",
    "            output_path = os.path.join(output_dir, f'semantica_readable_{uuid.uuid4()}.gif')\n",
    "            print(f\"Saving readable animation to {output_path}...\")\n",
    "            \n",
    "            # Use optimized writer settings for readability\n",
    "            writer = animation.PillowWriter(\n",
    "                fps=8,        # Much slower frame rate (was 15)\n",
    "                bitrate=2000, # Higher quality\n",
    "                metadata=dict(artist='Semantica')\n",
    "            )\n",
    "            \n",
    "            # Save with progress updates\n",
    "            anim.save(\n",
    "                output_path, \n",
    "                writer=writer,\n",
    "                dpi=120,      # Higher resolution\n",
    "                savefig_kwargs={'facecolor': 'black'}\n",
    "            )\n",
    "            \n",
    "            # Verify animation\n",
    "            if os.path.exists(output_path):\n",
    "                file_size = os.path.getsize(output_path) / (1024 * 1024)\n",
    "                print(f\"Readable animation saved successfully! File size: {file_size:.2f} MB\")\n",
    "                \n",
    "                # Verify it's a valid GIF\n",
    "                try:\n",
    "                    from PIL import Image\n",
    "                    with Image.open(output_path) as img:\n",
    "                        frames = 0\n",
    "                        try:\n",
    "                            while True:\n",
    "                                frames += 1\n",
    "                                img.seek(img.tell() + 1)\n",
    "                        except EOFError:\n",
    "                            pass\n",
    "                        print(f\"Animation contains {frames} frames\")\n",
    "                except Exception as e:\n",
    "                    print(f\"GIF validation error: {e}\")\n",
    "            \n",
    "            plt.close(fig)\n",
    "            return output_path\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Animation creation failed: {e}\")\n",
    "            print(traceback.format_exc())\n",
    "            plt.close('all')\n",
    "            return static_path\n",
    "\n",
    "# Update the process_conceptnet_data function to include the new visualization option\n",
    "def process_conceptnet_data(english_data, german_data, output_dir, visualization_type='readable'):\n",
    "    \"\"\"\n",
    "    Process ConceptNet data and create visualization\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    english_data : DataFrame\n",
    "        English ConceptNet data\n",
    "    german_data : DataFrame\n",
    "        German ConceptNet data\n",
    "    output_dir : str\n",
    "        Directory to save visualizations\n",
    "    visualization_type : str\n",
    "        Type of visualization to create:\n",
    "        - 'basic': Simple 3D visualization\n",
    "        - 'advanced': Enhanced 3D visualization with more visual elements\n",
    "        - 'network': 2D network visualization\n",
    "        - 'readable': New improved readable visualization with slower rotation\n",
    "        - 'all': Create all visualization types\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    concept_processor : ConceptNetProcessor\n",
    "        Processor object with semantic graph and vectors\n",
    "    output_paths : list\n",
    "        Paths to created visualizations\n",
    "    \"\"\"\n",
    "    print(\"Starting ConceptNet processing pipeline...\")\n",
    "    \n",
    "    # Initialize ConceptNet processor\n",
    "    concept_processor = ConceptNetProcessor(english_data, german_data)\n",
    "    \n",
    "    # Build semantic graph from ConceptNet data\n",
    "    concept_processor.build_semantic_graph(max_concepts=150, sample_size=5000)\n",
    "    \n",
    "    # Generate concept vectors\n",
    "    concept_vectors = concept_processor.generate_concept_vectors(dimensions=5)\n",
    "    \n",
    "    # Compute important relationships for visualization\n",
    "    important_relationships = concept_processor.compute_important_relationships(threshold=0.5, max_relationships=30)\n",
    "    \n",
    "    # Initialize visualizer\n",
    "    visualizer = SemanticVisualizer(concept_processor)\n",
    "    \n",
    "    output_paths = []\n",
    "    \n",
    "    # Create visualizations based on requested type\n",
    "    if visualization_type in ['readable', 'all']:\n",
    "        print(\"Creating readable 3D visualization...\")\n",
    "        output_path = visualizer.visualize_concepts_improved(\n",
    "            output_dir, \n",
    "            num_frames=40  # More frames for smoother, slower movement\n",
    "        )\n",
    "        output_paths.append(output_path)\n",
    "\n",
    "    if visualization_type in ['basic', 'all']:\n",
    "        print(\"Creating basic 3D visualization...\")\n",
    "        output_path = visualizer.visualize_concepts_enhanced(\n",
    "            output_dir, \n",
    "            num_frames=20\n",
    "        )\n",
    "        output_paths.append(output_path)\n",
    "\n",
    "    if visualization_type in ['advanced', 'all']:\n",
    "        print(\"Creating advanced 3D visualization...\")\n",
    "        output_path = visualizer.visualize_concepts_interactive(\n",
    "            output_dir, \n",
    "            num_frames=30\n",
    "        )\n",
    "        output_paths.append(output_path)\n",
    "\n",
    "    if visualization_type in ['network', 'all']:\n",
    "        print(\"Creating 2D network visualization...\")\n",
    "        output_path = visualizer.visualize_2d_network(output_dir)\n",
    "        output_paths.append(output_path)\n",
    "\n",
    "    print(f\"Visualization(s) created at: {', '.join(output_paths)}\")\n",
    "    return concept_processor, output_paths\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify input and output directories\n",
    "    input_data_path = '../Data/Input'\n",
    "    output_dir = '../Data/Output'\n",
    "    \n",
    "    # Load ConceptNet data\n",
    "    print(\"Loading ConceptNet data...\")\n",
    "    english_conceptnet = pd.read_csv(os.path.join(input_data_path, 'conceptnet-assertions-5.7.0.en.tsv'), \n",
    "                                   sep='\\t', header=None, names=['start', 'rel', 'end', 'weight'])\n",
    "    \n",
    "    german_conceptnet = pd.read_csv(os.path.join(input_data_path, 'conceptnet-assertions-5.7.0.de.tsv'), \n",
    "                                  sep='\\t', header=None, names=['start', 'rel', 'end', 'weight'])\n",
    "    \n",
    "    print(f\"English ConceptNet loaded with {len(english_conceptnet)} assertions.\")\n",
    "    print(f\"German ConceptNet loaded with {len(german_conceptnet)} assertions.\")\n",
    "    \n",
    "    # Process data and create visualizations\n",
    "    processor, viz_paths = process_conceptnet_data(\n",
    "        english_conceptnet, \n",
    "        german_conceptnet, \n",
    "        output_dir,\n",
    "        visualization_type='readable'  # Use the new readable visualization\n",
    "    )\n",
    "    \n",
    "    print(\"Process complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca1289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
