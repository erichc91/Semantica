{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deec642b",
   "metadata": {},
   "source": [
    "# Semantica relation GRaph visualized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d84ca",
   "metadata": {},
   "source": [
    "# Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2118648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "import random\n",
    "import io\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import uuid\n",
    "import warnings\n",
    "import traceback\n",
    "import json  # Added missing import\n",
    "from scipy.spatial.distance import cosine  # Added missing import\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-interactive backend for better memory handling\n",
    "\n",
    "class ConceptNetProcessor:\n",
    "    \"\"\"\n",
    "    Process ConceptNet data for semantic visualization\n",
    "    \"\"\"\n",
    "    def __init__(self, english_data=None, german_data=None):\n",
    "        self.english_data = english_data\n",
    "        self.german_data = german_data\n",
    "        self.semantic_graph = nx.DiGraph()\n",
    "        self.concept_vectors = {}\n",
    "        self.relation_types = set()\n",
    "        \n",
    "        print(\"ConceptNetProcessor initialized\")\n",
    "    \n",
    "    def clean_concept_name(self, concept_str):\n",
    "        \"\"\"Extract clean concept name from ConceptNet format\"\"\"\n",
    "        if not isinstance(concept_str, str):\n",
    "            return \"unknown\"\n",
    "            \n",
    "        # Extract the concept name from the ConceptNet URI format\n",
    "        parts = concept_str.split('/')\n",
    "        if len(parts) >= 4:\n",
    "            # Format is typically /c/LANG/CONCEPT\n",
    "            concept = parts[-1]\n",
    "            # Remove part-of-speech tags if present\n",
    "            if '/' in concept:\n",
    "                concept = concept.split('/')[0]\n",
    "            return concept\n",
    "        return concept_str\n",
    "    \n",
    "    def extract_relation_type(self, relation_str):\n",
    "        \"\"\"Extract relation type from ConceptNet format\"\"\"\n",
    "        if not isinstance(relation_str, str):\n",
    "            return \"unknown\"\n",
    "            \n",
    "        parts = relation_str.split('/')\n",
    "        if len(parts) >= 3:\n",
    "            # Format is typically /r/RELATION_TYPE\n",
    "            return parts[-1]\n",
    "        return relation_str\n",
    "    \n",
    "    def extract_language(self, concept_str):\n",
    "        \"\"\"Extract language from ConceptNet concept URI\"\"\"\n",
    "        if not isinstance(concept_str, str):\n",
    "            return \"unknown\"\n",
    "            \n",
    "        parts = concept_str.split('/')\n",
    "        if len(parts) >= 4:\n",
    "            # Format is typically /c/LANG/CONCEPT\n",
    "            return parts[2]\n",
    "        return \"unknown\"\n",
    "    \n",
    "    def parse_weight(self, weight_str):\n",
    "        \"\"\"Parse weight JSON string to extract numeric weight\"\"\"\n",
    "        if not isinstance(weight_str, str):\n",
    "            return 1.0\n",
    "            \n",
    "        try:\n",
    "            weight_data = json.loads(weight_str)\n",
    "            # ConceptNet weights are typically in 'weight' field\n",
    "            return float(weight_data.get('weight', 1.0))\n",
    "        except:\n",
    "            return 1.0\n",
    "    \n",
    "    def build_semantic_graph(self, max_concepts=200, min_weight=1.0, sample_size=0.25):\n",
    "        \"\"\"Build semantic graph from ConceptNet data\"\"\"\n",
    "        print(\"Building semantic graph from ConceptNet data...\")\n",
    "        \n",
    "        if self.english_data is None and self.german_data is None:\n",
    "            print(\"No ConceptNet data provided.\")\n",
    "            return\n",
    "        \n",
    "        # Combine datasets\n",
    "        all_data = []\n",
    "        if self.english_data is not None:\n",
    "            print(f\"Processing {len(self.english_data)} English ConceptNet assertions...\")\n",
    "            sample_size_en = int(len(self.english_data) * sample_size)\n",
    "            print(f\"Will sample {sample_size_en} English assertions\")\n",
    "            all_data.append(('en', self.english_data))\n",
    "        \n",
    "        if self.german_data is not None:\n",
    "            print(f\"Processing {len(self.german_data)} German ConceptNet assertions...\")\n",
    "            sample_size_de = int(len(self.german_data) * sample_size)\n",
    "            print(f\"Will sample {sample_size_de} German assertions\")\n",
    "            all_data.append(('de', self.german_data))\n",
    "        \n",
    "        # Track concepts and their occurrence count\n",
    "        concept_counts = {}\n",
    "        \n",
    "        # Process each language dataset\n",
    "        for lang, data in all_data:\n",
    "            curr_sample_size = int(len(data) * sample_size)\n",
    "            data_sample = data.sample(n=curr_sample_size, random_state=42)\n",
    "            print(f\"Sampling {curr_sample_size} assertions from {len(data)} {lang} assertions\")\n",
    "            \n",
    "            # Process assertions\n",
    "            for _, row in tqdm(data_sample.iterrows(), desc=f\"Processing {lang} assertions\", total=len(data_sample)):\n",
    "                try:\n",
    "                    # Extract source and target concepts\n",
    "                    source_concept = self.clean_concept_name(row['start'])\n",
    "                    target_concept = self.clean_concept_name(row['end'])\n",
    "                    \n",
    "                    # Extract relation type\n",
    "                    relation_type = self.extract_relation_type(row['rel'])\n",
    "                    self.relation_types.add(relation_type)\n",
    "                    \n",
    "                    # Extract languages\n",
    "                    source_lang = self.extract_language(row['start'])\n",
    "                    target_lang = self.extract_language(row['end'])\n",
    "                    \n",
    "                    # Parse weight\n",
    "                    weight = self.parse_weight(row['weight'])\n",
    "                    \n",
    "                    # Skip low-weight relationships\n",
    "                    if weight < min_weight:\n",
    "                        continue\n",
    "                    \n",
    "                    # Track concept occurrences\n",
    "                    concept_counts[source_concept] = concept_counts.get(source_concept, 0) + 1\n",
    "                    concept_counts[target_concept] = concept_counts.get(target_concept, 0) + 1\n",
    "                    \n",
    "                    # Add to graph\n",
    "                    self.semantic_graph.add_node(\n",
    "                        source_concept,\n",
    "                        lang=source_lang,\n",
    "                        count=concept_counts[source_concept]\n",
    "                    )\n",
    "                    \n",
    "                    self.semantic_graph.add_node(\n",
    "                        target_concept,\n",
    "                        lang=target_lang,\n",
    "                        count=concept_counts[target_concept]\n",
    "                    )\n",
    "                    \n",
    "                    # Add edge with relation data\n",
    "                    self.semantic_graph.add_edge(\n",
    "                        source_concept,\n",
    "                        target_concept,\n",
    "                        relation=relation_type,\n",
    "                        weight=weight\n",
    "                    )\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    warnings.warn(f\"Error processing assertion: {e}\")\n",
    "        \n",
    "        # Limit to top concepts if needed\n",
    "        if len(concept_counts) > max_concepts:\n",
    "            print(f\"Limiting graph to top {max_concepts} concepts...\")\n",
    "            top_concepts = sorted(concept_counts.items(), key=lambda x: x[1], reverse=True)[:max_concepts]\n",
    "            top_concept_names = {c[0] for c in top_concepts}\n",
    "            \n",
    "            # Create subgraph with only top concepts\n",
    "            subgraph = nx.DiGraph()\n",
    "            \n",
    "            for node in top_concept_names:\n",
    "                if self.semantic_graph.has_node(node):\n",
    "                    subgraph.add_node(\n",
    "                        node,\n",
    "                        **self.semantic_graph.nodes[node]\n",
    "                    )\n",
    "            \n",
    "            for source, target, data in self.semantic_graph.edges(data=True):\n",
    "                if source in top_concept_names and target in top_concept_names:\n",
    "                    subgraph.add_edge(\n",
    "                        source,\n",
    "                        target,\n",
    "                        **data\n",
    "                    )\n",
    "            \n",
    "            self.semantic_graph = subgraph\n",
    "        \n",
    "        print(f\"Semantic graph built with {self.semantic_graph.number_of_nodes()} nodes and {self.semantic_graph.number_of_edges()} edges\")\n",
    "        \n",
    "        # Infer semantic categories\n",
    "        self.infer_semantic_categories()\n",
    "        \n",
    "        return self.semantic_graph\n",
    "    \n",
    "    def infer_semantic_categories(self):\n",
    "        \"\"\"Infer semantic categories for concepts based on relationships\"\"\"\n",
    "        print(\"Inferring semantic categories...\")\n",
    "        categories = {}\n",
    "        \n",
    "        # Count relationship types for each concept\n",
    "        for node in self.semantic_graph.nodes():\n",
    "            # Initialize as generic\n",
    "            categories[node] = 'generic'\n",
    "            \n",
    "            # Get all relationships involving this concept\n",
    "            in_edges = self.semantic_graph.in_edges(node, data=True)\n",
    "            out_edges = self.semantic_graph.out_edges(node, data=True)\n",
    "            \n",
    "            # Count relationship types\n",
    "            person_relations = 0\n",
    "            place_relations = 0\n",
    "            animal_relations = 0\n",
    "            \n",
    "            for _, _, data in in_edges:\n",
    "                rel = data.get('relation', '')\n",
    "                if rel in {'IsA/person', 'CapableOf', 'HasA'}:\n",
    "                    person_relations += 1\n",
    "                elif rel in {'AtLocation', 'LocatedNear', 'HasA'}:\n",
    "                    place_relations += 1\n",
    "                elif rel in {'IsA/animal', 'CapableOf'}:\n",
    "                    animal_relations += 1\n",
    "            \n",
    "            for _, _, data in out_edges:\n",
    "                rel = data.get('relation', '')\n",
    "                if rel in {'IsA/person', 'CapableOf', 'HasA'}:\n",
    "                    person_relations += 1\n",
    "                elif rel in {'AtLocation', 'LocatedNear', 'HasA'}:\n",
    "                    place_relations += 1\n",
    "                elif rel in {'IsA/animal', 'CapableOf'}:\n",
    "                    animal_relations += 1\n",
    "            \n",
    "            # Assign category based on dominant relationships\n",
    "            max_relations = max(person_relations, place_relations, animal_relations)\n",
    "            if max_relations > 0:\n",
    "                if max_relations == person_relations:\n",
    "                    categories[node] = 'person'\n",
    "                elif max_relations == place_relations:\n",
    "                    categories[node] = 'place'\n",
    "                elif max_relations == animal_relations:\n",
    "                    categories[node] = 'animal'\n",
    "        \n",
    "        # Update graph with categories\n",
    "        nx.set_node_attributes(self.semantic_graph, categories, 'category')\n",
    "        \n",
    "        # Print category statistics\n",
    "        category_counts = {}\n",
    "        for cat in categories.values():\n",
    "            category_counts[cat] = category_counts.get(cat, 0) + 1\n",
    "        print(f\"Inferred categories: {category_counts}\")\n",
    "    \n",
    "    def compute_important_relationships(self, threshold=0.5, max_relationships=30):\n",
    "        \"\"\"Compute the most important relationships between concepts based on vector similarity\"\"\"\n",
    "        important_relationships = []\n",
    "        \n",
    "        # Get all pairs of concepts\n",
    "        concepts = list(self.concept_vectors.keys())\n",
    "        for i, concept1 in enumerate(concepts):\n",
    "            for concept2 in concepts[i+1:]:\n",
    "                # Get vectors\n",
    "                vec1 = self.concept_vectors[concept1]['vector']\n",
    "                vec2 = self.concept_vectors[concept2]['vector']\n",
    "                \n",
    "                # Compute cosine similarity\n",
    "                similarity = 1 - cosine(vec1, vec2)\n",
    "                \n",
    "                if similarity > threshold:\n",
    "                    important_relationships.append({\n",
    "                        'source': concept1,\n",
    "                        'target': concept2,\n",
    "                        'similarity': similarity\n",
    "                    })\n",
    "        \n",
    "        # Sort by similarity and take top N\n",
    "        important_relationships.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "        return important_relationships[:max_relationships]\n",
    "    \n",
    "    def generate_concept_vectors(self, dimensions=5):\n",
    "        \"\"\"Generate concept vectors based on graph structure\"\"\"\n",
    "        print(f\"Generating {dimensions}-dimensional concept vectors...\")\n",
    "        \n",
    "        # Use node2vec or similar embedding\n",
    "        nodes = list(self.semantic_graph.nodes())\n",
    "        \n",
    "        # Simple embedding based on connectivity patterns\n",
    "        adjacency_matrix = nx.adjacency_matrix(self.semantic_graph).todense()\n",
    "        \n",
    "        # Use SVD to reduce dimensionality\n",
    "        U, _, _ = np.linalg.svd(adjacency_matrix)\n",
    "        embeddings = U[:, :dimensions]\n",
    "        \n",
    "        # Normalize embeddings\n",
    "        embeddings = (embeddings - embeddings.mean(axis=0)) / embeddings.std(axis=0)\n",
    "        \n",
    "        # Convert to dictionary with structured data\n",
    "        for i, node in enumerate(nodes):\n",
    "            self.concept_vectors[node] = {\n",
    "                'vector': embeddings[i],\n",
    "                'category': self.semantic_graph.nodes[node].get('category', 'generic')\n",
    "            }\n",
    "        \n",
    "        print(f\"Generated vectors for {len(self.concept_vectors)} concepts\")\n",
    "        return self.concept_vectors\n",
    "\n",
    "class SemanticVisualizer:\n",
    "    def __init__(self, concept_processor=None):\n",
    "        self.concept_processor = concept_processor\n",
    "        self.fig = None\n",
    "        self.ax = None\n",
    "        self.category_colors = {\n",
    "            'person': '#FF6B6B',  # Warm red\n",
    "            'place': '#4ECDC4',   # Teal\n",
    "            'animal': '#FFD93D',  # Bright yellow\n",
    "            'generic': '#95A5A6'  # Neutral gray\n",
    "        }\n",
    "        self.category_descriptions = {\n",
    "            'person': 'Human Entities & Roles',\n",
    "            'place': 'Locations & Spaces',\n",
    "            'animal': 'Living Creatures',\n",
    "            'generic': 'Abstract Concepts'\n",
    "        }\n",
    "\n",
    "    def visualize_concepts_improved(self, output_dir, num_frames=30):\n",
    "        \"\"\"Create an enhanced visualization with labels, legends, and smooth transitions\"\"\"\n",
    "        try:\n",
    "            print(\"Creating enhanced semantic visualization...\")\n",
    "            \n",
    "            if not self.concept_processor or not self.concept_processor.concept_vectors:\n",
    "                raise ValueError(\"Concept processor not initialized or no vectors generated\")\n",
    "            \n",
    "            # Get important relationships\n",
    "            try:\n",
    "                important_relationships = self.concept_processor.compute_important_relationships(\n",
    "                    threshold=0.5, \n",
    "                    max_relationships=30\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not compute relationships: {str(e)}\")\n",
    "                important_relationships = []\n",
    "\n",
    "            # Setup figure with high DPI for crisp text\n",
    "            plt.close('all')\n",
    "            fig = plt.figure(figsize=(20, 14), facecolor='black', dpi=150)\n",
    "            ax = fig.add_subplot(111, projection='3d', facecolor='black')\n",
    "            \n",
    "            # Add a title with project info\n",
    "            fig.suptitle('Semantic Concept Space Visualization\\nRelational Semantic Convergence (RSC) Theory', \n",
    "                        color='white', y=0.95, fontsize=16, fontweight='bold')\n",
    "\n",
    "            def update(frame):\n",
    "                try:\n",
    "                    ax.clear()\n",
    "                    ax.set_facecolor('black')\n",
    "                    \n",
    "                    # Configure axis appearance\n",
    "                    ax.grid(True, alpha=0.1, color='white')\n",
    "                    ax.xaxis.pane.fill = False\n",
    "                    ax.yaxis.pane.fill = False\n",
    "                    ax.zaxis.pane.fill = False\n",
    "                    \n",
    "                    # Remove axis labels but keep tick marks\n",
    "                    ax.set_xticklabels([])\n",
    "                    ax.set_yticklabels([])\n",
    "                    ax.set_zticklabels([])\n",
    "                    \n",
    "                    # Calculate smooth rotation angle\n",
    "                    theta = (frame / num_frames) * 2 * np.pi\n",
    "                    \n",
    "                    # Convert concept vectors to 3D points with rotation\n",
    "                    points = {}\n",
    "                    for concept, data in self.concept_processor.concept_vectors.items():\n",
    "                        vector = data['vector'][:3]\n",
    "                        \n",
    "                        # Apply smooth rotation matrix\n",
    "                        x, y, z = vector\n",
    "                        x_rot = x * np.cos(theta) - y * np.sin(theta)\n",
    "                        y_rot = x * np.sin(theta) + y * np.cos(theta)\n",
    "                        \n",
    "                        points[concept] = (x_rot, y_rot, z)\n",
    "                    \n",
    "                    # Plot points by category with enhanced visual elements\n",
    "                    legend_elements = []\n",
    "                    for category, color in self.category_colors.items():\n",
    "                        cat_points = [\n",
    "                            (concept, (x, y, z)) for concept, (x, y, z) in points.items()\n",
    "                            if self.concept_processor.concept_vectors[concept]['category'] == category\n",
    "                        ]\n",
    "                        \n",
    "                        if cat_points:\n",
    "                            concepts, coords = zip(*cat_points)\n",
    "                            xs, ys, zs = zip(*coords)\n",
    "                            \n",
    "                            # Create scatter plot with glowing effect\n",
    "                            scatter = ax.scatter(xs, ys, zs, \n",
    "                                              c=color, \n",
    "                                              alpha=0.8, \n",
    "                                              s=100,  # Larger points\n",
    "                                              edgecolors='white',\n",
    "                                              linewidth=0.5)\n",
    "                            \n",
    "                            # Add category to legend\n",
    "                            legend_elements.append(plt.Line2D([0], [0], \n",
    "                                                            marker='o', \n",
    "                                                            color='none',\n",
    "                                                            markerfacecolor=color,\n",
    "                                                            markeredgecolor='white',\n",
    "                                                            markersize=10,\n",
    "                                                            label=self.category_descriptions[category]))\n",
    "                            \n",
    "                            # Add labels for important concepts\n",
    "                            for concept, (x, y, z) in zip(concepts, coords):\n",
    "                                if len(concept) > 2:  # Only label non-trivial concepts\n",
    "                                    ax.text(x, y, z, \n",
    "                                          concept,\n",
    "                                          color='white',\n",
    "                                          fontsize=8,\n",
    "                                          alpha=0.7,\n",
    "                                          backgroundcolor=(0, 0, 0, 0.3))\n",
    "                    \n",
    "                    # Add connections between related concepts\n",
    "                    if important_relationships and frame == 0:  # Only on first frame for performance\n",
    "                        for rel in important_relationships[:10]:  # Limit to top 10 relationships\n",
    "                            if rel['source'] in points and rel['target'] in points:\n",
    "                                x1, y1, z1 = points[rel['source']]\n",
    "                                x2, y2, z2 = points[rel['target']]\n",
    "                                ax.plot([x1, x2], [y1, y2], [z1, z2], \n",
    "                                      color='white',\n",
    "                                      alpha=0.2,\n",
    "                                      linestyle='--')\n",
    "                    \n",
    "                    # Add legend with enhanced styling\n",
    "                    legend = ax.legend(handles=legend_elements,\n",
    "                                     loc='center left',\n",
    "                                     bbox_to_anchor=(1.15, 0.5),\n",
    "                                     title='Semantic Categories',\n",
    "                                     facecolor='black',\n",
    "                                     edgecolor='white',\n",
    "                                     framealpha=0.8)\n",
    "                    legend.get_title().set_color('white')\n",
    "                    for text in legend.get_texts():\n",
    "                        text.set_color('white')\n",
    "                    \n",
    "                    # Add RSC theory info\n",
    "                    ax.text2D(0.02, 0.02, \n",
    "                             'RSC Theory Visualization\\nShowing semantic relationships and concept clustering',\n",
    "                             transform=ax.transAxes,\n",
    "                             color='white',\n",
    "                             alpha=0.7,\n",
    "                             fontsize=8)\n",
    "                    \n",
    "                    return ax\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error in update frame {frame}: {str(e)}\")\n",
    "                    return ax\n",
    "\n",
    "            # Create animation with enhanced parameters\n",
    "            anim = animation.FuncAnimation(\n",
    "                fig, \n",
    "                update,\n",
    "                frames=num_frames,\n",
    "                interval=50,  # Faster frame rate for smoother animation\n",
    "                blit=False\n",
    "            )\n",
    "            \n",
    "            # Create a static preview image\n",
    "            print(\"Creating enhanced static preview...\")\n",
    "            update(0)\n",
    "            \n",
    "            # Save with high quality settings\n",
    "            static_path = os.path.join(output_dir, f'semantica_readable_preview_{uuid.uuid4()}.png')\n",
    "            plt.savefig(static_path, dpi=150, bbox_inches='tight')\n",
    "            \n",
    "            # Save animation with enhanced quality\n",
    "            output_path = os.path.join(output_dir, f'semantica_readable_{uuid.uuid4()}.gif')\n",
    "            anim.save(\n",
    "                output_path,\n",
    "                writer='pillow',\n",
    "                fps=30,  # Higher FPS for smoother animation\n",
    "                dpi=150\n",
    "            )\n",
    "            \n",
    "            plt.close()\n",
    "            print(f\"Enhanced visualization saved successfully to {output_path}\")\n",
    "            return output_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating visualization: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6ca1289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ConceptNet data...\n",
      "English ConceptNet loaded with 3423004 assertions.\n",
      "German ConceptNet loaded with 1078946 assertions.\n",
      "ConceptNetProcessor initialized\n",
      "Building semantic graph from ConceptNet data...\n",
      "Processing 3423004 English ConceptNet assertions...\n",
      "Will sample 855751 English assertions\n",
      "Processing 1078946 German ConceptNet assertions...\n",
      "Will sample 269736 German assertions\n",
      "Sampling 855751 assertions from 3423004 en assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing en assertions: 100%|██████████| 855751/855751 [00:28<00:00, 30542.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 269736 assertions from 1078946 de assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing de assertions: 100%|██████████| 269736/269736 [00:08<00:00, 31268.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limiting graph to top 2000 concepts...\n",
      "Semantic graph built with 2000 nodes and 13518 edges\n",
      "Inferring semantic categories...\n",
      "Inferred categories: {'generic': 1503, 'person': 84, 'place': 413}\n",
      "Generating 5-dimensional concept vectors...\n",
      "Generated vectors for 2000 concepts\n",
      "Creating improved readable visualization...\n",
      "Creating static preview...\n",
      "Visualization created at: ../Data/Output\\semantica_readable_551255a7-0a1c-4798-928b-5d912f2715be.gif\n"
     ]
    }
   ],
   "source": [
    "# Load and process ConceptNet data\n",
    "print(\"Loading ConceptNet data...\")\n",
    "english_conceptnet = pd.read_csv(\n",
    "    '../Data/Input/conceptnet-assertions-5.7.0.en.tsv',\n",
    "    sep='\\t',\n",
    "    names=['URI', 'rel', 'start', 'end', 'weight', 'source', 'id', 'dataset', 'surfaceText']\n",
    ")\n",
    "german_conceptnet = pd.read_csv(\n",
    "    '../Data/Input/conceptnet-assertions-5.7.0.de.tsv',\n",
    "    sep='\\t',\n",
    "    names=['URI', 'rel', 'start', 'end', 'weight', 'source', 'id', 'dataset', 'surfaceText']\n",
    ")\n",
    "\n",
    "print(f\"English ConceptNet loaded with {len(english_conceptnet)} assertions.\")\n",
    "print(f\"German ConceptNet loaded with {len(german_conceptnet)} assertions.\")\n",
    "\n",
    "# Initialize processor with larger sample size\n",
    "processor = ConceptNetProcessor(english_conceptnet, german_conceptnet)\n",
    "\n",
    "# Build semantic graph with 25% sampling\n",
    "processor.build_semantic_graph(\n",
    "    max_concepts=2_000,  # Keep reasonable number of concepts for visualization\n",
    "    min_weight=1.0,\n",
    "    sample_size=0.25  # Use 25% of the data\n",
    ")\n",
    "\n",
    "# Generate concept vectors\n",
    "processor.generate_concept_vectors(dimensions=5)\n",
    "\n",
    "# Initialize visualizer\n",
    "visualizer = SemanticVisualizer(processor)\n",
    "\n",
    "# Create improved visualization with more frames for smoother animation\n",
    "output_dir = '../Data/Output'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "output_path = visualizer.visualize_concepts_improved(\n",
    "    output_dir,\n",
    "    num_frames=300  # Increased number of frames for smoother animation\n",
    ")\n",
    "\n",
    "print(f\"Visualization created at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247a4913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
