{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc93c8ff",
   "metadata": {},
   "source": [
    "# Data Loading and Setup\n",
    "\n",
    "First, we'll set up our environment and load the data once, making it available to both Phase 1 and Phase 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb84fa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ConceptNet data from Google Drive...\n",
      "Using cached data at ../Data/Input/conceptnet-assertions-5.7.0.en.tsv\n",
      "English ConceptNet loaded with 3423004 assertions.\n",
      "Using cached data at ../Data/Input/conceptnet-assertions-5.7.0.de.tsv\n",
      "German ConceptNet loaded with 1078946 assertions.\n",
      "Data loading complete. Datasets available: True\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "import random\n",
    "import io\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import uuid\n",
    "import warnings\n",
    "import traceback\n",
    "import json\n",
    "from scipy.spatial.distance import cosine\n",
    "import matplotlib\n",
    "import requests\n",
    "from io import StringIO\n",
    "import gdown\n",
    "matplotlib.use('Agg')  # Use non-interactive backend for better memory handling\n",
    "\n",
    "# Create necessary directories\n",
    "output_dir = '../Data/Output'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Load ConceptNet data from Google Drive links\n",
    "print(\"Loading ConceptNet data from Google Drive...\")\n",
    "\n",
    "# Define the Google Drive links\n",
    "english_dataset_id = \"1zBwy1rhJh-7ESQWVENkz1z1_G2aleu7-\"  # ID from the Google Drive link\n",
    "german_dataset_id = \"10Rb0sn4uZVUJSufp08t1wzrLL1jAnRHH\"  # ID from the Google Drive link\n",
    "\n",
    "# Define file paths for caching\n",
    "english_cache_path = '../Data/Input/conceptnet-assertions-5.7.0.en.tsv'\n",
    "german_cache_path = '../Data/Input/conceptnet-assertions-5.7.0.de.tsv'\n",
    "\n",
    "# Create the Input directory if it doesn't exist\n",
    "input_dir = '../Data/Input'\n",
    "if not os.path.exists(input_dir):\n",
    "    os.makedirs(input_dir)\n",
    "\n",
    "# Function to download data\n",
    "def download_from_gdrive(file_id, output_path):\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"Using cached data at {output_path}\")\n",
    "        return True\n",
    "    \n",
    "    print(f\"Downloading data to {output_path}...\")\n",
    "    try:\n",
    "        gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_path, quiet=False)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file: {e}\")\n",
    "        return False\n",
    "\n",
    "# Download and load the datasets\n",
    "english_conceptnet = None\n",
    "german_conceptnet = None\n",
    "\n",
    "# Try to download English dataset\n",
    "if download_from_gdrive(english_dataset_id, english_cache_path):\n",
    "    english_conceptnet = pd.read_csv(\n",
    "        english_cache_path,\n",
    "        sep='\\t',\n",
    "        names=['URI', 'rel', 'start', 'end', 'weight', 'source', 'id', 'dataset', 'surfaceText']\n",
    "    )\n",
    "    print(f\"English ConceptNet loaded with {len(english_conceptnet)} assertions.\")\n",
    "else:\n",
    "    print(\"Failed to load English dataset. Will use a smaller test dataset if available.\")\n",
    "\n",
    "# Try to download German dataset\n",
    "if download_from_gdrive(german_dataset_id, german_cache_path):\n",
    "    german_conceptnet = pd.read_csv(\n",
    "        german_cache_path,\n",
    "        sep='\\t',\n",
    "        names=['URI', 'rel', 'start', 'end', 'weight', 'source', 'id', 'dataset', 'surfaceText']\n",
    "    )\n",
    "    print(f\"German ConceptNet loaded with {len(german_conceptnet)} assertions.\")\n",
    "else:\n",
    "    print(\"Failed to load German dataset. Will use a smaller test dataset if available.\")\n",
    "\n",
    "# If downloading fails, try to use any existing files\n",
    "if english_conceptnet is None and os.path.exists(english_cache_path):\n",
    "    try:\n",
    "        english_conceptnet = pd.read_csv(\n",
    "            english_cache_path,\n",
    "            sep='\\t',\n",
    "            names=['URI', 'rel', 'start', 'end', 'weight', 'source', 'id', 'dataset', 'surfaceText']\n",
    "        )\n",
    "        print(f\"Using existing English ConceptNet with {len(english_conceptnet)} assertions.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading existing English data: {e}\")\n",
    "\n",
    "if german_conceptnet is None and os.path.exists(german_cache_path):\n",
    "    try:\n",
    "        german_conceptnet = pd.read_csv(\n",
    "            german_cache_path,\n",
    "            sep='\\t',\n",
    "            names=['URI', 'rel', 'start', 'end', 'weight', 'source', 'id', 'dataset', 'surfaceText']\n",
    "        )\n",
    "        print(f\"Using existing German ConceptNet with {len(german_conceptnet)} assertions.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading existing German data: {e}\")\n",
    "\n",
    "# Set a flag to track if we need to run Phase 1 data processing\n",
    "data_loaded = english_conceptnet is not None or german_conceptnet is not None\n",
    "print(f\"Data loading complete. Datasets available: {data_loaded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deec642b",
   "metadata": {},
   "source": [
    "# Semantica relation GRaph visualized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d84ca",
   "metadata": {},
   "source": [
    "# Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2118648f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e1d20ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "import random\n",
    "import io\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import uuid\n",
    "import warnings\n",
    "import traceback\n",
    "import json  # Added missing import\n",
    "from scipy.spatial.distance import cosine  # Added missing import\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-interactive backend for better memory handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a19c8254",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConceptNetProcessor:\n",
    "    \"\"\"\n",
    "    Process ConceptNet data for semantic visualization\n",
    "    \"\"\"\n",
    "    def __init__(self, english_data=None, german_data=None):\n",
    "        self.english_data = english_data\n",
    "        self.german_data = german_data\n",
    "        self.semantic_graph = nx.DiGraph()\n",
    "        self.concept_vectors = {}\n",
    "        self.relation_types = set()\n",
    "        \n",
    "        print(\"ConceptNetProcessor initialized\")\n",
    "    \n",
    "    def clean_concept_name(self, concept_str):\n",
    "        \"\"\"Extract clean concept name from ConceptNet format\"\"\"\n",
    "        if not isinstance(concept_str, str):\n",
    "            return \"unknown\"\n",
    "            \n",
    "        # Extract the concept name from the ConceptNet URI format\n",
    "        parts = concept_str.split('/')\n",
    "        if len(parts) >= 4:\n",
    "            # Format is typically /c/LANG/CONCEPT\n",
    "            concept = parts[-1]\n",
    "            # Remove part-of-speech tags if present\n",
    "            if '/' in concept:\n",
    "                concept = concept.split('/')[0]\n",
    "            return concept\n",
    "        return concept_str\n",
    "    \n",
    "    def extract_relation_type(self, relation_str):\n",
    "        \"\"\"Extract relation type from ConceptNet format\"\"\"\n",
    "        if not isinstance(relation_str, str):\n",
    "            return \"unknown\"\n",
    "            \n",
    "        parts = relation_str.split('/')\n",
    "        if len(parts) >= 3:\n",
    "            # Format is typically /r/RELATION_TYPE\n",
    "            return parts[-1]\n",
    "        return relation_str\n",
    "    \n",
    "    def extract_language(self, concept_str):\n",
    "        \"\"\"Extract language from ConceptNet concept URI\"\"\"\n",
    "        if not isinstance(concept_str, str):\n",
    "            return \"unknown\"\n",
    "            \n",
    "        parts = concept_str.split('/')\n",
    "        if len(parts) >= 4:\n",
    "            # Format is typically /c/LANG/CONCEPT\n",
    "            return parts[2]\n",
    "        return \"unknown\"\n",
    "    \n",
    "    def parse_weight(self, weight_str):\n",
    "        \"\"\"Parse weight JSON string to extract numeric weight\"\"\"\n",
    "        if not isinstance(weight_str, str):\n",
    "            return 1.0\n",
    "            \n",
    "        try:\n",
    "            weight_data = json.loads(weight_str)\n",
    "            # ConceptNet weights are typically in 'weight' field\n",
    "            return float(weight_data.get('weight', 1.0))\n",
    "        except:\n",
    "            return 1.0\n",
    "    \n",
    "    def build_semantic_graph(self, max_concepts=200, min_weight=1.0, sample_size=0.25):\n",
    "        \"\"\"Build semantic graph from ConceptNet data\"\"\"\n",
    "        print(\"Building semantic graph from ConceptNet data...\")\n",
    "        \n",
    "        if self.english_data is None and self.german_data is None:\n",
    "            print(\"No ConceptNet data provided.\")\n",
    "            return\n",
    "        \n",
    "        # Combine datasets\n",
    "        all_data = []\n",
    "        if self.english_data is not None:\n",
    "            print(f\"Processing {len(self.english_data)} English ConceptNet assertions...\")\n",
    "            sample_size_en = int(len(self.english_data) * sample_size)\n",
    "            print(f\"Will sample {sample_size_en} English assertions\")\n",
    "            all_data.append(('en', self.english_data))\n",
    "        \n",
    "        if self.german_data is not None:\n",
    "            print(f\"Processing {len(self.german_data)} German ConceptNet assertions...\")\n",
    "            sample_size_de = int(len(self.german_data) * sample_size)\n",
    "            print(f\"Will sample {sample_size_de} German assertions\")\n",
    "            all_data.append(('de', self.german_data))\n",
    "        \n",
    "        # Track concepts and their occurrence count\n",
    "        concept_counts = {}\n",
    "        \n",
    "        # Process each language dataset\n",
    "        for lang, data in all_data:\n",
    "            curr_sample_size = int(len(data) * sample_size)\n",
    "            data_sample = data.sample(n=curr_sample_size, random_state=42)\n",
    "            print(f\"Sampling {curr_sample_size} assertions from {len(data)} {lang} assertions\")\n",
    "            \n",
    "            # Process assertions\n",
    "            for _, row in tqdm(data_sample.iterrows(), desc=f\"Processing {lang} assertions\", total=len(data_sample)):\n",
    "                try:\n",
    "                    # Extract source and target concepts\n",
    "                    source_concept = self.clean_concept_name(row['start'])\n",
    "                    target_concept = self.clean_concept_name(row['end'])\n",
    "                    \n",
    "                    # Extract relation type\n",
    "                    relation_type = self.extract_relation_type(row['rel'])\n",
    "                    self.relation_types.add(relation_type)\n",
    "                    \n",
    "                    # Extract languages\n",
    "                    source_lang = self.extract_language(row['start'])\n",
    "                    target_lang = self.extract_language(row['end'])\n",
    "                    \n",
    "                    # Parse weight\n",
    "                    weight = self.parse_weight(row['weight'])\n",
    "                    \n",
    "                    # Skip low-weight relationships\n",
    "                    if weight < min_weight:\n",
    "                        continue\n",
    "                    \n",
    "                    # Track concept occurrences\n",
    "                    concept_counts[source_concept] = concept_counts.get(source_concept, 0) + 1\n",
    "                    concept_counts[target_concept] = concept_counts.get(target_concept, 0) + 1\n",
    "                    \n",
    "                    # Add to graph\n",
    "                    self.semantic_graph.add_node(\n",
    "                        source_concept,\n",
    "                        lang=source_lang,\n",
    "                        count=concept_counts[source_concept]\n",
    "                    )\n",
    "                    \n",
    "                    self.semantic_graph.add_node(\n",
    "                        target_concept,\n",
    "                        lang=target_lang,\n",
    "                        count=concept_counts[target_concept]\n",
    "                    )\n",
    "                    \n",
    "                    # Add edge with relation data\n",
    "                    self.semantic_graph.add_edge(\n",
    "                        source_concept,\n",
    "                        target_concept,\n",
    "                        relation=relation_type,\n",
    "                        weight=weight\n",
    "                    )\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    warnings.warn(f\"Error processing assertion: {e}\")\n",
    "        \n",
    "        # Limit to top concepts if needed\n",
    "        if len(concept_counts) > max_concepts:\n",
    "            print(f\"Limiting graph to top {max_concepts} concepts...\")\n",
    "            top_concepts = sorted(concept_counts.items(), key=lambda x: x[1], reverse=True)[:max_concepts]\n",
    "            top_concept_names = {c[0] for c in top_concepts}\n",
    "            \n",
    "            # Create subgraph with only top concepts\n",
    "            subgraph = nx.DiGraph()\n",
    "            \n",
    "            for node in top_concept_names:\n",
    "                if self.semantic_graph.has_node(node):\n",
    "                    subgraph.add_node(\n",
    "                        node,\n",
    "                        **self.semantic_graph.nodes[node]\n",
    "                    )\n",
    "            \n",
    "            for source, target, data in self.semantic_graph.edges(data=True):\n",
    "                if source in top_concept_names and target in top_concept_names:\n",
    "                    subgraph.add_edge(\n",
    "                        source,\n",
    "                        target,\n",
    "                        **data\n",
    "                    )\n",
    "            \n",
    "            self.semantic_graph = subgraph\n",
    "        \n",
    "        print(f\"Semantic graph built with {self.semantic_graph.number_of_nodes()} nodes and {self.semantic_graph.number_of_edges()} edges\")\n",
    "        \n",
    "        # Infer semantic categories\n",
    "        self.infer_semantic_categories()\n",
    "        \n",
    "        return self.semantic_graph\n",
    "    \n",
    "    def infer_semantic_categories(self):\n",
    "        \"\"\"Infer semantic categories for concepts based on relationships\"\"\"\n",
    "        print(\"Inferring semantic categories...\")\n",
    "        categories = {}\n",
    "        \n",
    "        # Count relationship types for each concept\n",
    "        for node in self.semantic_graph.nodes():\n",
    "            # Initialize as generic\n",
    "            categories[node] = 'generic'\n",
    "            \n",
    "            # Get all relationships involving this concept\n",
    "            in_edges = self.semantic_graph.in_edges(node, data=True)\n",
    "            out_edges = self.semantic_graph.out_edges(node, data=True)\n",
    "            \n",
    "            # Count relationship types\n",
    "            person_relations = 0\n",
    "            place_relations = 0\n",
    "            animal_relations = 0\n",
    "            \n",
    "            for _, _, data in in_edges:\n",
    "                rel = data.get('relation', '')\n",
    "                if rel in {'IsA/person', 'CapableOf', 'HasA'}:\n",
    "                    person_relations += 1\n",
    "                elif rel in {'AtLocation', 'LocatedNear', 'HasA'}:\n",
    "                    place_relations += 1\n",
    "                elif rel in {'IsA/animal', 'CapableOf'}:\n",
    "                    animal_relations += 1\n",
    "            \n",
    "            for _, _, data in out_edges:\n",
    "                rel = data.get('relation', '')\n",
    "                if rel in {'IsA/person', 'CapableOf', 'HasA'}:\n",
    "                    person_relations += 1\n",
    "                elif rel in {'AtLocation', 'LocatedNear', 'HasA'}:\n",
    "                    place_relations += 1\n",
    "                elif rel in {'IsA/animal', 'CapableOf'}:\n",
    "                    animal_relations += 1\n",
    "            \n",
    "            # Assign category based on dominant relationships\n",
    "            max_relations = max(person_relations, place_relations, animal_relations)\n",
    "            if max_relations > 0:\n",
    "                if max_relations == person_relations:\n",
    "                    categories[node] = 'person'\n",
    "                elif max_relations == place_relations:\n",
    "                    categories[node] = 'place'\n",
    "                elif max_relations == animal_relations:\n",
    "                    categories[node] = 'animal'\n",
    "        \n",
    "        # Update graph with categories\n",
    "        nx.set_node_attributes(self.semantic_graph, categories, 'category')\n",
    "        \n",
    "        # Print category statistics\n",
    "        category_counts = {}\n",
    "        for cat in categories.values():\n",
    "            category_counts[cat] = category_counts.get(cat, 0) + 1\n",
    "        print(f\"Inferred categories: {category_counts}\")\n",
    "    \n",
    "    def compute_important_relationships(self, threshold=0.5, max_relationships=30):\n",
    "        \"\"\"Compute the most important relationships between concepts based on vector similarity\"\"\"\n",
    "        important_relationships = []\n",
    "        \n",
    "        # Get all pairs of concepts\n",
    "        concepts = list(self.concept_vectors.keys())\n",
    "        for i, concept1 in enumerate(concepts):\n",
    "            for concept2 in concepts[i+1:]:\n",
    "                # Get vectors\n",
    "                vec1 = self.concept_vectors[concept1]['vector']\n",
    "                vec2 = self.concept_vectors[concept2]['vector']\n",
    "                \n",
    "                # Compute cosine similarity\n",
    "                similarity = 1 - cosine(vec1, vec2)\n",
    "                \n",
    "                if similarity > threshold:\n",
    "                    important_relationships.append({\n",
    "                        'source': concept1,\n",
    "                        'target': concept2,\n",
    "                        'similarity': similarity\n",
    "                    })\n",
    "        \n",
    "        # Sort by similarity and take top N\n",
    "        important_relationships.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "        return important_relationships[:max_relationships]\n",
    "    \n",
    "    def generate_concept_vectors(self, dimensions=5):\n",
    "        \"\"\"Generate concept vectors based on graph structure\"\"\"\n",
    "        print(f\"Generating {dimensions}-dimensional concept vectors...\")\n",
    "        \n",
    "        # Use node2vec or similar embedding\n",
    "        nodes = list(self.semantic_graph.nodes())\n",
    "        \n",
    "        # Simple embedding based on connectivity patterns\n",
    "        adjacency_matrix = nx.adjacency_matrix(self.semantic_graph).todense()\n",
    "        \n",
    "        # Use SVD to reduce dimensionality\n",
    "        U, _, _ = np.linalg.svd(adjacency_matrix)\n",
    "        embeddings = U[:, :dimensions]\n",
    "        \n",
    "        # Normalize embeddings\n",
    "        embeddings = (embeddings - embeddings.mean(axis=0)) / embeddings.std(axis=0)\n",
    "        \n",
    "        # Convert to dictionary with structured data\n",
    "        for i, node in enumerate(nodes):\n",
    "            self.concept_vectors[node] = {\n",
    "                'vector': embeddings[i],\n",
    "                'category': self.semantic_graph.nodes[node].get('category', 'generic')\n",
    "            }\n",
    "        \n",
    "        print(f\"Generated vectors for {len(self.concept_vectors)} concepts\")\n",
    "        return self.concept_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eb322a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SemanticVisualizer:\n",
    "    def __init__(self, concept_processor=None):\n",
    "        self.concept_processor = concept_processor\n",
    "        self.fig = None\n",
    "        self.ax = None\n",
    "        self.category_colors = {\n",
    "            'person': '#FF6B6B',  # Warm red\n",
    "            'place': '#4ECDC4',   # Teal\n",
    "            'animal': '#FFD93D',  # Bright yellow\n",
    "            'generic': '#95A5A6'  # Neutral gray\n",
    "        }\n",
    "        self.category_descriptions = {\n",
    "            'person': 'Human Entities & Roles',\n",
    "            'place': 'Locations & Spaces',\n",
    "            'animal': 'Living Creatures',\n",
    "            'generic': 'Abstract Concepts'\n",
    "        }\n",
    "\n",
    "    def visualize_concepts_improved(self, output_dir, num_frames=30):\n",
    "        \"\"\"Create an enhanced visualization with labels, legends, and smooth transitions\"\"\"\n",
    "        try:\n",
    "            print(\"Creating enhanced semantic visualization...\")\n",
    "            \n",
    "            if not self.concept_processor or not self.concept_processor.concept_vectors:\n",
    "                raise ValueError(\"Concept processor not initialized or no vectors generated\")\n",
    "            \n",
    "            # Get important relationships\n",
    "            try:\n",
    "                important_relationships = self.concept_processor.compute_important_relationships(\n",
    "                    threshold=0.5, \n",
    "                    max_relationships=30\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not compute relationships: {str(e)}\")\n",
    "                important_relationships = []\n",
    "\n",
    "            # Setup figure with high DPI for crisp text\n",
    "            plt.close('all')\n",
    "            fig = plt.figure(figsize=(20, 14), facecolor='black', dpi=150)\n",
    "            ax = fig.add_subplot(111, projection='3d', facecolor='black')\n",
    "            \n",
    "            # Add a title with project info\n",
    "            fig.suptitle('Semantic Concept Space Visualization\\nRelational Semantic Convergence (RSC) Theory', \n",
    "                        color='white', y=0.95, fontsize=16, fontweight='bold')\n",
    "\n",
    "            def update(frame):\n",
    "                try:\n",
    "                    ax.clear()\n",
    "                    ax.set_facecolor('black')\n",
    "                    \n",
    "                    # Configure axis appearance\n",
    "                    ax.grid(True, alpha=0.1, color='white')\n",
    "                    ax.xaxis.pane.fill = False\n",
    "                    ax.yaxis.pane.fill = False\n",
    "                    ax.zaxis.pane.fill = False\n",
    "                    \n",
    "                    # Remove axis labels but keep tick marks\n",
    "                    ax.set_xticklabels([])\n",
    "                    ax.set_yticklabels([])\n",
    "                    ax.set_zticklabels([])\n",
    "                    \n",
    "                    # Calculate smooth rotation angle\n",
    "                    theta = (frame / num_frames) * 2 * np.pi\n",
    "                    \n",
    "                    # Convert concept vectors to 3D points with rotation\n",
    "                    points = {}\n",
    "                    for concept, data in self.concept_processor.concept_vectors.items():\n",
    "                        vector = data['vector'][:3]\n",
    "                        \n",
    "                        # Apply smooth rotation matrix\n",
    "                        x, y, z = vector\n",
    "                        x_rot = x * np.cos(theta) - y * np.sin(theta)\n",
    "                        y_rot = x * np.sin(theta) + y * np.cos(theta)\n",
    "                        \n",
    "                        points[concept] = (x_rot, y_rot, z)\n",
    "                    \n",
    "                    # Plot points by category with enhanced visual elements\n",
    "                    legend_elements = []\n",
    "                    for category, color in self.category_colors.items():\n",
    "                        cat_points = [\n",
    "                            (concept, (x, y, z)) for concept, (x, y, z) in points.items()\n",
    "                            if self.concept_processor.concept_vectors[concept]['category'] == category\n",
    "                        ]\n",
    "                        \n",
    "                        if cat_points:\n",
    "                            concepts, coords = zip(*cat_points)\n",
    "                            xs, ys, zs = zip(*coords)\n",
    "                            \n",
    "                            # Create scatter plot with glowing effect\n",
    "                            scatter = ax.scatter(xs, ys, zs, \n",
    "                                              c=color, \n",
    "                                              alpha=0.8, \n",
    "                                              s=100,  # Larger points\n",
    "                                              edgecolors='white',\n",
    "                                              linewidth=0.5)\n",
    "                            \n",
    "                            # Add category to legend\n",
    "                            legend_elements.append(plt.Line2D([0], [0], \n",
    "                                                            marker='o', \n",
    "                                                            color='none',\n",
    "                                                            markerfacecolor=color,\n",
    "                                                            markeredgecolor='white',\n",
    "                                                            markersize=10,\n",
    "                                                            label=self.category_descriptions[category]))\n",
    "                            \n",
    "                            # Add labels for important concepts\n",
    "                            for concept, (x, y, z) in zip(concepts, coords):\n",
    "                                if len(concept) > 2:  # Only label non-trivial concepts\n",
    "                                    ax.text(x, y, z, \n",
    "                                          concept,\n",
    "                                          color='white',\n",
    "                                          fontsize=8,\n",
    "                                          alpha=0.7,\n",
    "                                          backgroundcolor=(0, 0, 0, 0.3))\n",
    "                    \n",
    "                    # Add connections between related concepts\n",
    "                    if important_relationships and frame == 0:  # Only on first frame for performance\n",
    "                        for rel in important_relationships[:10]:  # Limit to top 10 relationships\n",
    "                            if rel['source'] in points and rel['target'] in points:\n",
    "                                x1, y1, z1 = points[rel['source']]\n",
    "                                x2, y2, z2 = points[rel['target']]\n",
    "                                ax.plot([x1, x2], [y1, y2], [z1, z2], \n",
    "                                      color='white',\n",
    "                                      alpha=0.2,\n",
    "                                      linestyle='--')\n",
    "                    \n",
    "                    # Add legend with enhanced styling\n",
    "                    legend = ax.legend(handles=legend_elements,\n",
    "                                     loc='center left',\n",
    "                                     bbox_to_anchor=(1.15, 0.5),\n",
    "                                     title='Semantic Categories',\n",
    "                                     facecolor='black',\n",
    "                                     edgecolor='white',\n",
    "                                     framealpha=0.8)\n",
    "                    legend.get_title().set_color('white')\n",
    "                    for text in legend.get_texts():\n",
    "                        text.set_color('white')\n",
    "                    \n",
    "                    # Add RSC theory info\n",
    "                    ax.text2D(0.02, 0.02, \n",
    "                             'RSC Theory Visualization\\nShowing semantic relationships and concept clustering',\n",
    "                             transform=ax.transAxes,\n",
    "                             color='white',\n",
    "                             alpha=0.7,\n",
    "                             fontsize=8)\n",
    "                    \n",
    "                    return ax\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error in update frame {frame}: {str(e)}\")\n",
    "                    return ax\n",
    "\n",
    "            # Create animation with enhanced parameters\n",
    "            anim = animation.FuncAnimation(\n",
    "                fig, \n",
    "                update,\n",
    "                frames=num_frames,\n",
    "                interval=50,  # Faster frame rate for smoother animation\n",
    "                blit=False\n",
    "            )\n",
    "            \n",
    "            # Create a static preview image\n",
    "            print(\"Creating enhanced static preview...\")\n",
    "            update(0)\n",
    "            \n",
    "            # Save with high quality settings\n",
    "            static_path = os.path.join(output_dir, f'semantica_readable_preview_{uuid.uuid4()}.png')\n",
    "            plt.savefig(static_path, dpi=150, bbox_inches='tight')\n",
    "            \n",
    "            # Save animation with enhanced quality\n",
    "            output_path = os.path.join(output_dir, f'semantica_readable_{uuid.uuid4()}.gif')\n",
    "            # Use a more robust method to save the animation\n",
    "            frames = []\n",
    "            frame_files = []  # Keep track of temporary files\n",
    "            tmp_dir = os.path.join(output_dir, 'tmp_frames')\n",
    "            \n",
    "            # Create temporary directory for frames\n",
    "            if not os.path.exists(tmp_dir):\n",
    "                os.makedirs(tmp_dir)\n",
    "                \n",
    "            try:\n",
    "                print(\"Generating frames...\")\n",
    "                for i in range(num_frames):\n",
    "                    # Update the figure for this frame\n",
    "                    update(i)\n",
    "                    \n",
    "                    # Save frame to a temporary file instead of keeping in memory\n",
    "                    tmp_file = os.path.join(tmp_dir, f'frame_{i:04d}.png')\n",
    "                    plt.savefig(tmp_file, dpi=150, bbox_inches='tight',\n",
    "                               facecolor=self.bg_gradient['bottom'])\n",
    "                    frame_files.append(tmp_file)\n",
    "                    \n",
    "                    # Print progress\n",
    "                    if i % 10 == 0 or i == num_frames - 1:\n",
    "                        print(f\"Generated frame {i+1}/{num_frames}\")\n",
    "                \n",
    "                # Create GIF using external library\n",
    "                print(\"Saving animation...\")\n",
    "                from PIL import Image\n",
    "                \n",
    "                # Load all frames from files\n",
    "                frames = [Image.open(f) for f in frame_files]\n",
    "                \n",
    "                # Ensure all frames are the same size\n",
    "                if frames:\n",
    "                    size = frames[0].size\n",
    "                    frames = [f.resize(size) for f in frames]\n",
    "                    \n",
    "                    # Save as GIF\n",
    "                    frames[0].save(\n",
    "                        output_path,\n",
    "                        save_all=True,\n",
    "                        append_images=frames[1:],\n",
    "                        optimize=False,\n",
    "                        duration=1000/30,  # 30 FPS\n",
    "                        loop=0\n",
    "                    )\n",
    "                    \n",
    "                    # Close all frames\n",
    "                    for f in frames:\n",
    "                        f.close()\n",
    "                    \n",
    "                    print(f\"Enhanced visualization saved successfully to {output_path}\")\n",
    "            finally:\n",
    "                # Clean up temporary files\n",
    "                for file in frame_files:\n",
    "                    try:\n",
    "                        if os.path.exists(file):\n",
    "                            os.remove(file)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Warning: Could not remove temporary file {file}: {e}\")\n",
    "                        \n",
    "                # Try to remove temp directory\n",
    "                try:\n",
    "                    if os.path.exists(tmp_dir):\n",
    "                        os.rmdir(tmp_dir)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not remove temporary directory: {e}\")\n",
    "            \n",
    "            plt.close()\n",
    "            return output_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating visualization: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6ca1289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ConceptNetProcessor with loaded datasets...\n",
      "ConceptNetProcessor initialized\n",
      "Building semantic graph from ConceptNet data...\n",
      "Processing 3423004 English ConceptNet assertions...\n",
      "Will sample 171150 English assertions\n",
      "Processing 1078946 German ConceptNet assertions...\n",
      "Will sample 53947 German assertions\n",
      "Sampling 171150 assertions from 3423004 en assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing en assertions: 100%|██████████| 171150/171150 [00:04<00:00, 39983.64it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 53947 assertions from 1078946 de assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing de assertions: 100%|██████████| 53947/53947 [00:01<00:00, 36625.40it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limiting graph to top 100 concepts...\n",
      "Semantic graph built with 100 nodes and 697 edges\n",
      "Inferring semantic categories...\n",
      "Inferred categories: {'generic': 100}\n",
      "Generating 5-dimensional concept vectors...\n",
      "Generated vectors for 100 concepts\n",
      "Creating enhanced semantic visualization...\n",
      "Creating enhanced static preview...\n",
      "Generating frames...\n",
      "Error creating visualization: 'SemanticVisualizer' object has no attribute 'bg_gradient'\n",
      "Visualization created at: None\n",
      "Generating frames...\n",
      "Error creating visualization: 'SemanticVisualizer' object has no attribute 'bg_gradient'\n",
      "Visualization created at: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Erich Curtis\\AppData\\Local\\Temp\\ipykernel_61348\\574494523.py\", line 190, in visualize_concepts_improved\n",
      "    facecolor=self.bg_gradient['bottom'])\n",
      "              ^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'SemanticVisualizer' object has no attribute 'bg_gradient'\n"
     ]
    }
   ],
   "source": [
    "# Initialize processor with the datasets we loaded at the beginning\n",
    "print(\"Initializing ConceptNetProcessor with loaded datasets...\")\n",
    "processor = ConceptNetProcessor(english_conceptnet, german_conceptnet)\n",
    "\n",
    "# Build semantic graph with 25% sampling\n",
    "processor.build_semantic_graph(\n",
    "    max_concepts=100,  # Keep reasonable number of concepts for visualization\n",
    "    min_weight=1.0,\n",
    "    sample_size=0.05  # Use 25% of the data\n",
    ")\n",
    "\n",
    "# Generate concept vectors\n",
    "processor.generate_concept_vectors(dimensions=5)\n",
    "\n",
    "# Initialize visualizer\n",
    "visualizer = SemanticVisualizer(processor)\n",
    "\n",
    "# Create improved visualization with more frames for smoother animation\n",
    "output_path = visualizer.visualize_concepts_improved(\n",
    "    output_dir,\n",
    "    num_frames=300  # Increased number of frames for smoother animation\n",
    ")\n",
    "\n",
    "print(f\"Visualization created at: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bda2ec4",
   "metadata": {},
   "source": [
    "# Phase 2: Enhanced Visualization\n",
    "\n",
    "Based on feedback, we're improving the visualization to make it more intuitive and appealing for both technical and general audiences. Key enhancements include:\n",
    "\n",
    "1. **Progress indicator** - Shows current frame and total frames so viewers know where they are in the animation\n",
    "2. **Improved visual relationships** - Clear connection lines between related concepts with directional arrows\n",
    "3. **Interactive elements** - Hover tooltips and concept highlighting (for interactive environments)\n",
    "4. **Better storytelling** - Explanatory text and conceptual grouping visualizations\n",
    "5. **Visual appeal** - Enhanced color scheme, lighting effects, and background gradients\n",
    "6. **Clearer concept representation** - Size nodes based on importance, add labels for key concepts\n",
    "7. **Animation transitions** - Smoother transitions and camera movements between frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e717fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedSemanticVisualizer:\n",
    "    def __init__(self, concept_processor=None):\n",
    "        self.concept_processor = concept_processor\n",
    "        self.fig = None\n",
    "        self.ax = None\n",
    "        # Enhanced color palette with deeper, more vibrant colors\n",
    "        self.category_colors = {\n",
    "            'person': '#FF5E7E',     # Vibrant pink/red\n",
    "            'place': '#36EAFF',      # Bright cyan\n",
    "            'animal': '#FFDD3C',     # Golden yellow\n",
    "            'generic': '#B8C6DB'     # Soft lavender\n",
    "        }\n",
    "        # More descriptive category labels\n",
    "        self.category_descriptions = {\n",
    "            'person': 'Human Concepts & Relationships',\n",
    "            'place': 'Spatial & Location Concepts',\n",
    "            'animal': 'Living Entities & Nature',\n",
    "            'generic': 'Abstract & General Concepts'\n",
    "        }\n",
    "        # Background gradient colors\n",
    "        self.bg_gradient = {\n",
    "            'top': '#0F2027',       # Dark blue-black\n",
    "            'middle': '#203A43',    # Deep teal\n",
    "            'bottom': '#2C5364'     # Navy blue\n",
    "        }\n",
    "        # Store background rectangles\n",
    "        self.bg_rects = []\n",
    "        # Store progress indicator elements\n",
    "        self.progress_elements = []\n",
    "        \n",
    "    def _create_background_gradient(self, fig, ax):\n",
    "        \"\"\"Create a beautiful gradient background\"\"\"\n",
    "        # Clear any existing background rectangles\n",
    "        for rect in self.bg_rects:\n",
    "            if rect in fig.patches:\n",
    "                fig.patches.remove(rect)\n",
    "        self.bg_rects = []\n",
    "        \n",
    "        # Create new background rectangles\n",
    "        bottom_rect = plt.Rectangle(\n",
    "            (0, 0), 1, 1,\n",
    "            transform=fig.transFigure,\n",
    "            color=self.bg_gradient['bottom'],\n",
    "            alpha=0.9, zorder=-1\n",
    "        )\n",
    "        middle_rect = plt.Rectangle(\n",
    "            (0, 0.3), 1, 0.4,\n",
    "            transform=fig.transFigure,\n",
    "            color=self.bg_gradient['middle'],\n",
    "            alpha=0.7, zorder=-1\n",
    "        )\n",
    "        top_rect = plt.Rectangle(\n",
    "            (0, 0.7), 1, 0.3,\n",
    "            transform=fig.transFigure,\n",
    "            color=self.bg_gradient['top'],\n",
    "            alpha=0.8, zorder=-1\n",
    "        )\n",
    "        \n",
    "        # Add rectangles to figure\n",
    "        fig.patches.extend([bottom_rect, middle_rect, top_rect])\n",
    "        self.bg_rects = [bottom_rect, middle_rect, top_rect]\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def _add_progress_indicator(self, fig, frame, total_frames):\n",
    "        \"\"\"Add a visual progress indicator showing current frame and total\"\"\"\n",
    "        # Clear previous progress indicator elements\n",
    "        for element in self.progress_elements:\n",
    "            if isinstance(element, matplotlib.text.Text) and element in fig.texts:\n",
    "                fig.texts.remove(element)\n",
    "            elif isinstance(element, matplotlib.patches.Rectangle) and element in fig.patches:\n",
    "                fig.patches.remove(element)\n",
    "        self.progress_elements = []\n",
    "                \n",
    "        # Calculate percentage complete\n",
    "        percentage = (frame / total_frames) * 100\n",
    "        \n",
    "        # Create progress text\n",
    "        progress_text = fig.text(\n",
    "            0.01, 0.01,\n",
    "            f\"Frame: {frame+1}/{total_frames} ({percentage:.1f}%)\",\n",
    "            color='white',\n",
    "            fontsize=10,\n",
    "            alpha=0.8,\n",
    "            transform=fig.transFigure\n",
    "        )\n",
    "        self.progress_elements.append(progress_text)\n",
    "        \n",
    "        # Add progress bar background\n",
    "        progress_bar_bg = plt.Rectangle(\n",
    "            (0.01, 0.03), 0.2, 0.01,\n",
    "            transform=fig.transFigure,\n",
    "            color='white', alpha=0.3\n",
    "        )\n",
    "        fig.patches.append(progress_bar_bg)\n",
    "        self.progress_elements.append(progress_bar_bg)\n",
    "        \n",
    "        # Add progress bar fill\n",
    "        progress_bar_fill = plt.Rectangle(\n",
    "            (0.01, 0.03), 0.2 * (frame / total_frames), 0.01,\n",
    "            transform=fig.transFigure,\n",
    "            color='#36EAFF', alpha=0.8\n",
    "        )\n",
    "        fig.patches.append(progress_bar_fill)\n",
    "        self.progress_elements.append(progress_bar_fill)\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def _add_relationship_lines(self, ax, points, important_relationships, frame_pct):\n",
    "        \"\"\"Add visually appealing relationship lines between concepts\"\"\"\n",
    "        # Only show the top relationships for clarity\n",
    "        if not important_relationships:\n",
    "            return ax\n",
    "            \n",
    "        # Create a pulsing effect based on frame percentage\n",
    "        pulse = 0.5 + 0.5 * np.sin(frame_pct * 2 * np.pi * 2)  # 2 pulses per cycle\n",
    "        \n",
    "        # Draw connections with gradient colors and pulse effect\n",
    "        for i, rel in enumerate(important_relationships[:15]):  # Limit to top relationships\n",
    "            if rel['source'] in points and rel['target'] in points:\n",
    "                src = points[rel['source']]\n",
    "                tgt = points[rel['target']]\n",
    "                \n",
    "                # Gradually reveal relationships throughout the animation\n",
    "                reveal_threshold = i / 15  # Stagger appearance\n",
    "                if frame_pct < reveal_threshold:\n",
    "                    continue\n",
    "                    \n",
    "                # Calculate line alpha based on similarity strength and pulse\n",
    "                alpha = min(0.7, rel['similarity'] * pulse)\n",
    "                \n",
    "                # Determine relationship color based on similarity\n",
    "                if rel['similarity'] > 0.8:\n",
    "                    color = '#FF5E7E'  # Strong relationship - pink\n",
    "                elif rel['similarity'] > 0.65:\n",
    "                    color = '#36EAFF'  # Medium relationship - cyan\n",
    "                else:\n",
    "                    color = '#FFFFFF'  # Weak relationship - white\n",
    "                    \n",
    "                # Draw the relationship line with gradient effect\n",
    "                line = ax.plot([src[0], tgt[0]], [src[1], tgt[1]], [src[2], tgt[2]],\n",
    "                      color=color,\n",
    "                      alpha=alpha,\n",
    "                      linewidth=1.5,\n",
    "                      zorder=1)\n",
    "                \n",
    "                # Add small arrow to indicate relationship direction\n",
    "                if rel['similarity'] > 0.7:  # Only for stronger relationships\n",
    "                    # Calculate midpoint with slight offset toward target\n",
    "                    midpoint = tuple(0.6*src[i] + 0.4*tgt[i] for i in range(3))\n",
    "                    \n",
    "                    # Draw small sphere at midpoint to represent connection type\n",
    "                    ax.scatter([midpoint[0]], [midpoint[1]], [midpoint[2]],\n",
    "                             color=color,\n",
    "                             s=30,\n",
    "                             alpha=alpha*1.2,\n",
    "                             edgecolors='white',\n",
    "                             linewidth=0.5)\n",
    "        \n",
    "        return ax\n",
    "        \n",
    "    def _add_glow_effect(self, ax, xs, ys, zs, color, size):\n",
    "        \"\"\"Add a subtle glow effect to make points more visually appealing\"\"\"\n",
    "        # Create glow by adding multiple layers of decreasing opacity\n",
    "        for glow_size, alpha in [(size*3, 0.03), (size*2, 0.05), (size*1.5, 0.1)]:\n",
    "            ax.scatter(xs, ys, zs,\n",
    "                     color=color,\n",
    "                     s=glow_size,\n",
    "                     alpha=alpha,\n",
    "                     edgecolors='none')\n",
    "        \n",
    "        return ax\n",
    "    \n",
    "    def _add_explanatory_elements(self, fig, ax, frame_pct):\n",
    "        \"\"\"Add explanatory text and visual elements to guide understanding\"\"\"\n",
    "        # Title with project info and frame context\n",
    "        title_txt = fig.text(\n",
    "            0.5, 0.95,\n",
    "            'Semantic Concept Space Visualization',\n",
    "            ha='center',\n",
    "            color='white',\n",
    "            fontsize=18,\n",
    "            fontweight='bold',\n",
    "            alpha=0.9,\n",
    "            transform=fig.transFigure\n",
    "        )\n",
    "        \n",
    "        # Subtitle with RSC theory explanation\n",
    "        subtitle_txt = fig.text(\n",
    "            0.5, 0.92,\n",
    "            'Relational Semantic Convergence (RSC) Theory',\n",
    "            ha='center',\n",
    "            color='white',\n",
    "            fontsize=14,\n",
    "            fontweight='normal',\n",
    "            alpha=0.8,\n",
    "            transform=fig.transFigure\n",
    "        )\n",
    "        \n",
    "        # Rotating explanation text that changes throughout the animation\n",
    "        explanations = [\n",
    "            \"Visualizing how concepts form relationships in semantic space\",\n",
    "            \"Connected concepts share semantic properties and relationships\",\n",
    "            \"Colored clusters represent different semantic categories\",\n",
    "            \"Discover how meaning emerges from conceptual connections\"\n",
    "        ]\n",
    "        \n",
    "        # Select explanation based on frame position\n",
    "        explanation_idx = int(frame_pct * len(explanations)) % len(explanations)\n",
    "        explanation_txt = fig.text(\n",
    "            0.5, 0.89,\n",
    "            explanations[explanation_idx],\n",
    "            ha='center',\n",
    "            color='white',\n",
    "            fontsize=11,\n",
    "            fontstyle='italic',\n",
    "            alpha=0.7,\n",
    "            transform=fig.transFigure\n",
    "        )\n",
    "        \n",
    "        # Add a visual indicator for rotation direction\n",
    "        arrow_angle = frame_pct * 2 * np.pi\n",
    "        arrow_x = 0.97 + 0.02 * np.cos(arrow_angle)\n",
    "        arrow_y = 0.5 + 0.02 * np.sin(arrow_angle)\n",
    "        rotation_indicator = fig.text(\n",
    "            0.97, 0.5,\n",
    "            '↻',  # Rotation symbol\n",
    "            ha='center',\n",
    "            va='center',\n",
    "            color='white',\n",
    "            fontsize=14,\n",
    "            alpha=0.6,\n",
    "            transform=fig.transFigure\n",
    "        )\n",
    "        \n",
    "        # Add copyright and attribution\n",
    "        fig.text(\n",
    "            0.99, 0.01,\n",
    "            '© Semantica RSC Project ' + time.strftime('%Y'),\n",
    "            ha='right',\n",
    "            color='white',\n",
    "            fontsize=8,\n",
    "            alpha=0.5,\n",
    "            transform=fig.transFigure\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def _add_visual_cues(self, ax, points, frame_pct):\n",
    "        \"\"\"Add visual cues to highlight important features\"\"\"\n",
    "        # Find the most central points to highlight\n",
    "        center = np.array([0, 0, 0])\n",
    "        distances = {concept: np.linalg.norm(np.array(pos) - center) \n",
    "                    for concept, pos in points.items()}\n",
    "        \n",
    "        # Get 3 closest points to center\n",
    "        central_concepts = sorted(distances.items(), key=lambda x: x[1])[:3]\n",
    "        \n",
    "        # Highlight these central concepts with pulsing focus rings\n",
    "        pulse = 0.5 + 0.5 * np.sin(frame_pct * 2 * np.pi * 3)  # 3 pulses per cycle\n",
    "        \n",
    "        for concept, distance in central_concepts:\n",
    "            if concept in points:\n",
    "                x, y, z = points[concept]\n",
    "                \n",
    "                # Draw focus ring\n",
    "                theta = np.linspace(0, 2*np.pi, 20)\n",
    "                radius = 0.2 + 0.05 * pulse\n",
    "                \n",
    "                # Create a small circle around the point\n",
    "                circle_x = x + radius * np.cos(theta)\n",
    "                circle_y = y + radius * np.sin(theta)\n",
    "                circle_z = np.full_like(theta, z)\n",
    "                \n",
    "                ax.plot(circle_x, circle_y, circle_z, \n",
    "                      color='white', \n",
    "                      alpha=0.3*pulse,\n",
    "                      linewidth=1)\n",
    "        \n",
    "        return ax\n",
    "    \n",
    "    def visualize_concepts_enhanced(self, output_dir, num_frames=60):\n",
    "        \"\"\"Create a highly enhanced visualization with improved visual appeal and clarity\"\"\"\n",
    "        try:\n",
    "            print(\"Creating enhanced semantic visualization...\")\n",
    "            \n",
    "            if not self.concept_processor or not self.concept_processor.concept_vectors:\n",
    "                raise ValueError(\"Concept processor not initialized or no vectors generated\")\n",
    "            \n",
    "            # Get important relationships\n",
    "            try:\n",
    "                important_relationships = self.concept_processor.compute_important_relationships(\n",
    "                    threshold=0.5, \n",
    "                    max_relationships=30\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not compute relationships: {str(e)}\")\n",
    "                important_relationships = []\n",
    "\n",
    "            # Setup figure with high DPI for crisp text\n",
    "            plt.close('all')\n",
    "            fig = plt.figure(figsize=(16, 12), dpi=150)\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            \n",
    "            # Apply the background gradient\n",
    "            self._create_background_gradient(fig, ax)\n",
    "            \n",
    "            # Calculate node importance based on connectivity\n",
    "            node_importance = {}\n",
    "            for concept in self.concept_processor.concept_vectors.keys():\n",
    "                # Count occurrences in important relationships\n",
    "                count = sum(1 for rel in important_relationships \n",
    "                           if rel['source'] == concept or rel['target'] == concept)\n",
    "                node_importance[concept] = 30 + (count * 20)  # Base size + importance factor\n",
    "            \n",
    "            # Lists to keep track of text objects\n",
    "            text_objects = []\n",
    "            \n",
    "            def update(frame):\n",
    "                try:\n",
    "                    # Clear previous frame\n",
    "                    ax.clear()\n",
    "                    \n",
    "                    # Handle text objects removal more safely\n",
    "                    for txt in fig.texts[:]:\n",
    "                        fig.texts.remove(txt)\n",
    "                    \n",
    "                    # Calculate frame percentage for animations\n",
    "                    frame_pct = frame / num_frames\n",
    "                    \n",
    "                    # Configure axis appearance\n",
    "                    ax.grid(False)  # Remove grid for cleaner look\n",
    "                    ax.xaxis.pane.fill = False\n",
    "                    ax.yaxis.pane.fill = False\n",
    "                    ax.zaxis.pane.fill = False\n",
    "                    \n",
    "                    # Make panes completely transparent\n",
    "                    ax.xaxis.pane.set_edgecolor('none')\n",
    "                    ax.yaxis.pane.set_edgecolor('none')\n",
    "                    ax.zaxis.pane.set_edgecolor('none')\n",
    "                    \n",
    "                    # Remove axis labels and ticks for cleaner look\n",
    "                    ax.set_xticklabels([])\n",
    "                    ax.set_yticklabels([])\n",
    "                    ax.set_zticklabels([])\n",
    "                    ax.set_xticks([])\n",
    "                    ax.set_yticks([])\n",
    "                    ax.set_zticks([])\n",
    "                    \n",
    "                    # Calculate dynamic camera angle for smoother rotation\n",
    "                    theta = frame_pct * 2 * np.pi\n",
    "                    phi = 0.2 * np.sin(frame_pct * 2 * np.pi * 0.5) + 0.3  # Gentle up/down motion\n",
    "                    \n",
    "                    # Set viewing angle with smooth transitions\n",
    "                    ax.view_init(30 + 5 * np.sin(phi), 45 + 180 * frame_pct)\n",
    "                    \n",
    "                    # Convert concept vectors to 3D points with dynamic positioning\n",
    "                    points = {}\n",
    "                    for concept, data in self.concept_processor.concept_vectors.items():\n",
    "                        vector = data['vector'][:3]\n",
    "                        \n",
    "                        # Apply dynamic rotation matrix\n",
    "                        x, y, z = vector\n",
    "                        x_rot = x * np.cos(theta) - y * np.sin(theta)\n",
    "                        y_rot = x * np.sin(theta) + y * np.cos(theta)\n",
    "                        z_rot = z + 0.05 * np.sin(theta * 2 + x)  # Add gentle wave motion\n",
    "                        \n",
    "                        points[concept] = (x_rot, y_rot, z_rot)\n",
    "                    \n",
    "                    # Add relationship lines first (so they appear behind points)\n",
    "                    self._add_relationship_lines(ax, points, important_relationships, frame_pct)\n",
    "                    \n",
    "                    # Plot points by category with enhanced visual elements\n",
    "                    legend_elements = []\n",
    "                    for category, color in self.category_colors.items():\n",
    "                        cat_points = [\n",
    "                            (concept, points[concept], node_importance[concept]) \n",
    "                            for concept in self.concept_processor.concept_vectors\n",
    "                            if concept in points and \n",
    "                            self.concept_processor.concept_vectors[concept]['category'] == category\n",
    "                        ]\n",
    "                        \n",
    "                        if cat_points:\n",
    "                            # Split the data for plotting\n",
    "                            concepts, coords, sizes = zip(*cat_points)\n",
    "                            xs, ys, zs = zip(*coords)\n",
    "                            \n",
    "                            # Add glow effect for nicer visuals\n",
    "                            self._add_glow_effect(ax, xs, ys, zs, color, 30)\n",
    "                            \n",
    "                            # Create scatter plot with improved styling\n",
    "                            scatter = ax.scatter(xs, ys, zs, \n",
    "                                              c=color, \n",
    "                                              alpha=0.9, \n",
    "                                              s=sizes,  # Size based on importance\n",
    "                                              edgecolors='white',\n",
    "                                              linewidth=0.5,\n",
    "                                              zorder=10)\n",
    "                            \n",
    "                            # Add category to legend with improved styling\n",
    "                            legend_elements.append(plt.Line2D(\n",
    "                                [0], [0], \n",
    "                                marker='o', \n",
    "                                color='none',\n",
    "                                markerfacecolor=color,\n",
    "                                markeredgecolor='white',\n",
    "                                markersize=10,\n",
    "                                label=self.category_descriptions[category]))\n",
    "                            \n",
    "                            # Add labels for important concepts with improved styling\n",
    "                            for concept, (x, y, z), size in zip(concepts, coords, sizes):\n",
    "                                # Only label significant concepts for clarity\n",
    "                                if len(concept) > 2 and size > 50:  # Important nodes with meaningful names\n",
    "                                    # Calculate label transparency based on size\n",
    "                                    label_alpha = min(0.9, size / 100)\n",
    "                                    \n",
    "                                    # Create more visible text with better contrast\n",
    "                                    ax.text(x, y, z + 0.05,  # Slight offset\n",
    "                                          concept,\n",
    "                                          color='white',\n",
    "                                          fontsize=8,\n",
    "                                          fontweight='bold',\n",
    "                                          alpha=label_alpha,\n",
    "                                          backgroundcolor=(0, 0, 0, 0.4),\n",
    "                                          ha='center',\n",
    "                                          zorder=20)\n",
    "                    \n",
    "                    # Add visual cues to highlight key areas\n",
    "                    self._add_visual_cues(ax, points, frame_pct)\n",
    "                    \n",
    "                    # Add legend with enhanced styling\n",
    "                    legend = ax.legend(handles=legend_elements,\n",
    "                                     loc='upper right',\n",
    "                                     bbox_to_anchor=(0.99, 0.99),\n",
    "                                     title='Semantic Categories',\n",
    "                                     facecolor=(0.1, 0.1, 0.1, 0.7),\n",
    "                                     edgecolor='white',\n",
    "                                     fontsize=10)\n",
    "                    \n",
    "                    if legend:\n",
    "                        legend.get_title().set_color('white')\n",
    "                        for text in legend.get_texts():\n",
    "                            text.set_color('white')\n",
    "                    \n",
    "                    # Add progress indicator\n",
    "                    self._add_progress_indicator(fig, frame, num_frames)\n",
    "                    \n",
    "                    # Add explanatory text and elements\n",
    "                    self._add_explanatory_elements(fig, ax, frame_pct)\n",
    "                    \n",
    "                    return fig\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error in update frame {frame}: {str(e)}\")\n",
    "                    traceback.print_exc()\n",
    "                    return fig\n",
    "\n",
    "            # Create animation with enhanced parameters\n",
    "            anim = animation.FuncAnimation(\n",
    "                fig, \n",
    "                update,\n",
    "                frames=num_frames,\n",
    "                interval=40,  # Faster frame rate for smoother animation\n",
    "                blit=False\n",
    "            )\n",
    "            \n",
    "            # Create a static preview image\n",
    "            print(\"Creating enhanced static preview...\")\n",
    "            update(0)\n",
    "            \n",
    "            # Save with high quality settings\n",
    "            static_path = os.path.join(output_dir, f'semantica_enhanced_preview_{uuid.uuid4()}.png')\n",
    "            plt.savefig(static_path, dpi=150, bbox_inches='tight')\n",
    "            print(f\"Preview image saved to: {static_path}\")\n",
    "            \n",
    "            # Save animation with enhanced quality\n",
    "            output_path = os.path.join(output_dir, f'semantica_enhanced_{uuid.uuid4()}.gif')\n",
    "            print(f\"Generating animation (this may take some time)...\")\n",
    "            \n",
    "            # Add a timestamp to the animation\n",
    "            timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            fig.text(\n",
    "                0.5, 0.01,\n",
    "                f\"Generated: {timestamp}\",\n",
    "                ha='center',\n",
    "                color='white',\n",
    "                fontsize=8,\n",
    "                alpha=0.6,\n",
    "                transform=fig.transFigure\n",
    "            )\n",
    "            \n",
    "            # Use a more robust method to save the animation\n",
    "            frames = []\n",
    "            frame_files = []  # Keep track of temporary files\n",
    "            tmp_dir = os.path.join(output_dir, 'tmp_frames')\n",
    "            \n",
    "            # Create temporary directory for frames\n",
    "            if not os.path.exists(tmp_dir):\n",
    "                os.makedirs(tmp_dir)\n",
    "                \n",
    "            try:\n",
    "                print(\"Generating frames...\")\n",
    "                for i in range(num_frames):\n",
    "                    # Update the figure for this frame\n",
    "                    update(i)\n",
    "                    \n",
    "                    # Save frame to a temporary file instead of keeping in memory\n",
    "                    tmp_file = os.path.join(tmp_dir, f'frame_{i:04d}.png')\n",
    "                    plt.savefig(tmp_file, dpi=150, bbox_inches='tight',\n",
    "                               facecolor=self.bg_gradient['bottom'])\n",
    "                    frame_files.append(tmp_file)\n",
    "                    \n",
    "                    # Print progress\n",
    "                    if i % 10 == 0 or i == num_frames - 1:\n",
    "                        print(f\"Generated frame {i+1}/{num_frames}\")\n",
    "                \n",
    "                # Create GIF using external library\n",
    "                print(\"Saving animation...\")\n",
    "                from PIL import Image\n",
    "                \n",
    "                # Load all frames from files\n",
    "                frames = [Image.open(f) for f in frame_files]\n",
    "                \n",
    "                # Ensure all frames are the same size\n",
    "                if frames:\n",
    "                    size = frames[0].size\n",
    "                    frames = [f.resize(size) for f in frames]\n",
    "                    \n",
    "                    # Save as GIF\n",
    "                    frames[0].save(\n",
    "                        output_path,\n",
    "                        save_all=True,\n",
    "                        append_images=frames[1:],\n",
    "                        optimize=False,\n",
    "                        duration=1000/30,  # 30 FPS\n",
    "                        loop=0\n",
    "                    )\n",
    "                    \n",
    "                    # Close all frames\n",
    "                    for f in frames:\n",
    "                        f.close()\n",
    "                    \n",
    "                    print(f\"Enhanced visualization saved successfully to {output_path}\")\n",
    "            finally:\n",
    "                # Clean up temporary files\n",
    "                for file in frame_files:\n",
    "                    try:\n",
    "                        if os.path.exists(file):\n",
    "                            os.remove(file)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Warning: Could not remove temporary file {file}: {e}\")\n",
    "                        \n",
    "                # Try to remove temp directory\n",
    "                try:\n",
    "                    if os.path.exists(tmp_dir):\n",
    "                        os.rmdir(tmp_dir)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not remove temporary directory: {e}\")\n",
    "            \n",
    "            plt.close()\n",
    "            return output_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating visualization: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7ce40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Phase 2: Enhanced visualization generation...\n",
      "Initializing ConceptNetProcessor with loaded datasets...\n",
      "ConceptNetProcessor initialized\n",
      "Building semantic graph from ConceptNet data...\n",
      "Processing 3423004 English ConceptNet assertions...\n",
      "Will sample 1711502 English assertions\n",
      "Processing 1078946 German ConceptNet assertions...\n",
      "Will sample 539473 German assertions\n",
      "Sampling 1711502 assertions from 3423004 en assertions\n",
      "Sampling 1711502 assertions from 3423004 en assertions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing en assertions:  25%|██▍       | 422958/1711502 [00:10<00:32, 39135.48it/s]"
     ]
    }
   ],
   "source": [
    "# Phase 2: Generate the enhanced visualization\n",
    "print(\"Starting Phase 2: Enhanced visualization generation...\")\n",
    "\n",
    "# Create enhanced visualizer with the same processor\n",
    "enhanced_visualizer = EnhancedSemanticVisualizer(processor)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize processor with the datasets we loaded at the beginning\n",
    "print(\"Initializing ConceptNetProcessor with loaded datasets...\")\n",
    "processor = ConceptNetProcessor(english_conceptnet, german_conceptnet)\n",
    "\n",
    "# Build semantic graph with 25% sampling\n",
    "processor.build_semantic_graph(\n",
    "    max_concepts=10_000,  # Keep reasonable number of concepts for visualization\n",
    "    min_weight=1.0,\n",
    "    sample_size=0.5  # Use 25% of the data\n",
    ")\n",
    "\n",
    "# Generate concept vectors\n",
    "processor.generate_concept_vectors(dimensions=5)\n",
    "\n",
    "# Create the enhanced visualization with more frames for smoother animation\n",
    "# and additional visual elements for clarity and appeal\n",
    "output_path = enhanced_visualizer.visualize_concepts_enhanced(\n",
    "    output_dir,\n",
    "    num_frames=500  # Reasonable number of frames for smooth animation but faster rendering\n",
    ")\n",
    "\n",
    "print(f\"Enhanced visualization created at: {output_path}\")\n",
    "print(\"\\nKey improvements in Phase 2:\")\n",
    "print(\"1. Progress indicator showing current frame/total frames\")\n",
    "print(\"2. Beautiful gradient background instead of plain gray\")\n",
    "print(\"3. Clear relationship lines between related concepts\")\n",
    "print(\"4. Explanatory text elements that change throughout the animation\")\n",
    "print(\"5. Node sizing based on concept importance\")\n",
    "print(\"6. Improved color scheme and glow effects\")\n",
    "print(\"7. Smooth camera angles and transitions\")\n",
    "print(\"8. Visual cues highlighting important concepts\")\n",
    "print(\"9. Timestamp and attribution information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247a4913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
