{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "curr_dir = os.getcwd()\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(curr_dir, '../Data')\n",
    "\n",
    "input_path = os.path.join(data_path, '/Input')\n",
    "interim_path = os.path.join(data_path, '/Intermediate')\n",
    "output_path = os.path.join(data_path, '/Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --user --upgrade numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full RSC Semantic Convergence + Syntax Emergence Experiment\n",
    "# Author: Erich Curtis\n",
    "# Date: 2025-04-28\n",
    "\n",
    "import random\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------- 1. Vocabulary and Expanded Relations -------------------\n",
    "\n",
    "semantic_fields = {\n",
    "    \"Living Things\": ['dog', 'cat', 'horse', 'bird', 'deer', 'fox', 'shark', 'turtle', 'teacher', 'parent', 'child', 'friend', 'enemy'],\n",
    "    \"Actions\": ['run', 'walk', 'swim', 'teach', 'learn', 'jump', 'help', 'hurt', 'love', 'eat', 'think', 'cook', 'write', 'speak', 'listen', 'plan'],\n",
    "    \"Objects\": ['chair', 'table', 'cup', 'pen', 'phone', 'backpack', 'house', 'bridge', 'road', 'tree', 'bottle', 'knife', 'fork', 'window', 'bed'],\n",
    "    \"Locations\": ['forest', 'mountain', 'river', 'valley', 'school', 'city', 'field', 'beach', 'island', 'cave', 'hill', 'continent', 'stadium', 'village'],\n",
    "    \"Quantities\": ['one', 'two', 'few', 'many', 'all', 'none', 'some'],\n",
    "    \"Modifiers\": ['big', 'small', 'fast', 'slow', 'loud', 'quiet', 'happy', 'sad', 'bright', 'dark'],\n",
    "    \"Prepositions\": ['across', 'under', 'over', 'through', 'beside', 'near', 'around'],\n",
    "    \"Scientific\": ['earth', 'sun', 'water', 'ice', 'orbit', 'gravity', 'star', 'cloud'],\n",
    "    \"Social\": ['neighbor', 'stranger', 'friend', 'parent', 'enemy'],\n",
    "    \"Emotions\": ['happy', 'sad', 'angry', 'tired', 'calm', 'excited', 'afraid', 'safe', 'proud', 'ashamed'],\n",
    "    \"Time Concepts\": ['morning', 'afternoon', 'night', 'yesterday', 'today', 'tomorrow'],\n",
    "    \"Communication\": ['speak', 'say', 'listen', 'ask', 'answer', 'name', 'introduce'],\n",
    "    \"Complex Social\": ['my_name_is', 'he_is_my_friend', 'they_live_in_city'],\n",
    "    \"Conditions\": ['if', 'when', 'because', 'while', 'although', 'unless']\n",
    "}\n",
    "\n",
    "# Flat vocabulary\n",
    "vocab = list(set([item for sublist in semantic_fields.values() for item in sublist]))\n",
    "\n",
    "# Relations - Simple, Medium, Complex, Conditional\n",
    "relations = [\n",
    "    ('dog', 'is', 'mammal'),\n",
    "    ('car', 'moves_on', 'road'),\n",
    "    ('bird', 'flies_over', 'river'),\n",
    "    ('teacher', 'teaches', 'child'),\n",
    "    ('rain', 'causes', 'wet_ground'),\n",
    "    ('river', 'flows_into', 'lake'),\n",
    "    ('phone', 'connects_to', 'internet'),\n",
    "    ('earth', 'orbits', 'sun'),\n",
    "    ('sun', 'provides', 'light'),\n",
    "    ('friend', 'helps', 'friend'),\n",
    "    ('child', 'plays_with', 'dog'),\n",
    "    ('parent', 'loves', 'child'),\n",
    "    ('earth', 'has', 'gravity'),\n",
    "    ('water', 'freezes_at', '0C'),\n",
    "    ('mountain', 'stands_over', 'valley'),\n",
    "    ('wind', 'moves', 'clouds'),\n",
    "    ('child', 'crosses', 'bridge', 'during rain'),\n",
    "    ('friend', 'helps', 'friend', 'because of danger'),\n",
    "    ('sun', 'rises', 'over mountain', 'at morning'),\n",
    "    ('hunger', 'leads_to', 'eating'),\n",
    "    ('fish', 'cannot', 'walk'),\n",
    "    ('if rain', 'then', 'ground becomes wet'),\n",
    "    ('teacher', 'speaks_to', 'student', 'in school'),\n",
    "    ('cat', 'sleeps_on', 'bed'),\n",
    "    ('dog', 'barks_at', 'stranger'),\n",
    "    ('earthquake', 'shakes', 'city'),\n",
    "    ('student', 'learns_from', 'teacher'),\n",
    "    ('turtle', 'crawls_under', 'rock')\n",
    "]\n",
    "\n",
    "# ------------------- 2. Agent Initialization -------------------\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "agent_a_groundings = {word: word for word in vocab}\n",
    "agent_b_groundings = {}\n",
    "for word in vocab:\n",
    "    if random.random() < 0.8:\n",
    "        agent_b_groundings[word] = word\n",
    "    else:\n",
    "        agent_b_groundings[word] = random.choice(vocab)\n",
    "\n",
    "agent_c_groundings = {}\n",
    "for word in vocab:\n",
    "    if random.random() < 0.3:\n",
    "        agent_c_groundings[word] = word\n",
    "    else:\n",
    "        agent_c_groundings[word] = random.choice(vocab)\n",
    "\n",
    "# ------------------- 3. Learning Phase with RSC Stability -------------------\n",
    "\n",
    "total_frames = 1500\n",
    "batch_size = 3\n",
    "\n",
    "proposals_log_ab = []\n",
    "proposals_log_ac = []\n",
    "anchor_log_ab = []\n",
    "anchor_log_ac = []\n",
    "accepted_relations_ab = set()\n",
    "accepted_relations_ac = set()\n",
    "stability_counter_ab = {}\n",
    "stability_counter_ac = {}\n",
    "anchors_ab = set()\n",
    "anchors_ac = set()\n",
    "accuracy_over_time_ab = []\n",
    "accuracy_over_time_ac = []\n",
    "\n",
    "stability_threshold = 3\n",
    "\n",
    "# Ground truth set for validation\n",
    "ground_truth_set = set(relations)\n",
    "\n",
    "def validate_relation(*args):\n",
    "    return args in ground_truth_set\n",
    "\n",
    "def try_validate(groundings, *words):\n",
    "    mapped = tuple([groundings[w] if w in groundings else w for w in words])\n",
    "    return validate_relation(*mapped)\n",
    "\n",
    "# Learning Loop\n",
    "for frame in tqdm(range(total_frames), desc=\"Learning Progress\", unit=\"frame\"):\n",
    "    proposals = random.sample(relations, batch_size)\n",
    "    accepted_ab = 0\n",
    "    accepted_ac = 0\n",
    "\n",
    "    for proposal in proposals:\n",
    "        if try_validate(agent_b_groundings, *proposal):\n",
    "            accepted_relations_ab.add(proposal)\n",
    "            stability_counter_ab[proposal] = stability_counter_ab.get(proposal, 0) + 1\n",
    "            accepted_ab += 1\n",
    "            proposals_log_ab.append(f\"Frame {frame}: {proposal} → ACCEPTED (A↔B)\")\n",
    "            if stability_counter_ab[proposal] == stability_threshold:\n",
    "                anchors_ab.update(proposal)\n",
    "                anchor_log_ab.append(f\"Frame {frame}: ANCHORED {proposal}\")\n",
    "        else:\n",
    "            proposals_log_ab.append(f\"Frame {frame}: {proposal} → REJECTED (A↔B)\")\n",
    "\n",
    "        if try_validate(agent_c_groundings, *proposal):\n",
    "            accepted_relations_ac.add(proposal)\n",
    "            stability_counter_ac[proposal] = stability_counter_ac.get(proposal, 0) + 1\n",
    "            accepted_ac += 1\n",
    "            proposals_log_ac.append(f\"Frame {frame}: {proposal} → ACCEPTED (A↔C)\")\n",
    "            if stability_counter_ac[proposal] == stability_threshold:\n",
    "                anchors_ac.update(proposal)\n",
    "                anchor_log_ac.append(f\"Frame {frame}: ANCHORED {proposal}\")\n",
    "        else:\n",
    "            proposals_log_ac.append(f\"Frame {frame}: {proposal} → REJECTED (A↔C)\")\n",
    "\n",
    "    accuracy_over_time_ab.append(accepted_ab / batch_size)\n",
    "    accuracy_over_time_ac.append(accepted_ac / batch_size)\n",
    "\n",
    "    if frame % 25 == 0 and frame != 0:\n",
    "        for word in random.sample(list(agent_c_groundings.keys()), 5):\n",
    "            agent_c_groundings[word] = random.choice(vocab)\n",
    "\n",
    "# ------------------- 4. Save Logs -------------------\n",
    "\n",
    "with open('negotiation_log_ab.txt', 'w', encoding='utf-8') as f:\n",
    "    for line in proposals_log_ab:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "with open('negotiation_log_ac.txt', 'w', encoding='utf-8') as f:\n",
    "    for line in proposals_log_ac:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "with open('anchor_log_ab.txt', 'w', encoding='utf-8') as f:\n",
    "    for line in anchor_log_ab:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "with open('anchor_log_ac.txt', 'w', encoding='utf-8') as f:\n",
    "    for line in anchor_log_ac:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "print(\"All logs saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSC Visualizations Bundle\n",
    "# Author: Erich Curtis\n",
    "# Date: 2025-04-28\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Assume the following variables are already loaded from your main experiment:\n",
    "# semantic_fields, accepted_relations_ab, anchors_ab, anchor_log_ab, stability_counter_ab\n",
    "\n",
    "# ------------------- 1. Semantic Field Graph -------------------\n",
    "def plot_semantic_field_graph():\n",
    "    G_semantic = nx.Graph()\n",
    "    color_palette = ['red', 'blue', 'green', 'purple', 'orange', 'cyan', 'magenta', 'yellow', 'brown', 'pink']\n",
    "    color_map = {}\n",
    "\n",
    "    for idx, (field, words) in enumerate(semantic_fields.items()):\n",
    "        for word in words:\n",
    "            G_semantic.add_node(word, field=field)\n",
    "            color_map[word] = color_palette[idx % len(color_palette)]\n",
    "\n",
    "    for rel in accepted_relations_ab:\n",
    "        for i in range(len(rel) - 1):\n",
    "            G_semantic.add_edge(rel[i], rel[i+1])\n",
    "\n",
    "    plt.figure(figsize=(18, 12))\n",
    "    pos = nx.spring_layout(G_semantic, seed=42)\n",
    "    nx.draw_networkx_nodes(G_semantic, pos, node_color=[color_map.get(n, 'gray') for n in G_semantic.nodes()], node_size=300)\n",
    "    nx.draw_networkx_edges(G_semantic, pos, alpha=0.3)\n",
    "    nx.draw_networkx_labels(G_semantic, pos, font_size=8)\n",
    "\n",
    "    plt.title(\"Semantic Field Graph (Accepted Relations A↔B)\", fontsize=16)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# ------------------- 2. Syntax Emergence Graph -------------------\n",
    "# Semantic Field Graph Visualization\n",
    "def plot_semantic_field_graph():\n",
    "    G_semantic = nx.Graph()\n",
    "    color_palette = ['red', 'blue', 'green', 'purple', 'orange', 'cyan', 'magenta', 'yellow', 'brown', 'pink']\n",
    "    color_map = {}\n",
    "\n",
    "    # Add nodes and assign colors based on semantic fields\n",
    "    for idx, (field, words) in enumerate(semantic_fields.items()):\n",
    "        for word in words:\n",
    "            G_semantic.add_node(word, field=field)\n",
    "            color_map[word] = color_palette[idx % len(color_palette)]\n",
    "\n",
    "    # Add edges based on accepted relations\n",
    "    for rel in accepted_relations_ab:\n",
    "        for i in range(len(rel) - 1):\n",
    "            G_semantic.add_edge(rel[i], rel[i + 1])\n",
    "\n",
    "    # Plot the graph\n",
    "    plt.figure(figsize=(18, 12))\n",
    "    pos = nx.spring_layout(G_semantic, seed=42)\n",
    "\n",
    "    # Assign a default color (e.g., 'gray') for nodes not in color_map\n",
    "    default_color = 'gray'\n",
    "    node_colors = [color_map.get(n, default_color) for n in G_semantic.nodes()]\n",
    "\n",
    "    nx.draw_networkx_nodes(G_semantic, pos, node_color=node_colors, node_size=300)\n",
    "    nx.draw_networkx_edges(G_semantic, pos, alpha=0.3)\n",
    "    nx.draw_networkx_labels(G_semantic, pos, font_size=8)\n",
    "\n",
    "    plt.title(\"Semantic Field Graph (Accepted Relations A↔B)\", fontsize=16)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# ------------------- 3. Anchor Timeline Plot -------------------\n",
    "def plot_anchor_timeline():\n",
    "    anchor_frames = [int(line.split()[1][:-1]) for line in anchor_log_ab]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(anchor_frames, bins=50, cumulative=True, color='green')\n",
    "    plt.xlabel('Frame', fontsize=14)\n",
    "    plt.ylabel('Cumulative Anchors', fontsize=14)\n",
    "    plt.title('Anchor Emergence Timeline: Agent A↔B', fontsize=16)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ------------------- 4. Stability Heatmap -------------------\n",
    "def plot_stability_heatmap():\n",
    "    relation_names = [str(rel) for rel in stability_counter_ab.keys()]\n",
    "    validation_counts = [stability_counter_ab[rel] for rel in stability_counter_ab]\n",
    "\n",
    "    df = pd.DataFrame({'Relation': relation_names, 'Validations': validation_counts})\n",
    "    df = df.sort_values('Validations', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(df[['Validations']].T, cmap=\"YlGnBu\", cbar=True, annot=False, linewidths=.5)\n",
    "    plt.xticks(np.arange(len(df)) + 0.5, df['Relation'], rotation=90, fontsize=7)\n",
    "    plt.yticks([])\n",
    "    plt.title('Stability Heatmap of Relations', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ------------------- 5. Word Cloud of Anchors -------------------\n",
    "def plot_wordcloud_of_anchors():\n",
    "    anchor_words = list(anchors_ab)\n",
    "\n",
    "    wordcloud = WordCloud(width=1600, height=800, background_color='white').generate(' '.join(anchor_words))\n",
    "\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud of Anchored Concepts', fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "# ------------------- Main to Call All Visuals -------------------\n",
    "if __name__ == \"__main__\":\n",
    "    plot_semantic_field_graph()\n",
    "    # plot_syntax_emergence_graph()\n",
    "    plot_anchor_timeline()\n",
    "    plot_stability_heatmap()\n",
    "    plot_wordcloud_of_anchors()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
